<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.15.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tensor Library: include/tensor_perf.h File Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tensor Library
   </div>
   <div id="projectbrief">High-performance C++ tensor library with GPU, BLAS, autograd, and linear algebra support</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.15.0 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search/",'.html');
</script>
<script type="text/javascript">
$(function() { codefold.init(); });
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search',true);
  $(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(function(){initNavTree('tensor__perf_8h.html','',''); });
</script>
<div id="container">
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">tensor_perf.h File Reference</div></div>
</div><!--header-->
<div class="contents">

<p>Performance optimization features for tensor operations.  
<a href="#details">More...</a></p>
<div class="textblock"><code>#include &lt;memory&gt;</code><br />
<code>#include &lt;vector&gt;</code><br />
<code>#include &lt;mutex&gt;</code><br />
<code>#include &lt;thread&gt;</code><br />
<code>#include &lt;cstdint&gt;</code><br />
<code>#include &lt;cmath&gt;</code><br />
<code>#include &lt;cstring&gt;</code><br />
<code>#include &lt;functional&gt;</code><br />
<code>#include &lt;future&gt;</code><br />
<code>#include &lt;queue&gt;</code><br />
</div><div class="textblock"><div class="dynheader">
Include dependency graph for tensor_perf.h:</div>
<div class="dyncontent">
<div class="center"><img src="tensor__perf_8h__incl.png" border="0" usemap="#ainclude_2tensor__perf_8h" loading="lazy" alt=""/></div>
<map name="ainclude_2tensor__perf_8h" id="ainclude_2tensor__perf_8h">
<area shape="rect" title="Performance optimization features for tensor operations." alt="" coords="342,5,484,32"/>
<area shape="rect" title=" " alt="" coords="5,80,74,107"/>
<area shape="poly" title=" " alt="" coords="342,34,227,54,89,82,88,77,226,49,341,29"/>
<area shape="rect" title=" " alt="" coords="98,80,155,107"/>
<area shape="poly" title=" " alt="" coords="358,35,171,82,169,76,357,30"/>
<area shape="rect" title=" " alt="" coords="179,80,236,107"/>
<area shape="poly" title=" " alt="" coords="378,35,251,80,249,74,376,30"/>
<area shape="rect" title=" " alt="" coords="260,80,318,107"/>
<area shape="poly" title=" " alt="" coords="393,35,325,74,322,70,390,30"/>
<area shape="rect" title=" " alt="" coords="341,80,402,107"/>
<area shape="poly" title=" " alt="" coords="408,34,388,68,384,65,403,31"/>
<area shape="rect" title=" " alt="" coords="426,80,483,107"/>
<area shape="poly" title=" " alt="" coords="422,31,442,65,437,68,418,34"/>
<area shape="rect" title=" " alt="" coords="507,80,567,107"/>
<area shape="poly" title=" " alt="" coords="436,30,504,70,501,74,433,35"/>
<area shape="rect" title=" " alt="" coords="592,80,669,107"/>
<area shape="poly" title=" " alt="" coords="452,30,579,72,577,77,450,35"/>
<area shape="rect" title=" " alt="" coords="692,80,747,107"/>
<area shape="poly" title=" " alt="" coords="477,30,678,77,676,82,475,35"/>
<area shape="rect" title=" " alt="" coords="771,80,828,107"/>
<area shape="poly" title=" " alt="" coords="484,27,608,47,757,77,756,82,607,53,484,33"/>
</map>
</div>
</div><div class="textblock"><div class="dynheader">
This graph shows which files directly or indirectly include this file:</div>
<div class="dyncontent">
<div class="center"><img src="tensor__perf_8h__dep__incl.png" border="0" usemap="#ainclude_2tensor__perf_8hdep" loading="lazy" alt=""/></div>
<map name="ainclude_2tensor__perf_8hdep" id="ainclude_2tensor__perf_8hdep">
<area shape="rect" title="Performance optimization features for tensor operations." alt="" coords="481,5,623,32"/>
<area shape="rect" href="tensor_8h.html" title="High&#45;performance multi&#45;dimensional tensor library with GPU, BLAS, and autograd support." alt="" coords="495,80,608,107"/>
<area shape="poly" title=" " alt="" coords="554,48,554,80,549,80,549,48"/>
<area shape="rect" href="linalg_8h.html" title="Linear algebra operations for vectors and matrices." alt="" coords="211,155,319,181"/>
<area shape="poly" title=" " alt="" coords="488,114,316,157,315,151,486,108"/>
<area shape="rect" href="tensor__c_8cpp.html" title=" " alt="" coords="502,304,620,331"/>
<area shape="poly" title=" " alt="" coords="479,97,319,102,228,110,143,124,72,144,44,157,24,172,12,189,8,208,15,229,32,254,55,266,99,276,228,293,377,304,502,311,501,316,376,310,228,298,98,281,53,271,29,258,10,232,3,208,7,187,20,168,42,153,70,139,142,119,228,105,318,97,479,91"/>
<area shape="rect" href="tensor__instantiations_8cc.html" title="Explicit template instantiations for Matrix and Tensor types." alt="" coords="42,229,224,256"/>
<area shape="poly" title=" " alt="" coords="480,103,324,123,251,138,201,157,181,173,164,193,141,230,137,228,160,190,177,169,198,152,250,133,323,118,480,98"/>
<area shape="rect" href="loss__functions_8h.html" title="Loss functions for training neural networks." alt="" coords="352,155,514,181"/>
<area shape="poly" title=" " alt="" coords="520,117,455,156,453,152,517,113"/>
<area shape="rect" href="nn__layers_8h.html" title="Common neural network layer implementations." alt="" coords="654,229,788,256"/>
<area shape="poly" title=" " alt="" coords="572,117,598,148,629,179,665,206,699,226,696,231,662,210,626,183,594,152,568,121"/>
<area shape="rect" href="optimizers_8h.html" title="Optimization algorithms for training neural networks." alt="" coords="492,229,630,256"/>
<area shape="poly" title=" " alt="" coords="556,122,563,229,558,229,551,122"/>
<area shape="rect" href="tensor__io_8h.html" title="I/O operations for tensors (save/load/print)." alt="" coords="896,229,1026,256"/>
<area shape="poly" title=" " alt="" coords="624,92,717,94,821,103,869,111,913,121,947,135,971,153,980,172,981,193,970,230,965,228,975,192,975,173,967,156,945,140,911,127,868,116,820,108,717,100,624,97"/>
<area shape="rect" href="tensor__ops_8h.html" title="Core neural network operations with broadcasting and autograd." alt="" coords="816,155,957,181"/>
<area shape="poly" title=" " alt="" coords="624,108,828,151,827,157,623,113"/>
<area shape="rect" href="tensor__types_8h.html" title="Type aliases for common Tensor specializations." alt="" coords="640,155,792,181"/>
<area shape="poly" title=" " alt="" coords="595,111,688,152,686,156,593,116"/>
<area shape="rect" href="linalg__advanced_8h.html" title="Advanced linear algebra operations with LAPACK/cuSOLVER support." alt="" coords="299,229,469,256"/>
<area shape="poly" title=" " alt="" coords="300,187,364,226,362,231,297,192"/>
<area shape="poly" title=" " alt="" coords="267,196,273,227,279,242,288,254,303,264,324,273,379,289,502,308,501,313,378,294,322,278,300,269,285,258,274,244,268,229,262,197"/>
<area shape="poly" title=" " alt="" coords="231,191,158,231,155,226,228,187"/>
<area shape="poly" title=" " alt="" coords="430,260,531,301,529,306,428,265"/>
<area shape="poly" title=" " alt="" coords="680,265,590,306,588,301,678,260"/>
<area shape="poly" title=" " alt="" coords="564,272,564,304,558,304,558,272"/>
<area shape="poly" title=" " alt="" coords="881,261,621,308,620,303,880,256"/>
<area shape="poly" title=" " alt="" coords="758,187,781,201,799,218,808,237,807,247,802,258,790,268,773,277,726,293,621,312,620,307,725,287,770,272,787,264,798,254,802,246,803,238,795,221,777,205,756,191"/>
<area shape="poly" title=" " alt="" coords="720,197,723,229,718,229,715,197"/>
</map>
</div>
</div>
<p><a href="tensor__perf_8h_source.html">Go to the source code of this file.</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 id="header-nested-classes" class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:MemoryPool_3C_20T_20_3E" id="r_MemoryPool_3C_20T_20_3E"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classMemoryPool.html">MemoryPool&lt; T &gt;</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Thread-safe memory pool for efficient tensor allocation.  <a href="classMemoryPool.html#details">More...</a><br /></td></tr>
<tr class="memitem:MemoryPool_3C_20T_20_3E_3A_3ABlock" id="r_MemoryPool_3C_20T_20_3E_3A_3ABlock"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structMemoryPool_1_1Block.html">MemoryPool&lt; T &gt;::Block</a></td></tr>
<tr class="memitem:ThreadPool" id="r_ThreadPool"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classThreadPool.html">ThreadPool</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Thread pool for parallel tensor operations.  <a href="classThreadPool.html#details">More...</a><br /></td></tr>
<tr class="memitem:Float16" id="r_Float16"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structFloat16.html">Float16</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">IEEE 754 half-precision floating-point (FP16).  <a href="structFloat16.html#details">More...</a><br /></td></tr>
<tr class="memitem:BFloat16" id="r_BFloat16"><td class="memItemLeft" align="right" valign="top">struct &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="structBFloat16.html">BFloat16</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Brain floating-point (BF16).  <a href="structBFloat16.html#details">More...</a><br /></td></tr>
<tr class="memitem:LazyOperation_3C_20T_2C_20N_20_3E" id="r_LazyOperation_3C_20T_2C_20N_20_3E"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classLazyOperation.html">LazyOperation&lt; T, N &gt;</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Represents a deferred tensor operation.  <a href="classLazyOperation.html#details">More...</a><br /></td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 id="header-enum-members" class="groupheader"><a id="enum-members" name="enum-members"></a>
Enumerations</h2></td></tr>
<tr class="memitem:a9a2c9c31d675b34f6ec35cc1ca89e047" id="r_a9a2c9c31d675b34f6ec35cc1ca89e047"><td class="memItemLeft" align="right" valign="top">enum class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a9a2c9c31d675b34f6ec35cc1ca89e047">OperationType</a> { <br />
&#160;&#160;<a class="el" href="#a9a2c9c31d675b34f6ec35cc1ca89e047a6adf97f83acf6453d4a6a4b1070f3754">None</a>
, <a class="el" href="#a9a2c9c31d675b34f6ec35cc1ca89e047aec211f7c20af43e742bf2570c3cb84f9">Add</a>
, <a class="el" href="#a9a2c9c31d675b34f6ec35cc1ca89e047a1d9baf077ee87921f57a8fe42d510b65">Subtract</a>
, <a class="el" href="#a9a2c9c31d675b34f6ec35cc1ca89e047ae257376d913f3b53cbb4a9b19d770648">Multiply</a>
, <br />
&#160;&#160;<a class="el" href="#a9a2c9c31d675b34f6ec35cc1ca89e047a0b914e196182d02615487e9793ecff3d">Divide</a>
, <a class="el" href="#a9a2c9c31d675b34f6ec35cc1ca89e047acad39a154bffb61175f674d6eefaf6d0">Exp</a>
, <a class="el" href="#a9a2c9c31d675b34f6ec35cc1ca89e047ace0be71e33226e4c1db2bcea5959f16b">Log</a>
, <a class="el" href="#a9a2c9c31d675b34f6ec35cc1ca89e047aae77f3ad25595e35b327334d89410054">Sqrt</a>
, <br />
&#160;&#160;<a class="el" href="#a9a2c9c31d675b34f6ec35cc1ca89e047a0986d137604183312e6d3599578bc6cd">Sin</a>
, <a class="el" href="#a9a2c9c31d675b34f6ec35cc1ca89e047affca562be079b9e4e41ea9d6a86c582b">Cos</a>
, <a class="el" href="#a9a2c9c31d675b34f6ec35cc1ca89e047acc132a41cab5676334f353a22a0aa5c5">Tanh</a>
, <a class="el" href="#a9a2c9c31d675b34f6ec35cc1ca89e047a21eebb164e4b8b9bcf64fdb4d8d5dff4">Sigmoid</a>
, <br />
&#160;&#160;<a class="el" href="#a9a2c9c31d675b34f6ec35cc1ca89e047add10d919fa85cf27fc78c0e06fe0b378">ReLU</a>
<br />
 }</td></tr>
<tr class="memdesc:a9a2c9c31d675b34f6ec35cc1ca89e047"><td class="mdescLeft">&#160;</td><td class="mdescRight">Types of deferred operations for lazy evaluation.  <a href="#a9a2c9c31d675b34f6ec35cc1ca89e047">More...</a><br /></td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 id="header-func-members" class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:a1d35d3df85dfc709d12a9d7b25e44f6c" id="r_a1d35d3df85dfc709d12a9d7b25e44f6c"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:a1d35d3df85dfc709d12a9d7b25e44f6c template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classMemoryPool.html">MemoryPool</a>&lt; T &gt; &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a1d35d3df85dfc709d12a9d7b25e44f6c">get_memory_pool</a> ()</td></tr>
<tr class="memdesc:a1d35d3df85dfc709d12a9d7b25e44f6c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get global memory pool for a specific type.  <br /></td></tr>
<tr class="memitem:a19ac37b9274624b5a4c54bdd78a6c451" id="r_a19ac37b9274624b5a4c54bdd78a6c451"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classThreadPool.html">ThreadPool</a> &amp;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a19ac37b9274624b5a4c54bdd78a6c451">get_thread_pool</a> ()</td></tr>
<tr class="memdesc:a19ac37b9274624b5a4c54bdd78a6c451"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get global thread pool instance.  <br /></td></tr>
<tr class="memitem:ae153b382c70901f6a099c56efae1745d" id="r_ae153b382c70901f6a099c56efae1745d"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ae153b382c70901f6a099c56efae1745d">parallel_for</a> (size_t start, size_t end, std::function&lt; void(size_t)&gt; func, size_t min_per_thread=1000)</td></tr>
<tr class="memdesc:ae153b382c70901f6a099c56efae1745d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Parallel for loop using thread pool.  <br /></td></tr>
<tr class="memitem:aa1f51d301c3e6c23719bd19bbd2d9179" id="r_aa1f51d301c3e6c23719bd19bbd2d9179"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aa1f51d301c3e6c23719bd19bbd2d9179">convert_fp32_to_fp16</a> (const float *src, <a class="el" href="structFloat16.html">Float16</a> *dst, size_t count)</td></tr>
<tr class="memdesc:aa1f51d301c3e6c23719bd19bbd2d9179"><td class="mdescLeft">&#160;</td><td class="mdescRight">Convert array from FP32 to FP16.  <br /></td></tr>
<tr class="memitem:a9420b30c3a4a8e9e6db1f611c0948022" id="r_a9420b30c3a4a8e9e6db1f611c0948022"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a9420b30c3a4a8e9e6db1f611c0948022">convert_fp16_to_fp32</a> (const <a class="el" href="structFloat16.html">Float16</a> *src, float *dst, size_t count)</td></tr>
<tr class="memdesc:a9420b30c3a4a8e9e6db1f611c0948022"><td class="mdescLeft">&#160;</td><td class="mdescRight">Convert array from FP16 to FP32.  <br /></td></tr>
<tr class="memitem:a737436106bea15bb2d93bf83022129af" id="r_a737436106bea15bb2d93bf83022129af"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a737436106bea15bb2d93bf83022129af">convert_fp32_to_bf16</a> (const float *src, <a class="el" href="structBFloat16.html">BFloat16</a> *dst, size_t count)</td></tr>
<tr class="memdesc:a737436106bea15bb2d93bf83022129af"><td class="mdescLeft">&#160;</td><td class="mdescRight">Convert array from FP32 to BF16.  <br /></td></tr>
<tr class="memitem:a866251af0f73ed0228b075f2856c29fb" id="r_a866251af0f73ed0228b075f2856c29fb"><td class="memItemLeft" align="right" valign="top">void&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a866251af0f73ed0228b075f2856c29fb">convert_bf16_to_fp32</a> (const <a class="el" href="structBFloat16.html">BFloat16</a> *src, float *dst, size_t count)</td></tr>
<tr class="memdesc:a866251af0f73ed0228b075f2856c29fb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Convert array from BF16 to FP32.  <br /></td></tr>
<tr class="memitem:a83fcc629625234fab47be405a272f4c5" id="r_a83fcc629625234fab47be405a272f4c5"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:a83fcc629625234fab47be405a272f4c5 template"><td class="memItemLeft" align="right" valign="top">std::function&lt; void(T *, const T *, size_t)&gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a83fcc629625234fab47be405a272f4c5">fuse_operations</a> (const std::vector&lt; <a class="el" href="#a9a2c9c31d675b34f6ec35cc1ca89e047">OperationType</a> &gt; &amp;ops)</td></tr>
<tr class="memdesc:a83fcc629625234fab47be405a272f4c5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create fused element-wise operation.  <br /></td></tr>
</table>
<a name="details" id="details"></a><h2 id="header-details" class="groupheader">Detailed Description</h2>
<div class="textblock"><p>Performance optimization features for tensor operations. </p>
<p>This header provides advanced performance optimization features:</p><ul>
<li>Memory pooling for reduced allocation overhead</li>
<li>Multi-threading utilities for CPU operations</li>
<li>Mixed precision support (FP16, BF16)</li>
<li>Lazy evaluation for operation fusion</li>
</ul>
<dl class="section author"><dt>Author</dt><dd><a class="el" href="classTensor.html" title="Forward declaration for autograd.">Tensor</a> Library Team </dd></dl>
<dl class="section version"><dt>Version</dt><dd>1.0 </dd></dl>
<dl class="section date"><dt>Date</dt><dd>2024 </dd></dl>

<p class="definition">Definition in file <a class="el" href="tensor__perf_8h_source.html">tensor_perf.h</a>.</p>
</div><a name="doc-enum-members" id="doc-enum-members"></a><h2 id="header-doc-enum-members" class="groupheader">Enumeration Type Documentation</h2>
<a id="a9a2c9c31d675b34f6ec35cc1ca89e047" name="a9a2c9c31d675b34f6ec35cc1ca89e047"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9a2c9c31d675b34f6ec35cc1ca89e047">&#9670;&#160;</a></span>OperationType</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">enum class <a class="el" href="#a9a2c9c31d675b34f6ec35cc1ca89e047">OperationType</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel strong">strong</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Types of deferred operations for lazy evaluation. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="a9a2c9c31d675b34f6ec35cc1ca89e047a6adf97f83acf6453d4a6a4b1070f3754" name="a9a2c9c31d675b34f6ec35cc1ca89e047a6adf97f83acf6453d4a6a4b1070f3754"></a>None&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a9a2c9c31d675b34f6ec35cc1ca89e047aec211f7c20af43e742bf2570c3cb84f9" name="a9a2c9c31d675b34f6ec35cc1ca89e047aec211f7c20af43e742bf2570c3cb84f9"></a>Add&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a9a2c9c31d675b34f6ec35cc1ca89e047a1d9baf077ee87921f57a8fe42d510b65" name="a9a2c9c31d675b34f6ec35cc1ca89e047a1d9baf077ee87921f57a8fe42d510b65"></a>Subtract&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a9a2c9c31d675b34f6ec35cc1ca89e047ae257376d913f3b53cbb4a9b19d770648" name="a9a2c9c31d675b34f6ec35cc1ca89e047ae257376d913f3b53cbb4a9b19d770648"></a>Multiply&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a9a2c9c31d675b34f6ec35cc1ca89e047a0b914e196182d02615487e9793ecff3d" name="a9a2c9c31d675b34f6ec35cc1ca89e047a0b914e196182d02615487e9793ecff3d"></a>Divide&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a9a2c9c31d675b34f6ec35cc1ca89e047acad39a154bffb61175f674d6eefaf6d0" name="a9a2c9c31d675b34f6ec35cc1ca89e047acad39a154bffb61175f674d6eefaf6d0"></a>Exp&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a9a2c9c31d675b34f6ec35cc1ca89e047ace0be71e33226e4c1db2bcea5959f16b" name="a9a2c9c31d675b34f6ec35cc1ca89e047ace0be71e33226e4c1db2bcea5959f16b"></a>Log&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a9a2c9c31d675b34f6ec35cc1ca89e047aae77f3ad25595e35b327334d89410054" name="a9a2c9c31d675b34f6ec35cc1ca89e047aae77f3ad25595e35b327334d89410054"></a>Sqrt&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a9a2c9c31d675b34f6ec35cc1ca89e047a0986d137604183312e6d3599578bc6cd" name="a9a2c9c31d675b34f6ec35cc1ca89e047a0986d137604183312e6d3599578bc6cd"></a>Sin&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a9a2c9c31d675b34f6ec35cc1ca89e047affca562be079b9e4e41ea9d6a86c582b" name="a9a2c9c31d675b34f6ec35cc1ca89e047affca562be079b9e4e41ea9d6a86c582b"></a>Cos&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a9a2c9c31d675b34f6ec35cc1ca89e047acc132a41cab5676334f353a22a0aa5c5" name="a9a2c9c31d675b34f6ec35cc1ca89e047acc132a41cab5676334f353a22a0aa5c5"></a>Tanh&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a9a2c9c31d675b34f6ec35cc1ca89e047a21eebb164e4b8b9bcf64fdb4d8d5dff4" name="a9a2c9c31d675b34f6ec35cc1ca89e047a21eebb164e4b8b9bcf64fdb4d8d5dff4"></a>Sigmoid&#160;</td><td class="fielddoc"></td></tr>
<tr><td class="fieldname"><a id="a9a2c9c31d675b34f6ec35cc1ca89e047add10d919fa85cf27fc78c0e06fe0b378" name="a9a2c9c31d675b34f6ec35cc1ca89e047add10d919fa85cf27fc78c0e06fe0b378"></a>ReLU&#160;</td><td class="fielddoc"></td></tr>
</table>

<p class="definition">Definition at line <a class="el" href="tensor__perf_8h_source.html#l00502">502</a> of file <a class="el" href="tensor__perf_8h_source.html">tensor_perf.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  502</span>                         {</div>
<div class="line"><span class="lineno">  503</span>    <a class="code hl_enumvalue" href="#a9a2c9c31d675b34f6ec35cc1ca89e047a6adf97f83acf6453d4a6a4b1070f3754">None</a>,</div>
<div class="line"><span class="lineno">  504</span>    <a class="code hl_enumvalue" href="#a9a2c9c31d675b34f6ec35cc1ca89e047aec211f7c20af43e742bf2570c3cb84f9">Add</a>,</div>
<div class="line"><span class="lineno">  505</span>    <a class="code hl_enumvalue" href="#a9a2c9c31d675b34f6ec35cc1ca89e047a1d9baf077ee87921f57a8fe42d510b65">Subtract</a>,</div>
<div class="line"><span class="lineno">  506</span>    <a class="code hl_enumvalue" href="#a9a2c9c31d675b34f6ec35cc1ca89e047ae257376d913f3b53cbb4a9b19d770648">Multiply</a>,</div>
<div class="line"><span class="lineno">  507</span>    <a class="code hl_enumvalue" href="#a9a2c9c31d675b34f6ec35cc1ca89e047a0b914e196182d02615487e9793ecff3d">Divide</a>,</div>
<div class="line"><span class="lineno">  508</span>    <a class="code hl_enumvalue" href="#a9a2c9c31d675b34f6ec35cc1ca89e047acad39a154bffb61175f674d6eefaf6d0">Exp</a>,</div>
<div class="line"><span class="lineno">  509</span>    <a class="code hl_enumvalue" href="#a9a2c9c31d675b34f6ec35cc1ca89e047ace0be71e33226e4c1db2bcea5959f16b">Log</a>,</div>
<div class="line"><span class="lineno">  510</span>    <a class="code hl_enumvalue" href="#a9a2c9c31d675b34f6ec35cc1ca89e047aae77f3ad25595e35b327334d89410054">Sqrt</a>,</div>
<div class="line"><span class="lineno">  511</span>    <a class="code hl_enumvalue" href="#a9a2c9c31d675b34f6ec35cc1ca89e047a0986d137604183312e6d3599578bc6cd">Sin</a>,</div>
<div class="line"><span class="lineno">  512</span>    <a class="code hl_enumvalue" href="#a9a2c9c31d675b34f6ec35cc1ca89e047affca562be079b9e4e41ea9d6a86c582b">Cos</a>,</div>
<div class="line"><span class="lineno">  513</span>    <a class="code hl_enumvalue" href="#a9a2c9c31d675b34f6ec35cc1ca89e047acc132a41cab5676334f353a22a0aa5c5">Tanh</a>,</div>
<div class="line"><span class="lineno">  514</span>    <a class="code hl_enumvalue" href="#a9a2c9c31d675b34f6ec35cc1ca89e047a21eebb164e4b8b9bcf64fdb4d8d5dff4">Sigmoid</a>,</div>
<div class="line"><span class="lineno">  515</span>    <a class="code hl_enumvalue" href="#a9a2c9c31d675b34f6ec35cc1ca89e047add10d919fa85cf27fc78c0e06fe0b378">ReLU</a></div>
<div class="line"><span class="lineno">  516</span>};</div>
<div class="ttc" id="atensor__perf_8h_html_a9a2c9c31d675b34f6ec35cc1ca89e047a0986d137604183312e6d3599578bc6cd"><div class="ttname"><a href="#a9a2c9c31d675b34f6ec35cc1ca89e047a0986d137604183312e6d3599578bc6cd">OperationType::Sin</a></div><div class="ttdeci">@ Sin</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00511">tensor_perf.h:511</a></div></div>
<div class="ttc" id="atensor__perf_8h_html_a9a2c9c31d675b34f6ec35cc1ca89e047a0b914e196182d02615487e9793ecff3d"><div class="ttname"><a href="#a9a2c9c31d675b34f6ec35cc1ca89e047a0b914e196182d02615487e9793ecff3d">OperationType::Divide</a></div><div class="ttdeci">@ Divide</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00507">tensor_perf.h:507</a></div></div>
<div class="ttc" id="atensor__perf_8h_html_a9a2c9c31d675b34f6ec35cc1ca89e047a1d9baf077ee87921f57a8fe42d510b65"><div class="ttname"><a href="#a9a2c9c31d675b34f6ec35cc1ca89e047a1d9baf077ee87921f57a8fe42d510b65">OperationType::Subtract</a></div><div class="ttdeci">@ Subtract</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00505">tensor_perf.h:505</a></div></div>
<div class="ttc" id="atensor__perf_8h_html_a9a2c9c31d675b34f6ec35cc1ca89e047a21eebb164e4b8b9bcf64fdb4d8d5dff4"><div class="ttname"><a href="#a9a2c9c31d675b34f6ec35cc1ca89e047a21eebb164e4b8b9bcf64fdb4d8d5dff4">OperationType::Sigmoid</a></div><div class="ttdeci">@ Sigmoid</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00514">tensor_perf.h:514</a></div></div>
<div class="ttc" id="atensor__perf_8h_html_a9a2c9c31d675b34f6ec35cc1ca89e047a6adf97f83acf6453d4a6a4b1070f3754"><div class="ttname"><a href="#a9a2c9c31d675b34f6ec35cc1ca89e047a6adf97f83acf6453d4a6a4b1070f3754">OperationType::None</a></div><div class="ttdeci">@ None</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00503">tensor_perf.h:503</a></div></div>
<div class="ttc" id="atensor__perf_8h_html_a9a2c9c31d675b34f6ec35cc1ca89e047aae77f3ad25595e35b327334d89410054"><div class="ttname"><a href="#a9a2c9c31d675b34f6ec35cc1ca89e047aae77f3ad25595e35b327334d89410054">OperationType::Sqrt</a></div><div class="ttdeci">@ Sqrt</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00510">tensor_perf.h:510</a></div></div>
<div class="ttc" id="atensor__perf_8h_html_a9a2c9c31d675b34f6ec35cc1ca89e047acad39a154bffb61175f674d6eefaf6d0"><div class="ttname"><a href="#a9a2c9c31d675b34f6ec35cc1ca89e047acad39a154bffb61175f674d6eefaf6d0">OperationType::Exp</a></div><div class="ttdeci">@ Exp</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00508">tensor_perf.h:508</a></div></div>
<div class="ttc" id="atensor__perf_8h_html_a9a2c9c31d675b34f6ec35cc1ca89e047acc132a41cab5676334f353a22a0aa5c5"><div class="ttname"><a href="#a9a2c9c31d675b34f6ec35cc1ca89e047acc132a41cab5676334f353a22a0aa5c5">OperationType::Tanh</a></div><div class="ttdeci">@ Tanh</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00513">tensor_perf.h:513</a></div></div>
<div class="ttc" id="atensor__perf_8h_html_a9a2c9c31d675b34f6ec35cc1ca89e047ace0be71e33226e4c1db2bcea5959f16b"><div class="ttname"><a href="#a9a2c9c31d675b34f6ec35cc1ca89e047ace0be71e33226e4c1db2bcea5959f16b">OperationType::Log</a></div><div class="ttdeci">@ Log</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00509">tensor_perf.h:509</a></div></div>
<div class="ttc" id="atensor__perf_8h_html_a9a2c9c31d675b34f6ec35cc1ca89e047add10d919fa85cf27fc78c0e06fe0b378"><div class="ttname"><a href="#a9a2c9c31d675b34f6ec35cc1ca89e047add10d919fa85cf27fc78c0e06fe0b378">OperationType::ReLU</a></div><div class="ttdeci">@ ReLU</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00515">tensor_perf.h:515</a></div></div>
<div class="ttc" id="atensor__perf_8h_html_a9a2c9c31d675b34f6ec35cc1ca89e047ae257376d913f3b53cbb4a9b19d770648"><div class="ttname"><a href="#a9a2c9c31d675b34f6ec35cc1ca89e047ae257376d913f3b53cbb4a9b19d770648">OperationType::Multiply</a></div><div class="ttdeci">@ Multiply</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00506">tensor_perf.h:506</a></div></div>
<div class="ttc" id="atensor__perf_8h_html_a9a2c9c31d675b34f6ec35cc1ca89e047aec211f7c20af43e742bf2570c3cb84f9"><div class="ttname"><a href="#a9a2c9c31d675b34f6ec35cc1ca89e047aec211f7c20af43e742bf2570c3cb84f9">OperationType::Add</a></div><div class="ttdeci">@ Add</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00504">tensor_perf.h:504</a></div></div>
<div class="ttc" id="atensor__perf_8h_html_a9a2c9c31d675b34f6ec35cc1ca89e047affca562be079b9e4e41ea9d6a86c582b"><div class="ttname"><a href="#a9a2c9c31d675b34f6ec35cc1ca89e047affca562be079b9e4e41ea9d6a86c582b">OperationType::Cos</a></div><div class="ttdeci">@ Cos</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00512">tensor_perf.h:512</a></div></div>
</div><!-- fragment -->
</div>
</div>
<a name="doc-func-members" id="doc-func-members"></a><h2 id="header-doc-func-members" class="groupheader">Function Documentation</h2>
<a id="a866251af0f73ed0228b075f2856c29fb" name="a866251af0f73ed0228b075f2856c29fb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a866251af0f73ed0228b075f2856c29fb">&#9670;&#160;</a></span>convert_bf16_to_fp32()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void convert_bf16_to_fp32 </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structBFloat16.html">BFloat16</a> *</td>          <td class="paramname"><span class="paramname"><em>src</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *</td>          <td class="paramname"><span class="paramname"><em>dst</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>count</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Convert array from BF16 to FP32. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">src</td><td>Source BF16 array </td></tr>
    <tr><td class="paramname">dst</td><td>Destination FP32 array </td></tr>
    <tr><td class="paramname">count</td><td>Number of elements </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="tensor__perf_8h_source.html#l00488">488</a> of file <a class="el" href="tensor__perf_8h_source.html">tensor_perf.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  488</span>                                                                                {</div>
<div class="line"><span class="lineno">  489</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; count; ++i) {</div>
<div class="line"><span class="lineno">  490</span>        dst[i] = src[i].<a class="code hl_function" href="structBFloat16.html#aa0615d97d0b211fa5a2b96318c31c5f5">to_float</a>();</div>
<div class="line"><span class="lineno">  491</span>    }</div>
<div class="line"><span class="lineno">  492</span>}</div>
<div class="ttc" id="astructBFloat16_html_aa0615d97d0b211fa5a2b96318c31c5f5"><div class="ttname"><a href="structBFloat16.html#aa0615d97d0b211fa5a2b96318c31c5f5">BFloat16::to_float</a></div><div class="ttdeci">float to_float() const</div><div class="ttdoc">Convert to float.</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00436">tensor_perf.h:436</a></div></div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor__perf_8h_a866251af0f73ed0228b075f2856c29fb_cgraph.png" border="0" usemap="#atensor__perf_8h_a866251af0f73ed0228b075f2856c29fb_cgraph" loading="lazy" alt=""/></div>
<map name="atensor__perf_8h_a866251af0f73ed0228b075f2856c29fb_cgraph" id="atensor__perf_8h_a866251af0f73ed0228b075f2856c29fb_cgraph">
<area shape="rect" title="Convert array from BF16 to FP32." alt="" coords="5,5,152,32"/>
<area shape="rect" href="structBFloat16.html#aa0615d97d0b211fa5a2b96318c31c5f5" title="Convert to float." alt="" coords="200,5,324,32"/>
<area shape="poly" title=" " alt="" coords="152,16,184,16,184,21,152,21"/>
</map>
</div>

</div>
</div>
<a id="a9420b30c3a4a8e9e6db1f611c0948022" name="a9420b30c3a4a8e9e6db1f611c0948022"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9420b30c3a4a8e9e6db1f611c0948022">&#9670;&#160;</a></span>convert_fp16_to_fp32()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void convert_fp16_to_fp32 </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="structFloat16.html">Float16</a> *</td>          <td class="paramname"><span class="paramname"><em>src</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">float *</td>          <td class="paramname"><span class="paramname"><em>dst</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>count</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Convert array from FP16 to FP32. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">src</td><td>Source FP16 array </td></tr>
    <tr><td class="paramname">dst</td><td>Destination FP32 array </td></tr>
    <tr><td class="paramname">count</td><td>Number of elements </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="tensor__perf_8h_source.html#l00464">464</a> of file <a class="el" href="tensor__perf_8h_source.html">tensor_perf.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  464</span>                                                                               {</div>
<div class="line"><span class="lineno">  465</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; count; ++i) {</div>
<div class="line"><span class="lineno">  466</span>        dst[i] = src[i].<a class="code hl_function" href="structFloat16.html#ae615553575ed3ef5efb0f9c3faf6d9b9">to_float</a>();</div>
<div class="line"><span class="lineno">  467</span>    }</div>
<div class="line"><span class="lineno">  468</span>}</div>
<div class="ttc" id="astructFloat16_html_ae615553575ed3ef5efb0f9c3faf6d9b9"><div class="ttname"><a href="structFloat16.html#ae615553575ed3ef5efb0f9c3faf6d9b9">Float16::to_float</a></div><div class="ttdeci">float to_float() const</div><div class="ttdoc">Convert to float.</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00380">tensor_perf.h:380</a></div></div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor__perf_8h_a9420b30c3a4a8e9e6db1f611c0948022_cgraph.png" border="0" usemap="#atensor__perf_8h_a9420b30c3a4a8e9e6db1f611c0948022_cgraph" loading="lazy" alt=""/></div>
<map name="atensor__perf_8h_a9420b30c3a4a8e9e6db1f611c0948022_cgraph" id="atensor__perf_8h_a9420b30c3a4a8e9e6db1f611c0948022_cgraph">
<area shape="rect" title="Convert array from FP16 to FP32." alt="" coords="5,5,152,32"/>
<area shape="rect" href="structFloat16.html#ae615553575ed3ef5efb0f9c3faf6d9b9" title="Convert to float." alt="" coords="200,5,315,32"/>
<area shape="poly" title=" " alt="" coords="152,16,184,16,184,21,152,21"/>
</map>
</div>

</div>
</div>
<a id="a737436106bea15bb2d93bf83022129af" name="a737436106bea15bb2d93bf83022129af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a737436106bea15bb2d93bf83022129af">&#9670;&#160;</a></span>convert_fp32_to_bf16()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void convert_fp32_to_bf16 </td>
          <td>(</td>
          <td class="paramtype">const float *</td>          <td class="paramname"><span class="paramname"><em>src</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structBFloat16.html">BFloat16</a> *</td>          <td class="paramname"><span class="paramname"><em>dst</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>count</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Convert array from FP32 to BF16. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">src</td><td>Source FP32 array </td></tr>
    <tr><td class="paramname">dst</td><td>Destination BF16 array </td></tr>
    <tr><td class="paramname">count</td><td>Number of elements </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="tensor__perf_8h_source.html#l00476">476</a> of file <a class="el" href="tensor__perf_8h_source.html">tensor_perf.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  476</span>                                                                                {</div>
<div class="line"><span class="lineno">  477</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; count; ++i) {</div>
<div class="line"><span class="lineno">  478</span>        dst[i] = <a class="code hl_struct" href="structBFloat16.html">BFloat16</a>(src[i]);</div>
<div class="line"><span class="lineno">  479</span>    }</div>
<div class="line"><span class="lineno">  480</span>}</div>
<div class="ttc" id="astructBFloat16_html"><div class="ttname"><a href="structBFloat16.html">BFloat16</a></div><div class="ttdoc">Brain floating-point (BF16).</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00413">tensor_perf.h:413</a></div></div>
</div><!-- fragment -->
</div>
</div>
<a id="aa1f51d301c3e6c23719bd19bbd2d9179" name="aa1f51d301c3e6c23719bd19bbd2d9179"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa1f51d301c3e6c23719bd19bbd2d9179">&#9670;&#160;</a></span>convert_fp32_to_fp16()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void convert_fp32_to_fp16 </td>
          <td>(</td>
          <td class="paramtype">const float *</td>          <td class="paramname"><span class="paramname"><em>src</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype"><a class="el" href="structFloat16.html">Float16</a> *</td>          <td class="paramname"><span class="paramname"><em>dst</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>count</em></span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Convert array from FP32 to FP16. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">src</td><td>Source FP32 array </td></tr>
    <tr><td class="paramname">dst</td><td>Destination FP16 array </td></tr>
    <tr><td class="paramname">count</td><td>Number of elements </td></tr>
  </table>
  </dd>
</dl>

<p class="definition">Definition at line <a class="el" href="tensor__perf_8h_source.html#l00452">452</a> of file <a class="el" href="tensor__perf_8h_source.html">tensor_perf.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  452</span>                                                                               {</div>
<div class="line"><span class="lineno">  453</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; count; ++i) {</div>
<div class="line"><span class="lineno">  454</span>        dst[i] = <a class="code hl_struct" href="structFloat16.html">Float16</a>(src[i]);</div>
<div class="line"><span class="lineno">  455</span>    }</div>
<div class="line"><span class="lineno">  456</span>}</div>
<div class="ttc" id="astructFloat16_html"><div class="ttname"><a href="structFloat16.html">Float16</a></div><div class="ttdoc">IEEE 754 half-precision floating-point (FP16).</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00347">tensor_perf.h:347</a></div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a83fcc629625234fab47be405a272f4c5" name="a83fcc629625234fab47be405a272f4c5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a83fcc629625234fab47be405a272f4c5">&#9670;&#160;</a></span>fuse_operations()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">std::function&lt; void(T *, const T *, size_t)&gt; fuse_operations </td>
          <td>(</td>
          <td class="paramtype">const std::vector&lt; <a class="el" href="#a9a2c9c31d675b34f6ec35cc1ca89e047">OperationType</a> &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>ops</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create fused element-wise operation. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>Data type </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">ops</td><td><a class="el" href="linalg_8h.html#a99ba6a0becc538dc0109d3818ca80f3b" title="Type alias for 1D vectors.">Vector</a> of operations to fuse </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Fused operation function</dd></dl>
<p>Combines multiple element-wise operations into a single pass to improve cache utilization and reduce memory bandwidth. </p>

<p class="definition">Definition at line <a class="el" href="tensor__perf_8h_source.html#l00575">575</a> of file <a class="el" href="tensor__perf_8h_source.html">tensor_perf.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  575</span>                                                     {</div>
<div class="line"><span class="lineno">  576</span>    <span class="keywordflow">return</span> [ops](T* dst, <span class="keyword">const</span> T* src, <span class="keywordtype">size_t</span> size) {</div>
<div class="line"><span class="lineno">  577</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; size; ++i) {</div>
<div class="line"><span class="lineno">  578</span>            T val = src[i];</div>
<div class="line"><span class="lineno">  579</span>            <span class="keywordflow">for</span> (<span class="keyword">auto</span> op : ops) {</div>
<div class="line"><span class="lineno">  580</span>                <span class="keywordflow">switch</span> (op) {</div>
<div class="line"><span class="lineno">  581</span>                    <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="#a9a2c9c31d675b34f6ec35cc1ca89e047acad39a154bffb61175f674d6eefaf6d0">OperationType::Exp</a>:</div>
<div class="line"><span class="lineno">  582</span>                        val = std::exp(val);</div>
<div class="line"><span class="lineno">  583</span>                        <span class="keywordflow">break</span>;</div>
<div class="line"><span class="lineno">  584</span>                    <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="#a9a2c9c31d675b34f6ec35cc1ca89e047acc132a41cab5676334f353a22a0aa5c5">OperationType::Tanh</a>:</div>
<div class="line"><span class="lineno">  585</span>                        val = std::tanh(val);</div>
<div class="line"><span class="lineno">  586</span>                        <span class="keywordflow">break</span>;</div>
<div class="line"><span class="lineno">  587</span>                    <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="#a9a2c9c31d675b34f6ec35cc1ca89e047a21eebb164e4b8b9bcf64fdb4d8d5dff4">OperationType::Sigmoid</a>:</div>
<div class="line"><span class="lineno">  588</span>                        val = T(1) / (T(1) + std::exp(-val));</div>
<div class="line"><span class="lineno">  589</span>                        <span class="keywordflow">break</span>;</div>
<div class="line"><span class="lineno">  590</span>                    <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="#a9a2c9c31d675b34f6ec35cc1ca89e047add10d919fa85cf27fc78c0e06fe0b378">OperationType::ReLU</a>:</div>
<div class="line"><span class="lineno">  591</span>                        val = std::max(T(0), val);</div>
<div class="line"><span class="lineno">  592</span>                        <span class="keywordflow">break</span>;</div>
<div class="line"><span class="lineno">  593</span>                    <span class="keywordflow">default</span>:</div>
<div class="line"><span class="lineno">  594</span>                        <span class="keywordflow">break</span>;</div>
<div class="line"><span class="lineno">  595</span>                }</div>
<div class="line"><span class="lineno">  596</span>            }</div>
<div class="line"><span class="lineno">  597</span>            dst[i] = val;</div>
<div class="line"><span class="lineno">  598</span>        }</div>
<div class="line"><span class="lineno">  599</span>    };</div>
<div class="line"><span class="lineno">  600</span>}</div>
</div><!-- fragment -->
</div>
</div>
<a id="a1d35d3df85dfc709d12a9d7b25e44f6c" name="a1d35d3df85dfc709d12a9d7b25e44f6c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1d35d3df85dfc709d12a9d7b25e44f6c">&#9670;&#160;</a></span>get_memory_pool()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classMemoryPool.html">MemoryPool</a>&lt; T &gt; &amp; get_memory_pool </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Get global memory pool for a specific type. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>Data type </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Reference to the global memory pool for type T</dd></dl>
<p>Provides a singleton memory pool instance per type. </p>

<p class="definition">Definition at line <a class="el" href="tensor__perf_8h_source.html#l00159">159</a> of file <a class="el" href="tensor__perf_8h_source.html">tensor_perf.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  159</span>                                 {</div>
<div class="line"><span class="lineno">  160</span>    <span class="keyword">static</span> <a class="code hl_class" href="classMemoryPool.html">MemoryPool&lt;T&gt;</a> pool;</div>
<div class="line"><span class="lineno">  161</span>    <span class="keywordflow">return</span> pool;</div>
<div class="line"><span class="lineno">  162</span>}</div>
<div class="ttc" id="aclassMemoryPool_html"><div class="ttname"><a href="classMemoryPool.html">MemoryPool</a></div><div class="ttdoc">Thread-safe memory pool for efficient tensor allocation.</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00051">tensor_perf.h:51</a></div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a19ac37b9274624b5a4c54bdd78a6c451" name="a19ac37b9274624b5a4c54bdd78a6c451"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a19ac37b9274624b5a4c54bdd78a6c451">&#9670;&#160;</a></span>get_thread_pool()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classThreadPool.html">ThreadPool</a> &amp; get_thread_pool </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get global thread pool instance. </p>
<dl class="section return"><dt>Returns</dt><dd>Reference to the global thread pool </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor__perf_8h_source.html#l00274">274</a> of file <a class="el" href="tensor__perf_8h_source.html">tensor_perf.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  274</span>                                     {</div>
<div class="line"><span class="lineno">  275</span>    <span class="keyword">static</span> <a class="code hl_class" href="classThreadPool.html">ThreadPool</a> pool;</div>
<div class="line"><span class="lineno">  276</span>    <span class="keywordflow">return</span> pool;</div>
<div class="line"><span class="lineno">  277</span>}</div>
<div class="ttc" id="aclassThreadPool_html"><div class="ttname"><a href="classThreadPool.html">ThreadPool</a></div><div class="ttdoc">Thread pool for parallel tensor operations.</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00181">tensor_perf.h:181</a></div></div>
</div><!-- fragment --><div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor__perf_8h_a19ac37b9274624b5a4c54bdd78a6c451_icgraph.png" border="0" usemap="#atensor__perf_8h_a19ac37b9274624b5a4c54bdd78a6c451_icgraph" loading="lazy" alt=""/></div>
<map name="atensor__perf_8h_a19ac37b9274624b5a4c54bdd78a6c451_icgraph" id="atensor__perf_8h_a19ac37b9274624b5a4c54bdd78a6c451_icgraph">
<area shape="rect" title="Get global thread pool instance." alt="" coords="138,5,251,32"/>
<area shape="rect" href="tensor__perf_8h.html#ae153b382c70901f6a099c56efae1745d" title="Parallel for loop using thread pool." alt="" coords="5,5,90,32"/>
<area shape="poly" title=" " alt="" coords="122,21,90,21,90,16,122,16"/>
</map>
</div>

</div>
</div>
<a id="ae153b382c70901f6a099c56efae1745d" name="ae153b382c70901f6a099c56efae1745d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae153b382c70901f6a099c56efae1745d">&#9670;&#160;</a></span>parallel_for()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">void parallel_for </td>
          <td>(</td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>start</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>end</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::function&lt; void(size_t)&gt;</td>          <td class="paramname"><span class="paramname"><em>func</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>min_per_thread</em></span><span class="paramdefsep"> = </span><span class="paramdefval">1000</span>&#160;)</td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Parallel for loop using thread pool. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">start</td><td>Start index (inclusive) </td></tr>
    <tr><td class="paramname">end</td><td>End index (exclusive) </td></tr>
    <tr><td class="paramname">func</td><td>Function to execute for each index </td></tr>
    <tr><td class="paramname">min_per_thread</td><td>Minimum iterations per thread (default: 1000)</td></tr>
  </table>
  </dd>
</dl>
<p>Divides work among threads in the thread pool.</p>
<div class="fragment"><div class="line"><a class="code hl_function" href="#ae153b382c70901f6a099c56efae1745d">parallel_for</a>(0, 1000000, [&amp;](<span class="keywordtype">size_t</span> i) {</div>
<div class="line">    data[i] = compute(i);</div>
<div class="line">});</div>
<div class="ttc" id="atensor__perf_8h_html_ae153b382c70901f6a099c56efae1745d"><div class="ttname"><a href="#ae153b382c70901f6a099c56efae1745d">parallel_for</a></div><div class="ttdeci">void parallel_for(size_t start, size_t end, std::function&lt; void(size_t)&gt; func, size_t min_per_thread=1000)</div><div class="ttdoc">Parallel for loop using thread pool.</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00294">tensor_perf.h:294</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="tensor__perf_8h_source.html#l00294">294</a> of file <a class="el" href="tensor__perf_8h_source.html">tensor_perf.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  296</span>                                                      {</div>
<div class="line"><span class="lineno">  297</span>    <span class="keywordtype">size_t</span> range = end - start;</div>
<div class="line"><span class="lineno">  298</span>    <span class="keywordflow">if</span> (range &lt; min_per_thread) {</div>
<div class="line"><span class="lineno">  299</span>        <span class="comment">// Not worth parallelizing</span></div>
<div class="line"><span class="lineno">  300</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = start; i &lt; end; ++i) {</div>
<div class="line"><span class="lineno">  301</span>            func(i);</div>
<div class="line"><span class="lineno">  302</span>        }</div>
<div class="line"><span class="lineno">  303</span>        <span class="keywordflow">return</span>;</div>
<div class="line"><span class="lineno">  304</span>    }</div>
<div class="line"><span class="lineno">  305</span>    </div>
<div class="line"><span class="lineno">  306</span>    <span class="keyword">auto</span>&amp; pool = <a class="code hl_function" href="#a19ac37b9274624b5a4c54bdd78a6c451">get_thread_pool</a>();</div>
<div class="line"><span class="lineno">  307</span>    <span class="keywordtype">size_t</span> num_threads = std::min(range / min_per_thread, pool.size());</div>
<div class="line"><span class="lineno">  308</span>    </div>
<div class="line"><span class="lineno">  309</span>    <span class="keywordflow">if</span> (num_threads &lt;= 1) {</div>
<div class="line"><span class="lineno">  310</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = start; i &lt; end; ++i) {</div>
<div class="line"><span class="lineno">  311</span>            func(i);</div>
<div class="line"><span class="lineno">  312</span>        }</div>
<div class="line"><span class="lineno">  313</span>        <span class="keywordflow">return</span>;</div>
<div class="line"><span class="lineno">  314</span>    }</div>
<div class="line"><span class="lineno">  315</span>    </div>
<div class="line"><span class="lineno">  316</span>    <span class="keywordtype">size_t</span> chunk_size = range / num_threads;</div>
<div class="line"><span class="lineno">  317</span>    std::vector&lt;std::future&lt;void&gt;&gt; futures;</div>
<div class="line"><span class="lineno">  318</span>    </div>
<div class="line"><span class="lineno">  319</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> t = 0; t &lt; num_threads; ++t) {</div>
<div class="line"><span class="lineno">  320</span>        <span class="keywordtype">size_t</span> chunk_start = start + t * chunk_size;</div>
<div class="line"><span class="lineno">  321</span>        <span class="keywordtype">size_t</span> chunk_end = (t == num_threads - 1) ? end : chunk_start + chunk_size;</div>
<div class="line"><span class="lineno">  322</span>        </div>
<div class="line"><span class="lineno">  323</span>        futures.push_back(pool.enqueue([chunk_start, chunk_end, &amp;func]() {</div>
<div class="line"><span class="lineno">  324</span>            for (size_t i = chunk_start; i &lt; chunk_end; ++i) {</div>
<div class="line"><span class="lineno">  325</span>                func(i);</div>
<div class="line"><span class="lineno">  326</span>            }</div>
<div class="line"><span class="lineno">  327</span>        }));</div>
<div class="line"><span class="lineno">  328</span>    }</div>
<div class="line"><span class="lineno">  329</span>    </div>
<div class="line"><span class="lineno">  330</span>    <span class="keywordflow">for</span> (<span class="keyword">auto</span>&amp; f : futures) {</div>
<div class="line"><span class="lineno">  331</span>        f.get();</div>
<div class="line"><span class="lineno">  332</span>    }</div>
<div class="line"><span class="lineno">  333</span>}</div>
<div class="ttc" id="atensor__perf_8h_html_a19ac37b9274624b5a4c54bdd78a6c451"><div class="ttname"><a href="#a19ac37b9274624b5a4c54bdd78a6c451">get_thread_pool</a></div><div class="ttdeci">ThreadPool &amp; get_thread_pool()</div><div class="ttdoc">Get global thread pool instance.</div><div class="ttdef"><b>Definition</b> <a href="tensor__perf_8h_source.html#l00274">tensor_perf.h:274</a></div></div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor__perf_8h_ae153b382c70901f6a099c56efae1745d_cgraph.png" border="0" usemap="#atensor__perf_8h_ae153b382c70901f6a099c56efae1745d_cgraph" loading="lazy" alt=""/></div>
<map name="atensor__perf_8h_ae153b382c70901f6a099c56efae1745d_cgraph" id="atensor__perf_8h_ae153b382c70901f6a099c56efae1745d_cgraph">
<area shape="rect" title="Parallel for loop using thread pool." alt="" coords="5,5,90,32"/>
<area shape="rect" href="tensor__perf_8h.html#a19ac37b9274624b5a4c54bdd78a6c451" title="Get global thread pool instance." alt="" coords="138,5,251,32"/>
<area shape="poly" title=" " alt="" coords="90,16,122,16,122,21,90,21"/>
</map>
</div>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<div id="page-nav" class="page-nav-panel">
<div id="page-nav-resize-handle"></div>
<div id="page-nav-tree">
<div id="page-nav-contents">
</div><!-- page-nav-contents -->
</div><!-- page-nav-tree -->
</div><!-- page-nav -->
</div><!-- container -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a href="tensor__perf_8h.html">tensor_perf.h</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.15.0 </li>
  </ul>
</div>
</body>
</html>
