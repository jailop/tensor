<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.15.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tensor Library: include/tensor.h File Reference</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tensor Library
   </div>
   <div id="projectbrief">High-performance C++ tensor library with GPU, BLAS, autograd, and linear algebra support</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.15.0 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search/",'.html');
</script>
<script type="text/javascript">
$(function() { codefold.init(); });
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search',true);
  $(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(function(){initNavTree('tensor_8h.html','',''); });
</script>
<div id="container">
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">tensor.h File Reference</div></div>
</div><!--header-->
<div class="contents">

<p>High-performance multi-dimensional tensor library with GPU, BLAS, and autograd support.  
<a href="#details">More...</a></p>
<div class="textblock"><code>#include &lt;cstddef&gt;</code><br />
<code>#include &lt;algorithm&gt;</code><br />
<code>#include &lt;memory&gt;</code><br />
<code>#include &lt;array&gt;</code><br />
<code>#include &lt;variant&gt;</code><br />
<code>#include &lt;type_traits&gt;</code><br />
<code>#include &lt;string&gt;</code><br />
<code>#include &lt;execution&gt;</code><br />
<code>#include &lt;span&gt;</code><br />
<code>#include &lt;ranges&gt;</code><br />
<code>#include &lt;cmath&gt;</code><br />
<code>#include &lt;optional&gt;</code><br />
<code>#include &lt;functional&gt;</code><br />
<code>#include &lt;vector&gt;</code><br />
<code>#include &lt;random&gt;</code><br />
<code>#include &quot;<a class="el" href="tensor__perf_8h_source.html">tensor_perf.h</a>&quot;</code><br />
</div><div class="textblock"><div class="dynheader">
Include dependency graph for tensor.h:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h__incl.png" border="0" usemap="#ainclude_2tensor_8h" loading="lazy" alt=""/></div>
<map name="ainclude_2tensor_8h" id="ainclude_2tensor_8h">
<area shape="rect" title="High&#45;performance multi&#45;dimensional tensor library with GPU, BLAS, and autograd support." alt="" coords="525,5,638,32"/>
<area shape="rect" title=" " alt="" coords="5,80,70,107"/>
<area shape="poly" title=" " alt="" coords="525,27,334,45,212,61,86,82,85,77,211,56,333,40,524,21"/>
<area shape="rect" title=" " alt="" coords="94,80,168,107"/>
<area shape="poly" title=" " alt="" coords="525,30,372,52,187,83,183,83,182,78,186,77,371,47,524,25"/>
<area shape="rect" title=" " alt="" coords="75,155,144,181"/>
<area shape="poly" title=" " alt="" coords="525,29,408,48,341,63,276,83,203,115,143,149,140,144,201,110,274,77,340,58,407,42,524,24"/>
<area shape="rect" title=" " alt="" coords="516,80,567,107"/>
<area shape="poly" title=" " alt="" coords="577,34,558,68,553,65,572,31"/>
<area shape="rect" title=" " alt="" coords="591,80,652,107"/>
<area shape="poly" title=" " alt="" coords="591,31,610,65,605,68,586,34"/>
<area shape="rect" title=" " alt="" coords="676,80,759,107"/>
<area shape="poly" title=" " alt="" coords="606,30,682,70,679,75,604,35"/>
<area shape="rect" title=" " alt="" coords="783,80,836,107"/>
<area shape="poly" title=" " alt="" coords="622,30,769,76,767,81,620,35"/>
<area shape="rect" title=" " alt="" coords="860,80,938,107"/>
<area shape="poly" title=" " alt="" coords="639,30,845,77,844,82,638,35"/>
<area shape="rect" title=" " alt="" coords="962,80,1012,107"/>
<area shape="poly" title=" " alt="" coords="639,24,776,44,947,77,946,82,775,49,638,29"/>
<area shape="rect" title=" " alt="" coords="1035,80,1096,107"/>
<area shape="poly" title=" " alt="" coords="639,22,807,41,912,57,1021,77,1020,82,911,62,806,47,638,28"/>
<area shape="rect" title=" " alt="" coords="168,155,225,181"/>
<area shape="poly" title=" " alt="" coords="525,31,433,50,381,64,332,82,274,114,225,147,222,143,271,109,330,78,380,59,431,44,524,25"/>
<area shape="rect" title=" " alt="" coords="1120,80,1187,107"/>
<area shape="poly" title=" " alt="" coords="639,21,841,39,971,56,1105,77,1105,82,970,61,841,45,639,26"/>
<area shape="rect" title=" " alt="" coords="250,155,327,181"/>
<area shape="poly" title=" " alt="" coords="525,30,448,48,408,63,370,82,334,111,307,144,303,140,331,108,367,78,405,58,447,43,524,25"/>
<area shape="rect" title=" " alt="" coords="352,155,409,181"/>
<area shape="poly" title=" " alt="" coords="525,23,488,28,450,38,415,56,386,82,379,95,376,110,377,140,371,140,371,109,374,93,382,78,412,51,449,33,487,23,524,18"/>
<area shape="rect" title=" " alt="" coords="1211,80,1275,107"/>
<area shape="poly" title=" " alt="" coords="639,20,878,36,1035,53,1196,77,1195,82,1034,58,878,41,638,25"/>
<area shape="rect" href="tensor__perf_8h.html" title="Performance optimization features for tensor operations." alt="" coords="396,80,493,107"/>
<area shape="poly" title=" " alt="" coords="559,35,483,75,480,70,556,30"/>
<area shape="poly" title=" " alt="" coords="396,107,159,157,158,152,395,102"/>
<area shape="poly" title=" " alt="" coords="402,110,240,157,239,151,400,105"/>
<area shape="poly" title=" " alt="" coords="418,110,330,150,328,145,416,105"/>
<area shape="poly" title=" " alt="" coords="435,109,403,145,399,141,431,105"/>
<area shape="rect" title=" " alt="" coords="433,155,490,181"/>
<area shape="poly" title=" " alt="" coords="450,107,458,139,452,140,445,108"/>
<area shape="rect" title=" " alt="" coords="514,155,572,181"/>
<area shape="poly" title=" " alt="" coords="463,105,515,143,512,148,460,109"/>
<area shape="rect" title=" " alt="" coords="595,155,656,181"/>
<area shape="poly" title=" " alt="" coords="477,105,582,146,580,151,475,110"/>
<area shape="rect" title=" " alt="" coords="679,155,740,181"/>
<area shape="poly" title=" " alt="" coords="493,105,665,151,664,156,492,110"/>
<area shape="rect" title=" " alt="" coords="764,155,818,181"/>
<area shape="poly" title=" " alt="" coords="494,102,505,104,626,126,749,151,748,157,625,131,504,109,493,107"/>
<area shape="rect" title=" " alt="" coords="843,155,899,181"/>
<area shape="poly" title=" " alt="" coords="494,102,505,104,594,117,665,126,736,135,828,152,827,157,736,140,664,131,593,123,504,109,493,107"/>
</map>
</div>
</div><div class="textblock"><div class="dynheader">
This graph shows which files directly or indirectly include this file:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h__dep__incl.png" border="0" usemap="#ainclude_2tensor_8hdep" loading="lazy" alt=""/></div>
<map name="ainclude_2tensor_8hdep" id="ainclude_2tensor_8hdep">
<area shape="rect" title="High&#45;performance multi&#45;dimensional tensor library with GPU, BLAS, and autograd support." alt="" coords="495,5,608,32"/>
<area shape="rect" href="linalg_8h.html" title="Linear algebra operations for vectors and matrices." alt="" coords="211,80,319,107"/>
<area shape="poly" title=" " alt="" coords="488,39,316,82,315,77,486,34"/>
<area shape="rect" href="tensor__c_8cpp.html" title=" " alt="" coords="502,229,620,256"/>
<area shape="poly" title=" " alt="" coords="479,22,319,28,228,36,143,49,72,70,44,83,24,97,12,114,8,133,15,155,32,179,55,191,99,202,228,218,377,230,502,236,501,242,376,235,228,224,98,207,53,196,29,183,10,157,3,133,7,112,20,94,42,78,70,65,142,44,228,30,318,22,479,17"/>
<area shape="rect" href="tensor__instantiations_8cc.html" title="Explicit template instantiations for Matrix and Tensor types." alt="" coords="42,155,224,181"/>
<area shape="poly" title=" " alt="" coords="480,29,324,48,251,64,201,82,181,98,164,118,141,156,137,153,160,115,177,95,198,78,250,59,323,43,480,23"/>
<area shape="rect" href="loss__functions_8h.html" title="Loss functions for training neural networks." alt="" coords="352,80,514,107"/>
<area shape="poly" title=" " alt="" coords="520,43,455,82,453,77,517,38"/>
<area shape="rect" href="nn__layers_8h.html" title="Common neural network layer implementations." alt="" coords="654,155,788,181"/>
<area shape="poly" title=" " alt="" coords="572,42,598,73,629,105,665,131,699,152,696,156,662,135,626,109,594,77,568,46"/>
<area shape="rect" href="optimizers_8h.html" title="Optimization algorithms for training neural networks." alt="" coords="492,155,630,181"/>
<area shape="poly" title=" " alt="" coords="556,47,563,154,558,154,551,48"/>
<area shape="rect" href="tensor__io_8h.html" title="I/O operations for tensors (save/load/print)." alt="" coords="896,155,1026,181"/>
<area shape="poly" title=" " alt="" coords="624,17,717,20,821,29,869,36,913,47,947,61,971,78,980,97,981,118,970,155,965,154,975,118,975,98,967,82,945,65,911,52,868,42,820,34,717,25,624,22"/>
<area shape="rect" href="tensor__ops_8h.html" title="Core neural network operations with broadcasting and autograd." alt="" coords="816,80,957,107"/>
<area shape="poly" title=" " alt="" coords="624,33,828,77,827,82,623,38"/>
<area shape="rect" href="tensor__types_8h.html" title="Type aliases for common Tensor specializations." alt="" coords="640,80,792,107"/>
<area shape="poly" title=" " alt="" coords="595,36,688,77,686,82,593,41"/>
<area shape="rect" href="linalg__advanced_8h.html" title="Advanced linear algebra operations with LAPACK/cuSOLVER support." alt="" coords="299,155,469,181"/>
<area shape="poly" title=" " alt="" coords="300,113,364,152,362,156,297,117"/>
<area shape="poly" title=" " alt="" coords="267,122,273,153,279,167,288,179,303,189,324,199,379,214,502,233,501,238,378,219,322,204,300,194,285,183,274,170,268,154,262,123"/>
<area shape="poly" title=" " alt="" coords="231,117,158,156,155,152,228,112"/>
<area shape="poly" title=" " alt="" coords="430,185,531,226,529,231,428,190"/>
<area shape="poly" title=" " alt="" coords="680,191,590,231,588,226,678,186"/>
<area shape="poly" title=" " alt="" coords="564,197,564,229,558,229,558,197"/>
<area shape="poly" title=" " alt="" coords="881,186,621,233,620,228,880,181"/>
<area shape="poly" title=" " alt="" coords="758,112,781,126,799,143,808,162,807,173,802,183,790,194,773,203,726,218,621,237,620,232,725,213,770,198,787,189,798,180,802,171,803,163,795,146,777,130,756,116"/>
<area shape="poly" title=" " alt="" coords="720,122,723,154,718,154,715,123"/>
</map>
</div>
</div>
<p><a href="tensor_8h_source.html">Go to the source code of this file.</a></p>
<table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 id="header-nested-classes" class="groupheader"><a id="nested-classes" name="nested-classes"></a>
Classes</h2></td></tr>
<tr class="memitem:Tensor_3C_20T_2C_20N_20_3E" id="r_Tensor_3C_20T_2C_20N_20_3E"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTensor.html">Tensor&lt; T, N &gt;</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Forward declaration for autograd.  <a href="classTensor.html#details">More...</a><br /></td></tr>
<tr class="memitem:TensorRandom_3C_20T_20_3E" id="r_TensorRandom_3C_20T_20_3E"><td class="memItemLeft" align="right" valign="top">class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="classTensorRandom.html">TensorRandom&lt; T &gt;</a></td></tr>
<tr class="memdesc:"><td class="mdescLeft">&#160;</td><td class="mdescRight">Random number generator for tensor operations.  <a href="classTensorRandom.html#details">More...</a><br /></td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 id="header-namespaces" class="groupheader"><a id="namespaces" name="namespaces"></a>
Namespaces</h2></td></tr>
<tr class="memitem:loss" id="r_loss"><td class="memItemLeft" align="right" valign="top">namespace &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceloss.html">loss</a></td></tr>
<tr class="memdesc:namespaceloss"><td class="mdescLeft">&#160;</td><td class="mdescRight">Loss functions for neural network training. <br /></td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 id="header-typedef-members" class="groupheader"><a id="typedef-members" name="typedef-members"></a>
Typedefs</h2></td></tr>
<tr class="memitem:a4eaf7c692573fd9dc1a450be56b68fcc" id="r_a4eaf7c692573fd9dc1a450be56b68fcc"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:a4eaf7c692573fd9dc1a450be56b68fcc template"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a4eaf7c692573fd9dc1a450be56b68fcc">TensorResult</a> = std::variant&lt;T, <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaa">TensorError</a>&gt;</td></tr>
<tr class="memdesc:a4eaf7c692573fd9dc1a450be56b68fcc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Result type for tensor operations that may fail.  <br /></td></tr>
<tr class="memitem:ab58b5b2b06188fb918bfa78bdfce068b" id="r_ab58b5b2b06188fb918bfa78bdfce068b"><td class="memTemplParams" colspan="2">template&lt;size_t N&gt; </td></tr>
<tr class="memitem:ab58b5b2b06188fb918bfa78bdfce068b template"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a> = std::array&lt;size_t, N&gt;</td></tr>
<tr class="memdesc:ab58b5b2b06188fb918bfa78bdfce068b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Type alias for tensor indices/coordinates.  <br /></td></tr>
<tr class="memitem:a1e846f46f87b55f57de12d6aa70eda1e" id="r_a1e846f46f87b55f57de12d6aa70eda1e"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:a1e846f46f87b55f57de12d6aa70eda1e template"><td class="memItemLeft" align="right" valign="top">using&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a1e846f46f87b55f57de12d6aa70eda1e">BackwardFunc</a> = std::function&lt;void(const <a class="el" href="classTensor.html">Tensor</a>&lt;T, N&gt;&amp;)&gt;</td></tr>
<tr class="memdesc:a1e846f46f87b55f57de12d6aa70eda1e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Function type for backward pass in autograd.  <br /></td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 id="header-enum-members" class="groupheader"><a id="enum-members" name="enum-members"></a>
Enumerations</h2></td></tr>
<tr class="memitem:ae4db5848267c1a5a1413b7f87cf6889d" id="r_ae4db5848267c1a5a1413b7f87cf6889d"><td class="memItemLeft" align="right" valign="top">enum class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ae4db5848267c1a5a1413b7f87cf6889d">Backend</a> { <a class="el" href="#ae4db5848267c1a5a1413b7f87cf6889da2b55387dd066c5bac646ac61543d152d">CPU</a>
, <a class="el" href="#ae4db5848267c1a5a1413b7f87cf6889daf0c2cf06f9a01bc3a3ef50b116b18b51">BLAS</a>
, <a class="el" href="#ae4db5848267c1a5a1413b7f87cf6889da52f9ec21735243ad9917cda3ca077d32">GPU</a>
 }</td></tr>
<tr class="memdesc:ae4db5848267c1a5a1413b7f87cf6889d"><td class="mdescLeft">&#160;</td><td class="mdescRight">Available computational backends.  <a href="#ae4db5848267c1a5a1413b7f87cf6889d">More...</a><br /></td></tr>
<tr class="memitem:a2db6a67f5b95f95cb23a9d7b28deceaa" id="r_a2db6a67f5b95f95cb23a9d7b28deceaa"><td class="memItemLeft" align="right" valign="top">enum class &#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaa">TensorError</a> { <br />
&#160;&#160;<a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa2664c241558d7674e8ed4d5f63d2e463">DimensionMismatch</a>
, <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaaabb290efc01a42c7ed881f46a0477eca6">ContractionMismatch</a>
, <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa253ca7dd096ee0956cccee4d376cab8b">InvalidArgument</a>
, <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaaade2e45aece7bcbb9fe7540cc9e11c40f">SingularMatrix</a>
, <br />
&#160;&#160;<a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa5a386c59a2af4745f1107846201959ed">NotPositiveDefinite</a>
, <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa69d8864d8802ee76419e96eaa669295a">NotSquare</a>
, <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa953002ae82f05e5c52b3e676992dacc6">EmptyMatrix</a>
, <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaaaa1df5a085496d7c89611f837bf1d52ef">LapackError</a>
, <br />
&#160;&#160;<a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa997ca4ce119685f40f03a9a8a6c5346e">NotImplemented</a>
<br />
 }</td></tr>
<tr class="memdesc:a2db6a67f5b95f95cb23a9d7b28deceaa"><td class="mdescLeft">&#160;</td><td class="mdescRight">Error codes for tensor operations.  <a href="#a2db6a67f5b95f95cb23a9d7b28deceaa">More...</a><br /></td></tr>
</table><table class="memberdecls">
<tr class="heading"><td colspan="2"><h2 id="header-func-members" class="groupheader"><a id="func-members" name="func-members"></a>
Functions</h2></td></tr>
<tr class="memitem:ae65fd500e7e89fd9a45a887f9c9b67e7" id="r_ae65fd500e7e89fd9a45a887f9c9b67e7"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ae65fd500e7e89fd9a45a887f9c9b67e7">backend_name</a> (<a class="el" href="#ae4db5848267c1a5a1413b7f87cf6889d">Backend</a> backend)</td></tr>
<tr class="memdesc:ae65fd500e7e89fd9a45a887f9c9b67e7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the name of a backend as a string.  <br /></td></tr>
<tr class="memitem:a46e409633222975e3723ab74a190a8a5" id="r_a46e409633222975e3723ab74a190a8a5"><td class="memItemLeft" align="right" valign="top"><a class="el" href="#ae4db5848267c1a5a1413b7f87cf6889d">Backend</a>&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a46e409633222975e3723ab74a190a8a5">get_active_backend</a> ()</td></tr>
<tr class="memdesc:a46e409633222975e3723ab74a190a8a5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Get the currently active backend.  <br /></td></tr>
<tr class="memitem:ac3172c311c588e95a83276e2841906af" id="r_ac3172c311c588e95a83276e2841906af"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ac3172c311c588e95a83276e2841906af">is_gpu_available</a> ()</td></tr>
<tr class="memdesc:ac3172c311c588e95a83276e2841906af"><td class="mdescLeft">&#160;</td><td class="mdescRight">Check if GPU backend is available.  <br /></td></tr>
<tr class="memitem:a3c3ae83e0bf8e69abff6e2d476d6d4bc" id="r_a3c3ae83e0bf8e69abff6e2d476d6d4bc"><td class="memItemLeft" align="right" valign="top">constexpr bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a3c3ae83e0bf8e69abff6e2d476d6d4bc">is_blas_available</a> ()</td></tr>
<tr class="memdesc:a3c3ae83e0bf8e69abff6e2d476d6d4bc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Check if BLAS backend is available.  <br /></td></tr>
<tr class="memitem:a8003198c60408cf62b8a805020f1a749" id="r_a8003198c60408cf62b8a805020f1a749"><td class="memItemLeft" align="right" valign="top">std::string&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a8003198c60408cf62b8a805020f1a749">to_string</a> (<a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaa">TensorError</a> error)</td></tr>
<tr class="memdesc:a8003198c60408cf62b8a805020f1a749"><td class="mdescLeft">&#160;</td><td class="mdescRight">Convert <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaa" title="Error codes for tensor operations.">TensorError</a> to human-readable string.  <br /></td></tr>
<tr class="memitem:aff5180b0c38ddd16d08f058205c01ef7" id="r_aff5180b0c38ddd16d08f058205c01ef7"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:aff5180b0c38ddd16d08f058205c01ef7 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceloss.html#aff5180b0c38ddd16d08f058205c01ef7">loss::mse_loss</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;predictions, const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;targets, const std::string &amp;reduction)</td></tr>
<tr class="memdesc:aff5180b0c38ddd16d08f058205c01ef7"><td class="mdescLeft">&#160;</td><td class="mdescRight">Mean Squared Error (MSE) Loss.  <br /></td></tr>
<tr class="memitem:a75edef9d102d2ab811b15c50f13c4eee" id="r_a75edef9d102d2ab811b15c50f13c4eee"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:a75edef9d102d2ab811b15c50f13c4eee template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceloss.html#a75edef9d102d2ab811b15c50f13c4eee">loss::cross_entropy_loss</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;, const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;, const std::string &amp;=&quot;mean&quot;)</td></tr>
<tr class="memdesc:a75edef9d102d2ab811b15c50f13c4eee"><td class="mdescLeft">&#160;</td><td class="mdescRight">Cross entropy loss for multi-class classification.  <br /></td></tr>
<tr class="memitem:a365059b00ea1e6ec1db86710cfcf3b31" id="r_a365059b00ea1e6ec1db86710cfcf3b31"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:a365059b00ea1e6ec1db86710cfcf3b31 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceloss.html#a365059b00ea1e6ec1db86710cfcf3b31">loss::binary_cross_entropy</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;, const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;, const std::string &amp;=&quot;mean&quot;)</td></tr>
<tr class="memdesc:a365059b00ea1e6ec1db86710cfcf3b31"><td class="mdescLeft">&#160;</td><td class="mdescRight">Binary cross entropy loss for binary classification.  <br /></td></tr>
<tr class="memitem:ab7fbd0200f34e3d12f66d20b681a948f" id="r_ab7fbd0200f34e3d12f66d20b681a948f"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:ab7fbd0200f34e3d12f66d20b681a948f template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceloss.html#ab7fbd0200f34e3d12f66d20b681a948f">loss::l1_loss</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;, const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;, const std::string &amp;=&quot;mean&quot;)</td></tr>
<tr class="memdesc:ab7fbd0200f34e3d12f66d20b681a948f"><td class="mdescLeft">&#160;</td><td class="mdescRight">L1 loss (Mean Absolute Error).  <br /></td></tr>
<tr class="memitem:a2d2c1dacdb37d834f7dc10e85cd1a742" id="r_a2d2c1dacdb37d834f7dc10e85cd1a742"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:a2d2c1dacdb37d834f7dc10e85cd1a742 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="namespaceloss.html#a2d2c1dacdb37d834f7dc10e85cd1a742">loss::smooth_l1_loss</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;, const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;, T=T(1), const std::string &amp;=&quot;mean&quot;)</td></tr>
<tr class="memdesc:a2d2c1dacdb37d834f7dc10e85cd1a742"><td class="mdescLeft">&#160;</td><td class="mdescRight">Smooth L1 loss (Huber loss).  <br /></td></tr>
<tr class="memitem:a34fae58316c67748882059be5f1d153c" id="r_a34fae58316c67748882059be5f1d153c"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N, size_t M&gt; </td></tr>
<tr class="memitem:a34fae58316c67748882059be5f1d153c template"><td class="memItemLeft" align="right" valign="top">auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a34fae58316c67748882059be5f1d153c">broadcast_to</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;tensor, const <a class="el" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a>&lt; M &gt; &amp;target_shape) -&gt; std::variant&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T, M &gt;, <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaa">TensorError</a> &gt;</td></tr>
<tr class="memdesc:a34fae58316c67748882059be5f1d153c"><td class="mdescLeft">&#160;</td><td class="mdescRight">Broadcast a tensor to a new shape.  <br /></td></tr>
<tr class="memitem:adf94b1b28dd9932dd278abaa3cb7a9ee" id="r_adf94b1b28dd9932dd278abaa3cb7a9ee"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:adf94b1b28dd9932dd278abaa3cb7a9ee template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#adf94b1b28dd9932dd278abaa3cb7a9ee">row</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; &amp;matrix, size_t row_idx)</td></tr>
<tr class="memdesc:adf94b1b28dd9932dd278abaa3cb7a9ee"><td class="mdescLeft">&#160;</td><td class="mdescRight">Extract a single row from a 2D tensor.  <br /></td></tr>
<tr class="memitem:a5f2a03f722ba5a985a3733e2ff823a74" id="r_a5f2a03f722ba5a985a3733e2ff823a74"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:a5f2a03f722ba5a985a3733e2ff823a74 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a5f2a03f722ba5a985a3733e2ff823a74">col</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; &amp;matrix, size_t col_idx)</td></tr>
<tr class="memdesc:a5f2a03f722ba5a985a3733e2ff823a74"><td class="mdescLeft">&#160;</td><td class="mdescRight">Extract a single column from a 2D tensor.  <br /></td></tr>
<tr class="memitem:a43014e3309494c3851da86be3a162194" id="r_a43014e3309494c3851da86be3a162194"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:a43014e3309494c3851da86be3a162194 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a43014e3309494c3851da86be3a162194">diag</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; &amp;matrix)</td></tr>
<tr class="memdesc:a43014e3309494c3851da86be3a162194"><td class="mdescLeft">&#160;</td><td class="mdescRight">Extract the diagonal of a 2D tensor.  <br /></td></tr>
<tr class="memitem:ae66ddfcd20907014f524982e01698d82" id="r_ae66ddfcd20907014f524982e01698d82"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:ae66ddfcd20907014f524982e01698d82 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ae66ddfcd20907014f524982e01698d82">diag_matrix</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; &amp;vec)</td></tr>
<tr class="memdesc:ae66ddfcd20907014f524982e01698d82"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create a diagonal matrix from a 1D tensor.  <br /></td></tr>
<tr class="memitem:adc912199dacbff108e0d2cadfae000df" id="r_adc912199dacbff108e0d2cadfae000df"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:adc912199dacbff108e0d2cadfae000df template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#adc912199dacbff108e0d2cadfae000df">block</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; &amp;matrix, size_t start_row, size_t start_col, size_t num_rows, size_t num_cols)</td></tr>
<tr class="memdesc:adc912199dacbff108e0d2cadfae000df"><td class="mdescLeft">&#160;</td><td class="mdescRight">Extract a rectangular block from a 2D tensor.  <br /></td></tr>
<tr class="memitem:a04c7965d0b8f08cfdb84580050e9e0b5" id="r_a04c7965d0b8f08cfdb84580050e9e0b5"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:a04c7965d0b8f08cfdb84580050e9e0b5 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a04c7965d0b8f08cfdb84580050e9e0b5">head</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; &amp;vec, size_t n)</td></tr>
<tr class="memdesc:a04c7965d0b8f08cfdb84580050e9e0b5"><td class="mdescLeft">&#160;</td><td class="mdescRight">Extract first n elements from a 1D tensor.  <br /></td></tr>
<tr class="memitem:a90d629271a42d730c36b7be1f66deae8" id="r_a90d629271a42d730c36b7be1f66deae8"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:a90d629271a42d730c36b7be1f66deae8 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a90d629271a42d730c36b7be1f66deae8">tail</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; &amp;vec, size_t n)</td></tr>
<tr class="memdesc:a90d629271a42d730c36b7be1f66deae8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Extract last n elements from a 1D tensor.  <br /></td></tr>
<tr class="memitem:a1cb2cae503ca515b1780c72fd05b21db" id="r_a1cb2cae503ca515b1780c72fd05b21db"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:a1cb2cae503ca515b1780c72fd05b21db template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a1cb2cae503ca515b1780c72fd05b21db">topRows</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; &amp;matrix, size_t n)</td></tr>
<tr class="memdesc:a1cb2cae503ca515b1780c72fd05b21db"><td class="mdescLeft">&#160;</td><td class="mdescRight">Extract top n rows from a 2D tensor.  <br /></td></tr>
<tr class="memitem:aa94ca571f8bc2b76cd1bdb6fd851c556" id="r_aa94ca571f8bc2b76cd1bdb6fd851c556"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:aa94ca571f8bc2b76cd1bdb6fd851c556 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aa94ca571f8bc2b76cd1bdb6fd851c556">bottomRows</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; &amp;matrix, size_t n)</td></tr>
<tr class="memdesc:aa94ca571f8bc2b76cd1bdb6fd851c556"><td class="mdescLeft">&#160;</td><td class="mdescRight">Extract bottom n rows from a 2D tensor.  <br /></td></tr>
<tr class="memitem:a0d1116cdf6624cb52514979cd1869e55" id="r_a0d1116cdf6624cb52514979cd1869e55"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:a0d1116cdf6624cb52514979cd1869e55 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a0d1116cdf6624cb52514979cd1869e55">leftCols</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; &amp;matrix, size_t n)</td></tr>
<tr class="memdesc:a0d1116cdf6624cb52514979cd1869e55"><td class="mdescLeft">&#160;</td><td class="mdescRight">Extract leftmost n columns from a 2D tensor.  <br /></td></tr>
<tr class="memitem:a3798be100af6c60da8c8489ba3ac808a" id="r_a3798be100af6c60da8c8489ba3ac808a"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:a3798be100af6c60da8c8489ba3ac808a template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a3798be100af6c60da8c8489ba3ac808a">rightCols</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; &amp;matrix, size_t n)</td></tr>
<tr class="memdesc:a3798be100af6c60da8c8489ba3ac808a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Extract rightmost n columns from a 2D tensor.  <br /></td></tr>
<tr class="memitem:ab4f017dc744d8a8c5be14a419efc0b65" id="r_ab4f017dc744d8a8c5be14a419efc0b65"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:ab4f017dc744d8a8c5be14a419efc0b65 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ab4f017dc744d8a8c5be14a419efc0b65">operator+</a> (const T &amp;scalar, const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;tensor)</td></tr>
<tr class="memitem:aab7ab5d6f397d5c819291ee64a3285a9" id="r_aab7ab5d6f397d5c819291ee64a3285a9"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:aab7ab5d6f397d5c819291ee64a3285a9 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aab7ab5d6f397d5c819291ee64a3285a9">operator-</a> (const T &amp;scalar, const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;tensor)</td></tr>
<tr class="memitem:a98854ecedcd00bad8152e2a1064ccfd5" id="r_a98854ecedcd00bad8152e2a1064ccfd5"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:a98854ecedcd00bad8152e2a1064ccfd5 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a98854ecedcd00bad8152e2a1064ccfd5">operator*</a> (const T &amp;scalar, const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;tensor)</td></tr>
<tr class="memitem:a68ab7ecde44431a4d8e941737a5b2cba" id="r_a68ab7ecde44431a4d8e941737a5b2cba"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:a68ab7ecde44431a4d8e941737a5b2cba template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a68ab7ecde44431a4d8e941737a5b2cba">operator/</a> (const T &amp;scalar, const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;tensor)</td></tr>
<tr class="memitem:a4bfe3189f926716838813a01b6c37038" id="r_a4bfe3189f926716838813a01b6c37038"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:a4bfe3189f926716838813a01b6c37038 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a4bfe3189f926716838813a01b6c37038">sort</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; &amp;tensor, bool ascending=true)</td></tr>
<tr class="memdesc:a4bfe3189f926716838813a01b6c37038"><td class="mdescLeft">&#160;</td><td class="mdescRight">Sort tensor elements and return sorted tensor (1D only).  <br /></td></tr>
<tr class="memitem:a1ce61bbd53890adec19f5b19f946ef26" id="r_a1ce61bbd53890adec19f5b19f946ef26"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:a1ce61bbd53890adec19f5b19f946ef26 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; size_t, 1 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a1ce61bbd53890adec19f5b19f946ef26">argsort</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; &amp;tensor, bool ascending=true)</td></tr>
<tr class="memdesc:a1ce61bbd53890adec19f5b19f946ef26"><td class="mdescLeft">&#160;</td><td class="mdescRight">Return indices that would sort the tensor (1D only).  <br /></td></tr>
<tr class="memitem:a952343525fb5d9376af0645793e8f1d4" id="r_a952343525fb5d9376af0645793e8f1d4"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:a952343525fb5d9376af0645793e8f1d4 template"><td class="memItemLeft" align="right" valign="top">std::pair&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt;, <a class="el" href="classTensor.html">Tensor</a>&lt; size_t, 1 &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a952343525fb5d9376af0645793e8f1d4">topk</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; &amp;tensor, size_t k, bool largest=true)</td></tr>
<tr class="memdesc:a952343525fb5d9376af0645793e8f1d4"><td class="mdescLeft">&#160;</td><td class="mdescRight">Find k largest or smallest elements and their indices (1D only).  <br /></td></tr>
<tr class="memitem:ad136045cd6f420421ea5618b726778f3" id="r_ad136045cd6f420421ea5618b726778f3"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:ad136045cd6f420421ea5618b726778f3 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad136045cd6f420421ea5618b726778f3">unique</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; &amp;tensor)</td></tr>
<tr class="memdesc:ad136045cd6f420421ea5618b726778f3"><td class="mdescLeft">&#160;</td><td class="mdescRight">Find unique elements in tensor (1D only).  <br /></td></tr>
<tr class="memitem:abcbf52cee83938743ba0195663090841" id="r_abcbf52cee83938743ba0195663090841"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:abcbf52cee83938743ba0195663090841 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; size_t, 1 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#abcbf52cee83938743ba0195663090841">searchsorted</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; &amp;values, const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; &amp;search_values)</td></tr>
<tr class="memdesc:abcbf52cee83938743ba0195663090841"><td class="mdescLeft">&#160;</td><td class="mdescRight">Binary search to find indices where elements should be inserted (1D only).  <br /></td></tr>
<tr class="memitem:a139335a446015c5f7ad70fa3d2ccfbec" id="r_a139335a446015c5f7ad70fa3d2ccfbec"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:a139335a446015c5f7ad70fa3d2ccfbec template"><td class="memItemLeft" align="right" valign="top">std::vector&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a139335a446015c5f7ad70fa3d2ccfbec">split</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;tensor, size_t num_chunks, size_t axis=0)</td></tr>
<tr class="memdesc:a139335a446015c5f7ad70fa3d2ccfbec"><td class="mdescLeft">&#160;</td><td class="mdescRight">Split tensor into chunks along specified axis.  <br /></td></tr>
<tr class="memitem:a64dfa8c2475ed50ae00ef1d4e1c12fd2" id="r_a64dfa8c2475ed50ae00ef1d4e1c12fd2"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:a64dfa8c2475ed50ae00ef1d4e1c12fd2 template"><td class="memItemLeft" align="right" valign="top">std::vector&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a64dfa8c2475ed50ae00ef1d4e1c12fd2">chunk</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;tensor, size_t chunk_size, size_t axis=0)</td></tr>
<tr class="memdesc:a64dfa8c2475ed50ae00ef1d4e1c12fd2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Divide tensor into equal-sized chunks (last chunk may be smaller).  <br /></td></tr>
<tr class="memitem:ac2791cd88647d71068c02d8824a38ff2" id="r_ac2791cd88647d71068c02d8824a38ff2"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:ac2791cd88647d71068c02d8824a38ff2 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ac2791cd88647d71068c02d8824a38ff2">tile</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;tensor, const std::array&lt; size_t, N &gt; &amp;repeats)</td></tr>
<tr class="memdesc:ac2791cd88647d71068c02d8824a38ff2"><td class="mdescLeft">&#160;</td><td class="mdescRight">Repeat tensor multiple times along each dimension.  <br /></td></tr>
<tr class="memitem:ad71687cadd6e7bdae0f2d66fc9f437e1" id="r_ad71687cadd6e7bdae0f2d66fc9f437e1"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:ad71687cadd6e7bdae0f2d66fc9f437e1 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ad71687cadd6e7bdae0f2d66fc9f437e1">repeat_along_axis</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;tensor, size_t repeats, size_t axis=0)</td></tr>
<tr class="memdesc:ad71687cadd6e7bdae0f2d66fc9f437e1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Construct tensor by repeating along specified axis.  <br /></td></tr>
<tr class="memitem:a73f1eab7fbd472760c5d87a8acc9d7be" id="r_a73f1eab7fbd472760c5d87a8acc9d7be"><td class="memTemplParams" colspan="2">template&lt;size_t N1, size_t N2&gt; </td></tr>
<tr class="memitem:a73f1eab7fbd472760c5d87a8acc9d7be template"><td class="memItemLeft" align="right" valign="top">bool&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a73f1eab7fbd472760c5d87a8acc9d7be">are_broadcastable</a> (const <a class="el" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a>&lt; N1 &gt; &amp;shape1, const <a class="el" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a>&lt; N2 &gt; &amp;shape2, std::string *error_msg=nullptr)</td></tr>
<tr class="memdesc:a73f1eab7fbd472760c5d87a8acc9d7be"><td class="mdescLeft">&#160;</td><td class="mdescRight">Check if two tensor shapes are broadcastable.  <br /></td></tr>
<tr class="memitem:a9c62fb825b47530c2ec213d305b7c1d9" id="r_a9c62fb825b47530c2ec213d305b7c1d9"><td class="memTemplParams" colspan="2">template&lt;size_t N1, size_t N2&gt; </td></tr>
<tr class="memitem:a9c62fb825b47530c2ec213d305b7c1d9 template"><td class="memItemLeft" align="right" valign="top">auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a9c62fb825b47530c2ec213d305b7c1d9">compute_broadcast_shape</a> (const <a class="el" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a>&lt; N1 &gt; &amp;shape1, const <a class="el" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a>&lt; N2 &gt; &amp;shape2) -&gt; std::variant&lt; <a class="el" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a>&lt; std::max(N1, N2)&gt;, <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaa">TensorError</a> &gt;</td></tr>
<tr class="memdesc:a9c62fb825b47530c2ec213d305b7c1d9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Compute the broadcast shape of two tensors.  <br /></td></tr>
<tr class="memitem:a912e291f7a42f325c111def58ac98acf" id="r_a912e291f7a42f325c111def58ac98acf"><td class="memTemplParams" colspan="2">template&lt;typename U, typename T, size_t N&gt; </td></tr>
<tr class="memitem:a912e291f7a42f325c111def58ac98acf template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; U, N &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a912e291f7a42f325c111def58ac98acf">astype</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;tensor)</td></tr>
<tr class="memdesc:a912e291f7a42f325c111def58ac98acf"><td class="mdescLeft">&#160;</td><td class="mdescRight">Cast tensor to a different data type (NumPy-compatible astype).  <br /></td></tr>
<tr class="memitem:a3331b6cf4ac182d022336e4d068a0e58" id="r_a3331b6cf4ac182d022336e4d068a0e58"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:a3331b6cf4ac182d022336e4d068a0e58 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a3331b6cf4ac182d022336e4d068a0e58">copy</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;tensor)</td></tr>
<tr class="memdesc:a3331b6cf4ac182d022336e4d068a0e58"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create a copy of a tensor (NumPy-compatible).  <br /></td></tr>
<tr class="memitem:a249e6ed21f6e3540a11b62433237175a" id="r_a249e6ed21f6e3540a11b62433237175a"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:a249e6ed21f6e3540a11b62433237175a template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a249e6ed21f6e3540a11b62433237175a">zeros</a> (const <a class="el" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a>&lt; N &gt; &amp;shape, bool use_gpu=true)</td></tr>
<tr class="memdesc:a249e6ed21f6e3540a11b62433237175a"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create a tensor filled with zeros (NumPy-compatible).  <br /></td></tr>
<tr class="memitem:a37ee39b629ca93dc83259b6c8591d0d9" id="r_a37ee39b629ca93dc83259b6c8591d0d9"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:a37ee39b629ca93dc83259b6c8591d0d9 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a37ee39b629ca93dc83259b6c8591d0d9">ones</a> (const <a class="el" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a>&lt; N &gt; &amp;shape, bool use_gpu=true)</td></tr>
<tr class="memdesc:a37ee39b629ca93dc83259b6c8591d0d9"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create a tensor filled with ones (NumPy-compatible).  <br /></td></tr>
<tr class="memitem:abee606191f2a9544a7acbbd79094ed5b" id="r_abee606191f2a9544a7acbbd79094ed5b"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:abee606191f2a9544a7acbbd79094ed5b template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#abee606191f2a9544a7acbbd79094ed5b">arange</a> (T start, T stop, T step=T(1), bool use_gpu=true)</td></tr>
<tr class="memdesc:abee606191f2a9544a7acbbd79094ed5b"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create a tensor with values in a range (NumPy arange-compatible).  <br /></td></tr>
<tr class="memitem:a47fb1071bbaf297c2b7804f3a16cbce0" id="r_a47fb1071bbaf297c2b7804f3a16cbce0"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:a47fb1071bbaf297c2b7804f3a16cbce0 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a47fb1071bbaf297c2b7804f3a16cbce0">linspace</a> (T start, T stop, size_t num=50, bool use_gpu=true)</td></tr>
<tr class="memdesc:a47fb1071bbaf297c2b7804f3a16cbce0"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create a tensor with evenly spaced values (NumPy linspace-compatible).  <br /></td></tr>
<tr class="memitem:ac9b881e42d5eeb214b4ca87579eaaffc" id="r_ac9b881e42d5eeb214b4ca87579eaaffc"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:ac9b881e42d5eeb214b4ca87579eaaffc template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#ac9b881e42d5eeb214b4ca87579eaaffc">logspace</a> (T start, T stop, size_t num=50, T base=T(10), bool use_gpu=true)</td></tr>
<tr class="memdesc:ac9b881e42d5eeb214b4ca87579eaaffc"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create a tensor with values spaced evenly on a log scale.  <br /></td></tr>
<tr class="memitem:a8a0e6e335b72a473208ce2c8f17b4a6e" id="r_a8a0e6e335b72a473208ce2c8f17b4a6e"><td class="memTemplParams" colspan="2">template&lt;typename T&gt; </td></tr>
<tr class="memitem:a8a0e6e335b72a473208ce2c8f17b4a6e template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a8a0e6e335b72a473208ce2c8f17b4a6e">eye</a> (size_t n, bool use_gpu=true)</td></tr>
<tr class="memdesc:a8a0e6e335b72a473208ce2c8f17b4a6e"><td class="mdescLeft">&#160;</td><td class="mdescRight">Create an identity matrix (NumPy eye-compatible).  <br /></td></tr>
<tr class="memitem:a280a6c1ac0d132b0a98af81c1fe371d8" id="r_a280a6c1ac0d132b0a98af81c1fe371d8"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N, size_t M&gt; </td></tr>
<tr class="memitem:a280a6c1ac0d132b0a98af81c1fe371d8 template"><td class="memItemLeft" align="right" valign="top">auto&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a280a6c1ac0d132b0a98af81c1fe371d8">reshape_to</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;tensor, const <a class="el" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a>&lt; M &gt; &amp;new_shape) -&gt; std::variant&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T, M &gt;, <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaa">TensorError</a> &gt;</td></tr>
<tr class="memdesc:a280a6c1ac0d132b0a98af81c1fe371d8"><td class="mdescLeft">&#160;</td><td class="mdescRight">Reshape a tensor (returns variant for error handling).  <br /></td></tr>
<tr class="memitem:aa8d30c4d06f085bf8078c8644030c633" id="r_aa8d30c4d06f085bf8078c8644030c633"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:aa8d30c4d06f085bf8078c8644030c633 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#aa8d30c4d06f085bf8078c8644030c633">normalize_l1</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;tensor, int axis=-1)</td></tr>
<tr class="memdesc:aa8d30c4d06f085bf8078c8644030c633"><td class="mdescLeft">&#160;</td><td class="mdescRight">Normalize tensor using L1 norm (sum of absolute values).  <br /></td></tr>
<tr class="memitem:a7718d2096a1190de7777bc65f9a86deb" id="r_a7718d2096a1190de7777bc65f9a86deb"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:a7718d2096a1190de7777bc65f9a86deb template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a7718d2096a1190de7777bc65f9a86deb">normalize_l2</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;tensor, int axis=-1)</td></tr>
<tr class="memdesc:a7718d2096a1190de7777bc65f9a86deb"><td class="mdescLeft">&#160;</td><td class="mdescRight">Normalize tensor using L2 norm (Euclidean norm).  <br /></td></tr>
<tr class="memitem:a57c931d0d77f610850f315fdd9acef39" id="r_a57c931d0d77f610850f315fdd9acef39"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:a57c931d0d77f610850f315fdd9acef39 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a57c931d0d77f610850f315fdd9acef39">normalize_zscore</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;tensor, int axis=-1, T eps=T(1e-8))</td></tr>
<tr class="memdesc:a57c931d0d77f610850f315fdd9acef39"><td class="mdescLeft">&#160;</td><td class="mdescRight">Z-score normalization (standardization): (x - mean) / std.  <br /></td></tr>
<tr class="memitem:a1782e0dff417e1292f8a6f1e3e1975f1" id="r_a1782e0dff417e1292f8a6f1e3e1975f1"><td class="memTemplParams" colspan="2">template&lt;typename T, size_t N&gt; </td></tr>
<tr class="memitem:a1782e0dff417e1292f8a6f1e3e1975f1 template"><td class="memItemLeft" align="right" valign="top"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt;&#160;</td><td class="memItemRight" valign="bottom"><a class="el" href="#a1782e0dff417e1292f8a6f1e3e1975f1">normalize_minmax</a> (const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;tensor, int axis=-1, T min_val=T(0), T max_val=T(1), T eps=T(1e-8))</td></tr>
<tr class="memdesc:a1782e0dff417e1292f8a6f1e3e1975f1"><td class="mdescLeft">&#160;</td><td class="mdescRight">Min-Max normalization: scales values to [min_val, max_val] range.  <br /></td></tr>
</table>
<a name="details" id="details"></a><h2 id="header-details" class="groupheader">Detailed Description</h2>
<div class="textblock"><p>High-performance multi-dimensional tensor library with GPU, BLAS, and autograd support. </p>
<p>This header provides a comprehensive tensor library for scientific computing and machine learning. It features:</p><ul>
<li>Multi-dimensional tensor operations with arbitrary dimensions</li>
<li>GPU acceleration via CUDA (when USE_GPU is defined)</li>
<li>Optimized CPU operations via BLAS (when USE_BLAS is defined)</li>
<li>Automatic differentiation (autograd) for gradient computation</li>
<li>Mathematical function mapping (exp, log, sin, cos, etc.)</li>
<li>Statistical operations (mean, variance, correlation, etc.)</li>
<li>Broadcasting for element-wise operations</li>
<li><a class="el" href="classTensor.html" title="Forward declaration for autograd.">Tensor</a> views and slicing for memory-efficient operations</li>
</ul>
<h1 class="doxsection"><a class="anchor" id="backend"></a>
Backend Selection</h1>
<p>The library automatically selects the best available backend at runtime:</p><ol type="1">
<li><b>GPU (CUDA)</b>: Used by default if compiled with USE_GPU, GPU is available, and use_gpu=true</li>
<li><b>BLAS</b>: Used if GPU is not available but compiled with USE_BLAS</li>
<li><b>CPU</b>: Fallback implementation when neither GPU nor BLAS is available</li>
</ol>
<p>You can check the active backend using: </p><div class="fragment"><div class="line"><span class="keyword">auto</span> backend = <a class="code hl_function" href="#a46e409633222975e3723ab74a190a8a5">get_active_backend</a>();  <span class="comment">// Returns Backend::GPU, Backend::BLAS, or Backend::CPU</span></div>
<div class="line"><span class="keywordflow">if</span> (<a class="code hl_function" href="#ac3172c311c588e95a83276e2841906af">is_gpu_available</a>()) {</div>
<div class="line">    <span class="comment">// GPU operations are available</span></div>
<div class="line">}</div>
<div class="ttc" id="atensor_8h_html_a46e409633222975e3723ab74a190a8a5"><div class="ttname"><a href="#a46e409633222975e3723ab74a190a8a5">get_active_backend</a></div><div class="ttdeci">Backend get_active_backend()</div><div class="ttdoc">Get the currently active backend.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00197">tensor.h:197</a></div></div>
<div class="ttc" id="atensor_8h_html_ac3172c311c588e95a83276e2841906af"><div class="ttname"><a href="#ac3172c311c588e95a83276e2841906af">is_gpu_available</a></div><div class="ttdeci">bool is_gpu_available()</div><div class="ttdoc">Check if GPU backend is available.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00213">tensor.h:213</a></div></div>
</div><!-- fragment --><dl class="section author"><dt>Author</dt><dd><a class="el" href="classTensor.html" title="Forward declaration for autograd.">Tensor</a> Library Team </dd></dl>
<dl class="section version"><dt>Version</dt><dd>1.0 </dd></dl>
<dl class="section date"><dt>Date</dt><dd>2024</dd></dl>
<h1 class="doxsection"><a class="anchor" id="usage_tensor"></a>
Usage Example</h1>
<div class="fragment"><div class="line"><span class="comment">// Create a 2D tensor (matrix) - automatically uses GPU if available</span></div>
<div class="line"><a class="code hl_class" href="classTensor.html">Tensor&lt;float, 2&gt;</a> matrix({3, 4});</div>
<div class="line">matrix.<a class="code hl_function" href="classTensor.html#a234f74cd16bd13561f7963ba29efb163">fill</a>(1.0f);</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Check which backend is being used</span></div>
<div class="line">std::cout &lt;&lt; <span class="stringliteral">&quot;Using: &quot;</span> &lt;&lt; <a class="code hl_function" href="#ae65fd500e7e89fd9a45a887f9c9b67e7">backend_name</a>(matrix.backend()) &lt;&lt; std::endl;</div>
<div class="line"> </div>
<div class="line"><span class="comment">// Enable gradient tracking</span></div>
<div class="line"><a class="code hl_class" href="classTensor.html">Tensor&lt;float, 2&gt;</a> x({2, 2}, <span class="keyword">true</span>, <span class="keyword">true</span>);  <span class="comment">// use_gpu=true, requires_grad=true</span></div>
<div class="line"><span class="keyword">auto</span> y = x * x;</div>
<div class="line">y.<a class="code hl_function" href="classTensor.html#ace4d96d1fc0d364577334241662fb60e">backward</a>();</div>
<div class="ttc" id="aclassTensor_html"><div class="ttname"><a href="classTensor.html">Tensor</a></div><div class="ttdoc">Forward declaration for autograd.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00444">tensor.h:444</a></div></div>
<div class="ttc" id="aclassTensor_html_a234f74cd16bd13561f7963ba29efb163"><div class="ttname"><a href="classTensor.html#a234f74cd16bd13561f7963ba29efb163">Tensor::fill</a></div><div class="ttdeci">void fill(const T &amp;value)</div><div class="ttdoc">Fill the tensor with a specified value.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00636">tensor.h:636</a></div></div>
<div class="ttc" id="aclassTensor_html_ace4d96d1fc0d364577334241662fb60e"><div class="ttname"><a href="classTensor.html#ace4d96d1fc0d364577334241662fb60e">Tensor::backward</a></div><div class="ttdeci">std::optional&lt; TensorError &gt; backward(const Tensor&lt; T, N &gt; *gradient=nullptr)</div><div class="ttdoc">Perform backward pass to compute gradients (autograd).</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00783">tensor.h:783</a></div></div>
<div class="ttc" id="atensor_8h_html_ae65fd500e7e89fd9a45a887f9c9b67e7"><div class="ttname"><a href="#ae65fd500e7e89fd9a45a887f9c9b67e7">backend_name</a></div><div class="ttdeci">std::string backend_name(Backend backend)</div><div class="ttdoc">Get the name of a backend as a string.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00181">tensor.h:181</a></div></div>
</div><!-- fragment --><h1 class="doxsection"><a class="anchor" id="features"></a>
Key Features</h1>
<ul>
<li><b>Type-safe</b>: Template-based compile-time dimension checking</li>
<li><b>High-performance</b>: Optimized with BLAS and GPU support</li>
<li><b>Autograd</b>: Automatic gradient computation for deep learning</li>
<li><b>Flexible</b>: Support for views, slicing, and broadcasting</li>
<li><b>Smart backend selection</b>: Automatically uses GPU  BLAS  CPU </li>
</ul>

<p class="definition">Definition in file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
</div><a name="doc-typedef-members" id="doc-typedef-members"></a><h2 id="header-doc-typedef-members" class="groupheader">Typedef Documentation</h2>
<a id="a1e846f46f87b55f57de12d6aa70eda1e" name="a1e846f46f87b55f57de12d6aa70eda1e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1e846f46f87b55f57de12d6aa70eda1e">&#9670;&#160;</a></span>BackwardFunc</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T, size_t N&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="#a1e846f46f87b55f57de12d6aa70eda1e">BackwardFunc</a> = std::function&lt;void(const <a class="el" href="classTensor.html">Tensor</a>&lt;T, N&gt;&amp;)&gt;</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Function type for backward pass in autograd. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>Data type (float, double, etc.) </td></tr>
    <tr><td class="paramname">N</td><td>Number of dimensions</td></tr>
  </table>
  </dd>
</dl>
<p>Used to store gradient computation functions in the computational graph. </p>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l00324">324</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>

</div>
</div>
<a id="ab58b5b2b06188fb918bfa78bdfce068b" name="ab58b5b2b06188fb918bfa78bdfce068b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab58b5b2b06188fb918bfa78bdfce068b">&#9670;&#160;</a></span>TensorIndices</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;size_t N&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a> = std::array&lt;size_t, N&gt;</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Type alias for tensor indices/coordinates. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">N</td><td>Number of dimensions</td></tr>
  </table>
  </dd>
</dl>
<p>Fixed-size array representing indices or coordinates in N-dimensional space. </p>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l00310">310</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>

</div>
</div>
<a id="a4eaf7c692573fd9dc1a450be56b68fcc" name="a4eaf7c692573fd9dc1a450be56b68fcc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4eaf7c692573fd9dc1a450be56b68fcc">&#9670;&#160;</a></span>TensorResult</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">using <a class="el" href="#a4eaf7c692573fd9dc1a450be56b68fcc">TensorResult</a> = std::variant&lt;T, <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaa">TensorError</a>&gt;</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Result type for tensor operations that may fail. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>The expected result type (usually a <a class="el" href="classTensor.html" title="Forward declaration for autograd.">Tensor</a>)</td></tr>
  </table>
  </dd>
</dl>
<p>Operations that can fail return a variant containing either the result or a <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaa" title="Error codes for tensor operations.">TensorError</a>. Use std::holds_alternative and std::get to access.</p>
<div class="fragment"><div class="line"><span class="keyword">auto</span> result = tensor1 + tensor2;</div>
<div class="line"><span class="keywordflow">if</span> (std::holds_alternative&lt;<a class="code hl_class" href="classTensor.html">Tensor&lt;float, 2&gt;</a>&gt;(result)) {</div>
<div class="line">    <span class="keyword">auto</span>&amp; tensor = std::get&lt;Tensor&lt;float, 2&gt;&gt;(result);</div>
<div class="line">    <span class="comment">// use tensor</span></div>
<div class="line">} <span class="keywordflow">else</span> {</div>
<div class="line">    <span class="keyword">auto</span> error = std::get&lt;TensorError&gt;(result);</div>
<div class="line">    <span class="comment">// handle error</span></div>
<div class="line">}</div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l00301">301</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>

</div>
</div>
<a name="doc-enum-members" id="doc-enum-members"></a><h2 id="header-doc-enum-members" class="groupheader">Enumeration Type Documentation</h2>
<a id="ae4db5848267c1a5a1413b7f87cf6889d" name="ae4db5848267c1a5a1413b7f87cf6889d"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae4db5848267c1a5a1413b7f87cf6889d">&#9670;&#160;</a></span>Backend</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">enum class <a class="el" href="#ae4db5848267c1a5a1413b7f87cf6889d">Backend</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel strong">strong</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Available computational backends. </p>
<p>Indicates which backend is being used for tensor operations. Priority order: GPU &gt; BLAS &gt; CPU </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="ae4db5848267c1a5a1413b7f87cf6889da2b55387dd066c5bac646ac61543d152d" name="ae4db5848267c1a5a1413b7f87cf6889da2b55387dd066c5bac646ac61543d152d"></a>CPU&#160;</td><td class="fielddoc"><p>Standard CPU implementation. </p>
</td></tr>
<tr><td class="fieldname"><a id="ae4db5848267c1a5a1413b7f87cf6889daf0c2cf06f9a01bc3a3ef50b116b18b51" name="ae4db5848267c1a5a1413b7f87cf6889daf0c2cf06f9a01bc3a3ef50b116b18b51"></a>BLAS&#160;</td><td class="fielddoc"><p>Optimized BLAS for CPU operations. </p>
</td></tr>
<tr><td class="fieldname"><a id="ae4db5848267c1a5a1413b7f87cf6889da52f9ec21735243ad9917cda3ca077d32" name="ae4db5848267c1a5a1413b7f87cf6889da52f9ec21735243ad9917cda3ca077d32"></a>GPU&#160;</td><td class="fielddoc"><p>CUDA GPU acceleration. </p>
</td></tr>
</table>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l00170">170</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  170</span>                   {</div>
<div class="line"><span class="lineno">  171</span>    <a class="code hl_enumvalue" href="#ae4db5848267c1a5a1413b7f87cf6889da2b55387dd066c5bac646ac61543d152d">CPU</a>,   </div>
<div class="line"><span class="lineno">  172</span>    <a class="code hl_enumvalue" href="#ae4db5848267c1a5a1413b7f87cf6889daf0c2cf06f9a01bc3a3ef50b116b18b51">BLAS</a>,  </div>
<div class="line"><span class="lineno">  173</span>    <a class="code hl_enumvalue" href="#ae4db5848267c1a5a1413b7f87cf6889da52f9ec21735243ad9917cda3ca077d32">GPU</a>    </div>
<div class="line"><span class="lineno">  174</span>};</div>
<div class="ttc" id="atensor_8h_html_ae4db5848267c1a5a1413b7f87cf6889da2b55387dd066c5bac646ac61543d152d"><div class="ttname"><a href="#ae4db5848267c1a5a1413b7f87cf6889da2b55387dd066c5bac646ac61543d152d">Backend::CPU</a></div><div class="ttdeci">@ CPU</div><div class="ttdoc">Standard CPU implementation.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00171">tensor.h:171</a></div></div>
<div class="ttc" id="atensor_8h_html_ae4db5848267c1a5a1413b7f87cf6889da52f9ec21735243ad9917cda3ca077d32"><div class="ttname"><a href="#ae4db5848267c1a5a1413b7f87cf6889da52f9ec21735243ad9917cda3ca077d32">Backend::GPU</a></div><div class="ttdeci">@ GPU</div><div class="ttdoc">CUDA GPU acceleration.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00173">tensor.h:173</a></div></div>
<div class="ttc" id="atensor_8h_html_ae4db5848267c1a5a1413b7f87cf6889daf0c2cf06f9a01bc3a3ef50b116b18b51"><div class="ttname"><a href="#ae4db5848267c1a5a1413b7f87cf6889daf0c2cf06f9a01bc3a3ef50b116b18b51">Backend::BLAS</a></div><div class="ttdeci">@ BLAS</div><div class="ttdoc">Optimized BLAS for CPU operations.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00172">tensor.h:172</a></div></div>
</div><!-- fragment -->
</div>
</div>
<a id="a2db6a67f5b95f95cb23a9d7b28deceaa" name="a2db6a67f5b95f95cb23a9d7b28deceaa"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a2db6a67f5b95f95cb23a9d7b28deceaa">&#9670;&#160;</a></span>TensorError</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">enum class <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaa">TensorError</a></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel strong">strong</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Error codes for tensor operations. </p>
<p>Provides enumeration of possible errors that can occur during tensor operations. These errors are returned as part of <a class="el" href="#a4eaf7c692573fd9dc1a450be56b68fcc" title="Result type for tensor operations that may fail.">TensorResult</a> variant type. </p>
<table class="fieldtable">
<tr><th colspan="2">Enumerator</th></tr><tr><td class="fieldname"><a id="a2db6a67f5b95f95cb23a9d7b28deceaaa2664c241558d7674e8ed4d5f63d2e463" name="a2db6a67f5b95f95cb23a9d7b28deceaaa2664c241558d7674e8ed4d5f63d2e463"></a>DimensionMismatch&#160;</td><td class="fielddoc"><p><a class="el" href="classTensor.html" title="Forward declaration for autograd.">Tensor</a> dimensions do not match for the operation. </p>
</td></tr>
<tr><td class="fieldname"><a id="a2db6a67f5b95f95cb23a9d7b28deceaaabb290efc01a42c7ed881f46a0477eca6" name="a2db6a67f5b95f95cb23a9d7b28deceaaabb290efc01a42c7ed881f46a0477eca6"></a>ContractionMismatch&#160;</td><td class="fielddoc"><p>Contraction dimensions are incompatible. </p>
</td></tr>
<tr><td class="fieldname"><a id="a2db6a67f5b95f95cb23a9d7b28deceaaa253ca7dd096ee0956cccee4d376cab8b" name="a2db6a67f5b95f95cb23a9d7b28deceaaa253ca7dd096ee0956cccee4d376cab8b"></a>InvalidArgument&#160;</td><td class="fielddoc"><p>Invalid argument provided to a function. </p>
</td></tr>
<tr><td class="fieldname"><a id="a2db6a67f5b95f95cb23a9d7b28deceaaade2e45aece7bcbb9fe7540cc9e11c40f" name="a2db6a67f5b95f95cb23a9d7b28deceaaade2e45aece7bcbb9fe7540cc9e11c40f"></a>SingularMatrix&#160;</td><td class="fielddoc"><p><a class="el" href="linalg_8h.html#aab91b0e1295509532b53ec846e227dcc" title="Type alias for 2D matrices.">Matrix</a> is singular (non-invertible). </p>
</td></tr>
<tr><td class="fieldname"><a id="a2db6a67f5b95f95cb23a9d7b28deceaaa5a386c59a2af4745f1107846201959ed" name="a2db6a67f5b95f95cb23a9d7b28deceaaa5a386c59a2af4745f1107846201959ed"></a>NotPositiveDefinite&#160;</td><td class="fielddoc"><p><a class="el" href="linalg_8h.html#aab91b0e1295509532b53ec846e227dcc" title="Type alias for 2D matrices.">Matrix</a> is not positive definite. </p>
</td></tr>
<tr><td class="fieldname"><a id="a2db6a67f5b95f95cb23a9d7b28deceaaa69d8864d8802ee76419e96eaa669295a" name="a2db6a67f5b95f95cb23a9d7b28deceaaa69d8864d8802ee76419e96eaa669295a"></a>NotSquare&#160;</td><td class="fielddoc"><p>Operation requires square matrix. </p>
</td></tr>
<tr><td class="fieldname"><a id="a2db6a67f5b95f95cb23a9d7b28deceaaa953002ae82f05e5c52b3e676992dacc6" name="a2db6a67f5b95f95cb23a9d7b28deceaaa953002ae82f05e5c52b3e676992dacc6"></a>EmptyMatrix&#160;</td><td class="fielddoc"><p><a class="el" href="linalg_8h.html#aab91b0e1295509532b53ec846e227dcc" title="Type alias for 2D matrices.">Matrix</a> is empty. </p>
</td></tr>
<tr><td class="fieldname"><a id="a2db6a67f5b95f95cb23a9d7b28deceaaaa1df5a085496d7c89611f837bf1d52ef" name="a2db6a67f5b95f95cb23a9d7b28deceaaaa1df5a085496d7c89611f837bf1d52ef"></a>LapackError&#160;</td><td class="fielddoc"><p>LAPACK routine error. </p>
</td></tr>
<tr><td class="fieldname"><a id="a2db6a67f5b95f95cb23a9d7b28deceaaa997ca4ce119685f40f03a9a8a6c5346e" name="a2db6a67f5b95f95cb23a9d7b28deceaaa997ca4ce119685f40f03a9a8a6c5346e"></a>NotImplemented&#160;</td><td class="fielddoc"><p>Feature not yet implemented. </p>
</td></tr>
</table>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l00240">240</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  240</span>                       {</div>
<div class="line"><span class="lineno">  241</span>    <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa2664c241558d7674e8ed4d5f63d2e463">DimensionMismatch</a>,    </div>
<div class="line"><span class="lineno">  242</span>    <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaabb290efc01a42c7ed881f46a0477eca6">ContractionMismatch</a>,  </div>
<div class="line"><span class="lineno">  243</span>    <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa253ca7dd096ee0956cccee4d376cab8b">InvalidArgument</a>,      </div>
<div class="line"><span class="lineno">  244</span>    <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaade2e45aece7bcbb9fe7540cc9e11c40f">SingularMatrix</a>,       </div>
<div class="line"><span class="lineno">  245</span>    <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa5a386c59a2af4745f1107846201959ed">NotPositiveDefinite</a>,  </div>
<div class="line"><span class="lineno">  246</span>    <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa69d8864d8802ee76419e96eaa669295a">NotSquare</a>,            </div>
<div class="line"><span class="lineno">  247</span>    <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa953002ae82f05e5c52b3e676992dacc6">EmptyMatrix</a>,          </div>
<div class="line"><span class="lineno">  248</span>    <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaaa1df5a085496d7c89611f837bf1d52ef">LapackError</a>,          </div>
<div class="line"><span class="lineno">  249</span>    <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa997ca4ce119685f40f03a9a8a6c5346e">NotImplemented</a>        </div>
<div class="line"><span class="lineno">  250</span>};</div>
<div class="ttc" id="atensor_8h_html_a2db6a67f5b95f95cb23a9d7b28deceaaa253ca7dd096ee0956cccee4d376cab8b"><div class="ttname"><a href="#a2db6a67f5b95f95cb23a9d7b28deceaaa253ca7dd096ee0956cccee4d376cab8b">TensorError::InvalidArgument</a></div><div class="ttdeci">@ InvalidArgument</div><div class="ttdoc">Invalid argument provided to a function.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00243">tensor.h:243</a></div></div>
<div class="ttc" id="atensor_8h_html_a2db6a67f5b95f95cb23a9d7b28deceaaa2664c241558d7674e8ed4d5f63d2e463"><div class="ttname"><a href="#a2db6a67f5b95f95cb23a9d7b28deceaaa2664c241558d7674e8ed4d5f63d2e463">TensorError::DimensionMismatch</a></div><div class="ttdeci">@ DimensionMismatch</div><div class="ttdoc">Tensor dimensions do not match for the operation.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00241">tensor.h:241</a></div></div>
<div class="ttc" id="atensor_8h_html_a2db6a67f5b95f95cb23a9d7b28deceaaa5a386c59a2af4745f1107846201959ed"><div class="ttname"><a href="#a2db6a67f5b95f95cb23a9d7b28deceaaa5a386c59a2af4745f1107846201959ed">TensorError::NotPositiveDefinite</a></div><div class="ttdeci">@ NotPositiveDefinite</div><div class="ttdoc">Matrix is not positive definite.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00245">tensor.h:245</a></div></div>
<div class="ttc" id="atensor_8h_html_a2db6a67f5b95f95cb23a9d7b28deceaaa69d8864d8802ee76419e96eaa669295a"><div class="ttname"><a href="#a2db6a67f5b95f95cb23a9d7b28deceaaa69d8864d8802ee76419e96eaa669295a">TensorError::NotSquare</a></div><div class="ttdeci">@ NotSquare</div><div class="ttdoc">Operation requires square matrix.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00246">tensor.h:246</a></div></div>
<div class="ttc" id="atensor_8h_html_a2db6a67f5b95f95cb23a9d7b28deceaaa953002ae82f05e5c52b3e676992dacc6"><div class="ttname"><a href="#a2db6a67f5b95f95cb23a9d7b28deceaaa953002ae82f05e5c52b3e676992dacc6">TensorError::EmptyMatrix</a></div><div class="ttdeci">@ EmptyMatrix</div><div class="ttdoc">Matrix is empty.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00247">tensor.h:247</a></div></div>
<div class="ttc" id="atensor_8h_html_a2db6a67f5b95f95cb23a9d7b28deceaaa997ca4ce119685f40f03a9a8a6c5346e"><div class="ttname"><a href="#a2db6a67f5b95f95cb23a9d7b28deceaaa997ca4ce119685f40f03a9a8a6c5346e">TensorError::NotImplemented</a></div><div class="ttdeci">@ NotImplemented</div><div class="ttdoc">Feature not yet implemented.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00249">tensor.h:249</a></div></div>
<div class="ttc" id="atensor_8h_html_a2db6a67f5b95f95cb23a9d7b28deceaaaa1df5a085496d7c89611f837bf1d52ef"><div class="ttname"><a href="#a2db6a67f5b95f95cb23a9d7b28deceaaaa1df5a085496d7c89611f837bf1d52ef">TensorError::LapackError</a></div><div class="ttdeci">@ LapackError</div><div class="ttdoc">LAPACK routine error.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00248">tensor.h:248</a></div></div>
<div class="ttc" id="atensor_8h_html_a2db6a67f5b95f95cb23a9d7b28deceaaabb290efc01a42c7ed881f46a0477eca6"><div class="ttname"><a href="#a2db6a67f5b95f95cb23a9d7b28deceaaabb290efc01a42c7ed881f46a0477eca6">TensorError::ContractionMismatch</a></div><div class="ttdeci">@ ContractionMismatch</div><div class="ttdoc">Contraction dimensions are incompatible.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00242">tensor.h:242</a></div></div>
<div class="ttc" id="atensor_8h_html_a2db6a67f5b95f95cb23a9d7b28deceaaade2e45aece7bcbb9fe7540cc9e11c40f"><div class="ttname"><a href="#a2db6a67f5b95f95cb23a9d7b28deceaaade2e45aece7bcbb9fe7540cc9e11c40f">TensorError::SingularMatrix</a></div><div class="ttdeci">@ SingularMatrix</div><div class="ttdoc">Matrix is singular (non-invertible).</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00244">tensor.h:244</a></div></div>
</div><!-- fragment -->
</div>
</div>
<a name="doc-func-members" id="doc-func-members"></a><h2 id="header-doc-func-members" class="groupheader">Function Documentation</h2>
<a id="abee606191f2a9544a7acbbd79094ed5b" name="abee606191f2a9544a7acbbd79094ed5b"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abee606191f2a9544a7acbbd79094ed5b">&#9670;&#160;</a></span>arange()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; arange </td>
          <td>(</td>
          <td class="paramtype">T</td>          <td class="paramname"><span class="paramname"><em>start</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T</td>          <td class="paramname"><span class="paramname"><em>stop</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T</td>          <td class="paramname"><span class="paramname"><em>step</em></span><span class="paramdefsep"> = </span><span class="paramdefval">T(1)</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>use_gpu</em></span><span class="paramdefsep"> = </span><span class="paramdefval">true</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create a tensor with values in a range (NumPy arange-compatible). </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>The data type </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">start</td><td>Start value (inclusive) </td></tr>
    <tr><td class="paramname">stop</td><td>Stop value (exclusive) </td></tr>
    <tr><td class="paramname">step</td><td>Step size </td></tr>
    <tr><td class="paramname">use_gpu</td><td>Whether to use GPU </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A 1D tensor with values from start to stop with given step </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06169">6169</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6169</span>                                                                         {</div>
<div class="line"><span class="lineno"> 6170</span>    <span class="keywordtype">size_t</span> n = <span class="keyword">static_cast&lt;</span><span class="keywordtype">size_t</span><span class="keyword">&gt;</span>((stop - start) / step);</div>
<div class="line"><span class="lineno"> 6171</span>    <span class="keywordflow">if</span> (n == 0) n = 1;</div>
<div class="line"><span class="lineno"> 6172</span>    </div>
<div class="line"><span class="lineno"> 6173</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 1&gt;</a> result({n}, use_gpu);</div>
<div class="line"><span class="lineno"> 6174</span>    T* data = result.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>();</div>
<div class="line"><span class="lineno"> 6175</span>    </div>
<div class="line"><span class="lineno"> 6176</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; n; ++i) {</div>
<div class="line"><span class="lineno"> 6177</span>        data[i] = start + i * step;</div>
<div class="line"><span class="lineno"> 6178</span>    }</div>
<div class="line"><span class="lineno"> 6179</span>    </div>
<div class="line"><span class="lineno"> 6180</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6181</span>}</div>
<div class="ttc" id="aclassTensor_html_a3f3c97d177cb960a4423afc3dafc612a"><div class="ttname"><a href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">Tensor::data_ptr</a></div><div class="ttdeci">const T * data_ptr() const</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00504">tensor.h:504</a></div></div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_abee606191f2a9544a7acbbd79094ed5b_cgraph.png" border="0" usemap="#atensor_8h_abee606191f2a9544a7acbbd79094ed5b_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_abee606191f2a9544a7acbbd79094ed5b_cgraph" id="atensor_8h_abee606191f2a9544a7acbbd79094ed5b_cgraph">
<area shape="rect" title="Create a tensor with values in a range (NumPy arange&#45;compatible)." alt="" coords="5,5,66,32"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="114,5,229,32"/>
<area shape="poly" title=" " alt="" coords="66,16,98,16,98,21,66,21"/>
</map>
</div>

</div>
</div>
<a id="a73f1eab7fbd472760c5d87a8acc9d7be" name="a73f1eab7fbd472760c5d87a8acc9d7be"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a73f1eab7fbd472760c5d87a8acc9d7be">&#9670;&#160;</a></span>are_broadcastable()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;size_t N1, size_t N2&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">bool are_broadcastable </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a>&lt; N1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>shape1</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a>&lt; N2 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>shape2</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">std::string *</td>          <td class="paramname"><span class="paramname"><em>error_msg</em></span><span class="paramdefsep"> = </span><span class="paramdefval">nullptr</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Check if two tensor shapes are broadcastable. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">N1</td><td>Number of dimensions in first tensor </td></tr>
    <tr><td class="paramname">N2</td><td>Number of dimensions in second tensor </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">shape1</td><td>Shape of first tensor </td></tr>
    <tr><td class="paramname">shape2</td><td>Shape of second tensor </td></tr>
    <tr><td class="paramname">error_msg</td><td>Optional pointer to store detailed error message </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>true if shapes are broadcastable, false otherwise</dd></dl>
<p>Two shapes are broadcastable if:</p><ul>
<li>They are equal, or</li>
<li>One of them is 1 This is checked for each dimension from right to left. </li>
</ul>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l05939">5939</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 5941</span>                                                       {</div>
<div class="line"><span class="lineno"> 5942</span>    <span class="comment">// Align shapes from the right (trailing dimensions)</span></div>
<div class="line"><span class="lineno"> 5943</span>    <span class="keywordtype">size_t</span> max_dims = std::max(N1, N2);</div>
<div class="line"><span class="lineno"> 5944</span>    <span class="keywordtype">size_t</span> offset1 = max_dims - N1;</div>
<div class="line"><span class="lineno"> 5945</span>    <span class="keywordtype">size_t</span> offset2 = max_dims - N2;</div>
<div class="line"><span class="lineno"> 5946</span>    </div>
<div class="line"><span class="lineno"> 5947</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; max_dims; ++i) {</div>
<div class="line"><span class="lineno"> 5948</span>        <span class="keywordtype">size_t</span> dim1 = (i &lt; offset1) ? 1 : shape1[i - offset1];</div>
<div class="line"><span class="lineno"> 5949</span>        <span class="keywordtype">size_t</span> dim2 = (i &lt; offset2) ? 1 : shape2[i - offset2];</div>
<div class="line"><span class="lineno"> 5950</span>        </div>
<div class="line"><span class="lineno"> 5951</span>        <span class="keywordflow">if</span> (dim1 != dim2 &amp;&amp; dim1 != 1 &amp;&amp; dim2 != 1) {</div>
<div class="line"><span class="lineno"> 5952</span>            <span class="keywordflow">if</span> (error_msg) {</div>
<div class="line"><span class="lineno"> 5953</span>                *error_msg = <span class="stringliteral">&quot;Shapes are not broadcastable: shape1[&quot;</span> + </div>
<div class="line"><span class="lineno"> 5954</span>                            std::to_string(i) + <span class="stringliteral">&quot;]=&quot;</span> + std::to_string(dim1) +</div>
<div class="line"><span class="lineno"> 5955</span>                            <span class="stringliteral">&quot; vs shape2[&quot;</span> + std::to_string(i) + <span class="stringliteral">&quot;]=&quot;</span> + </div>
<div class="line"><span class="lineno"> 5956</span>                            std::to_string(dim2);</div>
<div class="line"><span class="lineno"> 5957</span>            }</div>
<div class="line"><span class="lineno"> 5958</span>            <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><span class="lineno"> 5959</span>        }</div>
<div class="line"><span class="lineno"> 5960</span>    }</div>
<div class="line"><span class="lineno"> 5961</span>    <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno"> 5962</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a73f1eab7fbd472760c5d87a8acc9d7be_icgraph.png" border="0" usemap="#atensor_8h_a73f1eab7fbd472760c5d87a8acc9d7be_icgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a73f1eab7fbd472760c5d87a8acc9d7be_icgraph" id="atensor_8h_a73f1eab7fbd472760c5d87a8acc9d7be_icgraph">
<area shape="rect" title="Check if two tensor shapes are broadcastable." alt="" coords="231,31,358,57"/>
<area shape="rect" href="tensor_8h.html#a34fae58316c67748882059be5f1d153c" title="Broadcast a tensor to a new shape." alt="" coords="46,5,142,32"/>
<area shape="poly" title=" " alt="" coords="215,37,142,27,143,22,216,31"/>
<area shape="rect" href="tensor_8h.html#a9c62fb825b47530c2ec213d305b7c1d9" title="Compute the broadcast shape of two tensors." alt="" coords="5,56,183,83"/>
<area shape="poly" title=" " alt="" coords="216,57,183,61,183,55,215,51"/>
</map>
</div>

</div>
</div>
<a id="a1ce61bbd53890adec19f5b19f946ef26" name="a1ce61bbd53890adec19f5b19f946ef26"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1ce61bbd53890adec19f5b19f946ef26">&#9670;&#160;</a></span>argsort()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; size_t, 1 &gt; argsort </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>ascending</em></span><span class="paramdefsep"> = </span><span class="paramdefval">true</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Return indices that would sort the tensor (1D only). </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>Input tensor to get sort indices for. </td></tr>
    <tr><td class="paramname">ascending</td><td>If true, sort in ascending order; otherwise descending. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>1D tensor of indices. </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l05523">5523</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 5523</span>                                                                             {</div>
<div class="line"><span class="lineno"> 5524</span>    <span class="keywordtype">size_t</span> n = tensor.<a class="code hl_function" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7">total_size</a>();</div>
<div class="line"><span class="lineno"> 5525</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;size_t, 1&gt;</a> indices({n}, <span class="keyword">false</span>, <span class="keyword">false</span>);</div>
<div class="line"><span class="lineno"> 5526</span>    </div>
<div class="line"><span class="lineno"> 5527</span>    <span class="keywordtype">size_t</span>* indices_data = indices.<a class="code hl_function" href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4">data</a>();</div>
<div class="line"><span class="lineno"> 5528</span>    <span class="keyword">const</span> T* tensor_data = tensor.<a class="code hl_function" href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4">data</a>();</div>
<div class="line"><span class="lineno"> 5529</span>    </div>
<div class="line"><span class="lineno"> 5530</span>    <span class="comment">// Initialize indices</span></div>
<div class="line"><span class="lineno"> 5531</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; n; ++i) {</div>
<div class="line"><span class="lineno"> 5532</span>        indices_data[i] = i;</div>
<div class="line"><span class="lineno"> 5533</span>    }</div>
<div class="line"><span class="lineno"> 5534</span>    </div>
<div class="line"><span class="lineno"> 5535</span>    <span class="comment">// Sort indices based on tensor values</span></div>
<div class="line"><span class="lineno"> 5536</span>    <span class="keywordflow">if</span> (ascending) {</div>
<div class="line"><span class="lineno"> 5537</span>        std::sort(indices_data, indices_data + n,</div>
<div class="line"><span class="lineno"> 5538</span>                  [tensor_data](<span class="keywordtype">size_t</span> i1, <span class="keywordtype">size_t</span> i2) {</div>
<div class="line"><span class="lineno"> 5539</span>                      <span class="keywordflow">return</span> tensor_data[i1] &lt; tensor_data[i2];</div>
<div class="line"><span class="lineno"> 5540</span>                  });</div>
<div class="line"><span class="lineno"> 5541</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><span class="lineno"> 5542</span>        std::sort(indices_data, indices_data + n,</div>
<div class="line"><span class="lineno"> 5543</span>                  [tensor_data](<span class="keywordtype">size_t</span> i1, <span class="keywordtype">size_t</span> i2) {</div>
<div class="line"><span class="lineno"> 5544</span>                      <span class="keywordflow">return</span> tensor_data[i1] &gt; tensor_data[i2];</div>
<div class="line"><span class="lineno"> 5545</span>                  });</div>
<div class="line"><span class="lineno"> 5546</span>    }</div>
<div class="line"><span class="lineno"> 5547</span>    </div>
<div class="line"><span class="lineno"> 5548</span>    <span class="keywordflow">return</span> indices;</div>
<div class="line"><span class="lineno"> 5549</span>}</div>
<div class="ttc" id="aclassTensor_html_a07bf856a863505d2960b0bfad9c3b3f4"><div class="ttname"><a href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4">Tensor::data</a></div><div class="ttdeci">const T * data() const</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00523">tensor.h:523</a></div></div>
<div class="ttc" id="aclassTensor_html_aad6aeb4859940befd0c46f0b99388bd7"><div class="ttname"><a href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7">Tensor::total_size</a></div><div class="ttdeci">size_t total_size() const</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00511">tensor.h:511</a></div></div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a1ce61bbd53890adec19f5b19f946ef26_cgraph.png" border="0" usemap="#atensor_8h_a1ce61bbd53890adec19f5b19f946ef26_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a1ce61bbd53890adec19f5b19f946ef26_cgraph" id="atensor_8h_a1ce61bbd53890adec19f5b19f946ef26_cgraph">
<area shape="rect" title="Return indices that would sort the tensor (1D only)." alt="" coords="5,31,67,57"/>
<area shape="rect" href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4" title=" " alt="" coords="130,5,224,32"/>
<area shape="poly" title=" " alt="" coords="67,36,114,27,115,32,68,41"/>
<area shape="rect" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7" title=" " alt="" coords="115,56,239,83"/>
<area shape="poly" title=" " alt="" coords="68,47,100,53,99,58,67,52"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a1ce61bbd53890adec19f5b19f946ef26_icgraph.png" border="0" usemap="#atensor_8h_a1ce61bbd53890adec19f5b19f946ef26_icgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a1ce61bbd53890adec19f5b19f946ef26_icgraph" id="atensor_8h_a1ce61bbd53890adec19f5b19f946ef26_icgraph">
<area shape="rect" title="Return indices that would sort the tensor (1D only)." alt="" coords="100,5,161,32"/>
<area shape="rect" href="tensor_8h.html#a952343525fb5d9376af0645793e8f1d4" title="Find k largest or smallest elements and their indices (1D only)." alt="" coords="5,5,52,32"/>
<area shape="poly" title=" " alt="" coords="84,21,52,21,52,16,84,16"/>
</map>
</div>

</div>
</div>
<a id="a912e291f7a42f325c111def58ac98acf" name="a912e291f7a42f325c111def58ac98acf"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a912e291f7a42f325c111def58ac98acf">&#9670;&#160;</a></span>astype()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename U, typename T, size_t N&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; U, N &gt; astype </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Cast tensor to a different data type (NumPy-compatible astype). </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>Source data type </td></tr>
    <tr><td class="paramname">U</td><td>Target data type </td></tr>
    <tr><td class="paramname">N</td><td>Number of dimensions </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The input tensor </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with the target data type</dd></dl>
<p>This is the NumPy-compatible version of type casting.</p>
<p>Example: </p><div class="fragment"><div class="line"><a class="code hl_class" href="classTensor.html">Tensor&lt;int, 2&gt;</a> x({2, 3});</div>
<div class="line"><span class="keyword">auto</span> y = <a class="code hl_function" href="#a912e291f7a42f325c111def58ac98acf">astype&lt;float&gt;</a>(x);  <span class="comment">// Convert int tensor to float</span></div>
<div class="ttc" id="atensor_8h_html_a912e291f7a42f325c111def58ac98acf"><div class="ttname"><a href="#a912e291f7a42f325c111def58ac98acf">astype</a></div><div class="ttdeci">Tensor&lt; U, N &gt; astype(const Tensor&lt; T, N &gt; &amp;tensor)</div><div class="ttdoc">Cast tensor to a different data type (NumPy-compatible astype).</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l06096">tensor.h:6096</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06096">6096</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6096</span>                                                {</div>
<div class="line"><span class="lineno"> 6097</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;U, N&gt;</a> result(tensor.<a class="code hl_function" href="classTensor.html#a80b3ffaf92ed36f02d6f4d4230b5d2a0">shape</a>(), tensor.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>());</div>
<div class="line"><span class="lineno"> 6098</span>    </div>
<div class="line"><span class="lineno"> 6099</span>    <span class="keyword">const</span> T* src_data = tensor.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>();</div>
<div class="line"><span class="lineno"> 6100</span>    U* dst_data = result.data_ptr();</div>
<div class="line"><span class="lineno"> 6101</span>    <span class="keywordtype">size_t</span> total_size = tensor.<a class="code hl_function" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7">total_size</a>();</div>
<div class="line"><span class="lineno"> 6102</span>    </div>
<div class="line"><span class="lineno"> 6103</span><span class="preprocessor">    #pragma omp parallel for if(total_size &gt; 10000)</span></div>
<div class="line"><span class="lineno"> 6104</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; total_size; ++i) {</div>
<div class="line"><span class="lineno"> 6105</span>        dst_data[i] = <span class="keyword">static_cast&lt;</span>U<span class="keyword">&gt;</span>(src_data[i]);</div>
<div class="line"><span class="lineno"> 6106</span>    }</div>
<div class="line"><span class="lineno"> 6107</span>    </div>
<div class="line"><span class="lineno"> 6108</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6109</span>}</div>
<div class="ttc" id="aclassTensor_html_a80b3ffaf92ed36f02d6f4d4230b5d2a0"><div class="ttname"><a href="classTensor.html#a80b3ffaf92ed36f02d6f4d4230b5d2a0">Tensor::shape</a></div><div class="ttdeci">TensorIndices&lt; N &gt; shape() const</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00650">tensor.h:650</a></div></div>
<div class="ttc" id="aclassTensor_html_a83ae42925e21d2871d755407d7505c10"><div class="ttname"><a href="classTensor.html#a83ae42925e21d2871d755407d7505c10">Tensor::uses_gpu</a></div><div class="ttdeci">bool uses_gpu() const</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00656">tensor.h:656</a></div></div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a912e291f7a42f325c111def58ac98acf_cgraph.png" border="0" usemap="#atensor_8h_a912e291f7a42f325c111def58ac98acf_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a912e291f7a42f325c111def58ac98acf_cgraph" id="atensor_8h_a912e291f7a42f325c111def58ac98acf_cgraph">
<area shape="rect" title="Cast tensor to a different data type (NumPy&#45;compatible astype)." alt="" coords="5,81,66,108"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="118,5,234,32"/>
<area shape="poly" title=" " alt="" coords="54,78,112,42,123,36,125,41,115,46,57,83"/>
<area shape="rect" href="classTensor.html#a80b3ffaf92ed36f02d6f4d4230b5d2a0" title=" " alt="" coords="124,56,228,83"/>
<area shape="poly" title=" " alt="" coords="66,87,108,79,109,84,67,92"/>
<area shape="rect" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7" title=" " alt="" coords="114,107,238,133"/>
<area shape="poly" title=" " alt="" coords="67,97,99,103,98,109,66,103"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="114,157,238,184"/>
<area shape="poly" title=" " alt="" coords="57,106,115,143,125,148,123,153,112,148,54,111"/>
</map>
</div>

</div>
</div>
<a id="ae65fd500e7e89fd9a45a887f9c9b67e7" name="ae65fd500e7e89fd9a45a887f9c9b67e7"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae65fd500e7e89fd9a45a887f9c9b67e7">&#9670;&#160;</a></span>backend_name()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::string backend_name </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#ae4db5848267c1a5a1413b7f87cf6889d">Backend</a></td>          <td class="paramname"><span class="paramname"><em>backend</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the name of a backend as a string. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">backend</td><td>The backend enum value </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Human-readable name of the backend </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l00181">181</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  181</span>                                               {</div>
<div class="line"><span class="lineno">  182</span>    <span class="keywordflow">switch</span> (backend) {</div>
<div class="line"><span class="lineno">  183</span>        <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="#ae4db5848267c1a5a1413b7f87cf6889da2b55387dd066c5bac646ac61543d152d">Backend::CPU</a>: <span class="keywordflow">return</span> <span class="stringliteral">&quot;CPU&quot;</span>;</div>
<div class="line"><span class="lineno">  184</span>        <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="#ae4db5848267c1a5a1413b7f87cf6889daf0c2cf06f9a01bc3a3ef50b116b18b51">Backend::BLAS</a>: <span class="keywordflow">return</span> <span class="stringliteral">&quot;BLAS&quot;</span>;</div>
<div class="line"><span class="lineno">  185</span>        <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="#ae4db5848267c1a5a1413b7f87cf6889da52f9ec21735243ad9917cda3ca077d32">Backend::GPU</a>: <span class="keywordflow">return</span> <span class="stringliteral">&quot;GPU&quot;</span>;</div>
<div class="line"><span class="lineno">  186</span>        <span class="keywordflow">default</span>: <span class="keywordflow">return</span> <span class="stringliteral">&quot;Unknown&quot;</span>;</div>
<div class="line"><span class="lineno">  187</span>    }</div>
<div class="line"><span class="lineno">  188</span>}</div>
</div><!-- fragment -->
</div>
</div>
<a id="adc912199dacbff108e0d2cadfae000df" name="adc912199dacbff108e0d2cadfae000df"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adc912199dacbff108e0d2cadfae000df">&#9670;&#160;</a></span>block()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; block </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>matrix</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>start_row</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>start_col</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>num_rows</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>num_cols</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Extract a rectangular block from a 2D tensor. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>Data type </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">matrix</td><td>2D tensor </td></tr>
    <tr><td class="paramname">start_row</td><td>Starting row index </td></tr>
    <tr><td class="paramname">start_col</td><td>Starting column index </td></tr>
    <tr><td class="paramname">num_rows</td><td>Number of rows to extract </td></tr>
    <tr><td class="paramname">num_cols</td><td>Number of columns to extract </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>2D tensor containing the block</dd></dl>
<div class="fragment"><div class="line"><a class="code hl_class" href="classTensor.html">Tensor&lt;float, 2&gt;</a> mat({10, 10});</div>
<div class="line"><span class="keyword">auto</span> <a class="code hl_function" href="#adc912199dacbff108e0d2cadfae000df">block</a> = mat.block(2, 3, 4, 5);  <span class="comment">// 4x5 block starting at (2,3)</span></div>
<div class="ttc" id="atensor_8h_html_adc912199dacbff108e0d2cadfae000df"><div class="ttname"><a href="#adc912199dacbff108e0d2cadfae000df">block</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; block(const Tensor&lt; T, 2 &gt; &amp;matrix, size_t start_row, size_t start_col, size_t num_rows, size_t num_cols)</div><div class="ttdoc">Extract a rectangular block from a 2D tensor.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l06774">tensor.h:6774</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06774">6774</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6775</span>                                                     {</div>
<div class="line"><span class="lineno"> 6776</span>    <span class="keyword">auto</span> dims = matrix.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>();</div>
<div class="line"><span class="lineno"> 6777</span>    <span class="keywordflow">if</span> (start_row + num_rows &gt; dims[0] || start_col + num_cols &gt; dims[1]) {</div>
<div class="line"><span class="lineno"> 6778</span>        <span class="keywordflow">throw</span> std::out_of_range(<span class="stringliteral">&quot;Block exceeds matrix bounds&quot;</span>);</div>
<div class="line"><span class="lineno"> 6779</span>    }</div>
<div class="line"><span class="lineno"> 6780</span>    </div>
<div class="line"><span class="lineno"> 6781</span>    <span class="keywordtype">size_t</span> cols = dims[1];</div>
<div class="line"><span class="lineno"> 6782</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> result({num_rows, num_cols}, matrix.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>());</div>
<div class="line"><span class="lineno"> 6783</span>    </div>
<div class="line"><span class="lineno"> 6784</span>    <span class="keyword">const</span> T* src = matrix.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>();</div>
<div class="line"><span class="lineno"> 6785</span>    T* dst = result.data_ptr();</div>
<div class="line"><span class="lineno"> 6786</span>    </div>
<div class="line"><span class="lineno"> 6787</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; num_rows; ++i) {</div>
<div class="line"><span class="lineno"> 6788</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; num_cols; ++j) {</div>
<div class="line"><span class="lineno"> 6789</span>            dst[i * num_cols + j] = src[(start_row + i) * cols + (start_col + j)];</div>
<div class="line"><span class="lineno"> 6790</span>        }</div>
<div class="line"><span class="lineno"> 6791</span>    }</div>
<div class="line"><span class="lineno"> 6792</span>    </div>
<div class="line"><span class="lineno"> 6793</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6794</span>}</div>
<div class="ttc" id="aclassTensor_html_a03d314303958ffc5644796d8025cd012"><div class="ttname"><a href="classTensor.html#a03d314303958ffc5644796d8025cd012">Tensor::dims</a></div><div class="ttdeci">TensorIndices&lt; N &gt; dims() const</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00644">tensor.h:644</a></div></div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_adc912199dacbff108e0d2cadfae000df_cgraph.png" border="0" usemap="#atensor_8h_adc912199dacbff108e0d2cadfae000df_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_adc912199dacbff108e0d2cadfae000df_cgraph" id="atensor_8h_adc912199dacbff108e0d2cadfae000df_cgraph">
<area shape="rect" title="Extract a rectangular block from a 2D tensor." alt="" coords="5,56,58,83"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="110,5,226,32"/>
<area shape="poly" title=" " alt="" coords="57,57,115,35,117,40,59,62"/>
<area shape="rect" href="classTensor.html#a03d314303958ffc5644796d8025cd012" title=" " alt="" coords="120,56,216,83"/>
<area shape="poly" title=" " alt="" coords="58,67,104,67,104,72,58,72"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="106,107,230,133"/>
<area shape="poly" title=" " alt="" coords="59,76,117,98,115,103,57,81"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_adc912199dacbff108e0d2cadfae000df_icgraph.png" border="0" usemap="#atensor_8h_adc912199dacbff108e0d2cadfae000df_icgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_adc912199dacbff108e0d2cadfae000df_icgraph" id="atensor_8h_adc912199dacbff108e0d2cadfae000df_icgraph">
<area shape="rect" title="Extract a rectangular block from a 2D tensor." alt="" coords="237,31,289,57"/>
<area shape="rect" href="classMemoryPool.html#a980db306a49ce0f4b149198a99b6d24e" title="Clear all pooled memory." alt="" coords="32,5,162,32"/>
<area shape="poly" title=" " alt="" coords="221,40,162,31,163,26,221,35"/>
<area shape="rect" href="classMemoryPool.html#a842e63c49f94b807e42b8ed5897bd1bb" title="Destructor &#45; frees all pooled memory." alt="" coords="5,56,189,83"/>
<area shape="poly" title=" " alt="" coords="221,53,189,58,188,53,220,48"/>
</map>
</div>

</div>
</div>
<a id="aa94ca571f8bc2b76cd1bdb6fd851c556" name="aa94ca571f8bc2b76cd1bdb6fd851c556"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa94ca571f8bc2b76cd1bdb6fd851c556">&#9670;&#160;</a></span>bottomRows()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; bottomRows </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>matrix</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>n</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Extract bottom n rows from a 2D tensor. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>Data type </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">matrix</td><td>2D tensor </td></tr>
    <tr><td class="paramname">n</td><td>Number of rows to extract </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>2D tensor containing bottom n rows</dd></dl>
<div class="fragment"><div class="line"><a class="code hl_class" href="classTensor.html">Tensor&lt;float, 2&gt;</a> mat({10, 5});</div>
<div class="line"><span class="keyword">auto</span> bottom3 = mat.<a class="code hl_function" href="classTensor.html#a8ecd760521443aca3613911d9af40d5a">bottomRows</a>(3);</div>
<div class="ttc" id="aclassTensor_html_a8ecd760521443aca3613911d9af40d5a"><div class="ttname"><a href="classTensor.html#a8ecd760521443aca3613911d9af40d5a">Tensor::bottomRows</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; bottomRows(size_t n) const</div><div class="ttdoc">Extract bottom n rows (only for 2D tensors).</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l05113">tensor.h:5113</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06880">6880</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6880</span>                                                              {</div>
<div class="line"><span class="lineno"> 6881</span>    <span class="keyword">auto</span> dims = matrix.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>();</div>
<div class="line"><span class="lineno"> 6882</span>    <span class="keywordtype">size_t</span> rows = dims[0];</div>
<div class="line"><span class="lineno"> 6883</span>    <span class="keywordtype">size_t</span> cols = dims[1];</div>
<div class="line"><span class="lineno"> 6884</span>    <span class="keywordflow">if</span> (n &gt; rows) n = rows;</div>
<div class="line"><span class="lineno"> 6885</span>    </div>
<div class="line"><span class="lineno"> 6886</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> result({n, cols}, matrix.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>());</div>
<div class="line"><span class="lineno"> 6887</span>    std::copy_n(matrix.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>() + (rows - n) * cols, n * cols, result.data_ptr());</div>
<div class="line"><span class="lineno"> 6888</span>    </div>
<div class="line"><span class="lineno"> 6889</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6890</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_aa94ca571f8bc2b76cd1bdb6fd851c556_cgraph.png" border="0" usemap="#atensor_8h_aa94ca571f8bc2b76cd1bdb6fd851c556_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_aa94ca571f8bc2b76cd1bdb6fd851c556_cgraph" id="atensor_8h_aa94ca571f8bc2b76cd1bdb6fd851c556_cgraph">
<area shape="rect" title="Extract bottom n rows from a 2D tensor." alt="" coords="5,56,101,83"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="153,5,268,32"/>
<area shape="poly" title=" " alt="" coords="96,53,152,35,153,40,98,58"/>
<area shape="rect" href="classTensor.html#a03d314303958ffc5644796d8025cd012" title=" " alt="" coords="163,56,259,83"/>
<area shape="poly" title=" " alt="" coords="101,67,147,67,147,72,101,72"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="149,107,273,133"/>
<area shape="poly" title=" " alt="" coords="98,81,153,99,152,104,96,86"/>
</map>
</div>

</div>
</div>
<a id="a34fae58316c67748882059be5f1d153c" name="a34fae58316c67748882059be5f1d153c"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a34fae58316c67748882059be5f1d153c">&#9670;&#160;</a></span>broadcast_to()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T, size_t N, size_t M&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">auto broadcast_to </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a>&lt; M &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>target_shape</em></span>&#160;)-&gt;std::variant&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T, M &gt;, <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaa">TensorError</a> &gt;</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Broadcast a tensor to a new shape. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>The data type </td></tr>
    <tr><td class="paramname">N</td><td>The number of dimensions </td></tr>
    <tr><td class="paramname">M</td><td>The number of dimensions in target shape </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The input tensor </td></tr>
    <tr><td class="paramname">target_shape</td><td>The target shape to broadcast to </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with the broadcast shape, or <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaa" title="Error codes for tensor operations.">TensorError</a> on failure</dd></dl>
<dl class="section note"><dt>Note</dt><dd>This creates a new tensor with data copied according to broadcast rules. Broadcasting rules (NumPy-compatible):<ul>
<li>Prepend dimensions of size 1 if needed</li>
<li>For each dimension, sizes must either match or one must be 1</li>
<li>Dimensions of size 1 are "stretched" to match the target</li>
</ul>
</dd></dl>
<p>Example: </p><div class="fragment"><div class="line"><a class="code hl_class" href="classTensor.html">Tensor&lt;float, 1&gt;</a> x({3});</div>
<div class="line"><span class="keyword">auto</span> result = <a class="code hl_function" href="#a34fae58316c67748882059be5f1d153c">broadcast_to</a>(x, {4, 3});  <span class="comment">// Shape (3,) -&gt; (4, 3)</span></div>
<div class="ttc" id="atensor_8h_html_a34fae58316c67748882059be5f1d153c"><div class="ttname"><a href="#a34fae58316c67748882059be5f1d153c">broadcast_to</a></div><div class="ttdeci">auto broadcast_to(const Tensor&lt; T, N &gt; &amp;tensor, const TensorIndices&lt; M &gt; &amp;target_shape) -&gt; std::variant&lt; Tensor&lt; T, M &gt;, TensorError &gt;</div><div class="ttdoc">Broadcast a tensor to a new shape.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l06018">tensor.h:6018</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06018">6018</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6019</span>                                             {</div>
<div class="line"><span class="lineno"> 6020</span>    </div>
<div class="line"><span class="lineno"> 6021</span>    <span class="comment">// Check if broadcasting is valid</span></div>
<div class="line"><span class="lineno"> 6022</span>    std::string error_msg;</div>
<div class="line"><span class="lineno"> 6023</span>    <span class="keywordflow">if</span> (!<a class="code hl_function" href="#a73f1eab7fbd472760c5d87a8acc9d7be">are_broadcastable</a>(tensor.<a class="code hl_function" href="classTensor.html#a80b3ffaf92ed36f02d6f4d4230b5d2a0">shape</a>(), target_shape, &amp;error_msg)) {</div>
<div class="line"><span class="lineno"> 6024</span>        <span class="keywordflow">return</span> <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa2664c241558d7674e8ed4d5f63d2e463">TensorError::DimensionMismatch</a>;</div>
<div class="line"><span class="lineno"> 6025</span>    }</div>
<div class="line"><span class="lineno"> 6026</span>    </div>
<div class="line"><span class="lineno"> 6027</span>    <span class="comment">// Create result tensor</span></div>
<div class="line"><span class="lineno"> 6028</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, M&gt;</a> result(target_shape, tensor.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>());</div>
<div class="line"><span class="lineno"> 6029</span>    </div>
<div class="line"><span class="lineno"> 6030</span>    <span class="comment">// Get raw pointers</span></div>
<div class="line"><span class="lineno"> 6031</span>    <span class="keyword">const</span> T* src_data = tensor.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>();</div>
<div class="line"><span class="lineno"> 6032</span>    T* dst_data = result.data_ptr();</div>
<div class="line"><span class="lineno"> 6033</span>    </div>
<div class="line"><span class="lineno"> 6034</span>    <span class="comment">// Compute strides for broadcasting</span></div>
<div class="line"><span class="lineno"> 6035</span>    <span class="keywordtype">size_t</span> offset = M - N;</div>
<div class="line"><span class="lineno"> 6036</span>    <a class="code hl_typedef" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices&lt;M&gt;</a> src_strides;</div>
<div class="line"><span class="lineno"> 6037</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; M; ++i) {</div>
<div class="line"><span class="lineno"> 6038</span>        <span class="keywordflow">if</span> (i &lt; offset) {</div>
<div class="line"><span class="lineno"> 6039</span>            src_strides[i] = 0;  <span class="comment">// New dimension, don&#39;t advance</span></div>
<div class="line"><span class="lineno"> 6040</span>        } <span class="keywordflow">else</span> {</div>
<div class="line"><span class="lineno"> 6041</span>            <span class="keywordtype">size_t</span> src_dim = i - offset;</div>
<div class="line"><span class="lineno"> 6042</span>            <span class="keywordflow">if</span> (tensor.<a class="code hl_function" href="classTensor.html#a80b3ffaf92ed36f02d6f4d4230b5d2a0">shape</a>()[src_dim] == 1) {</div>
<div class="line"><span class="lineno"> 6043</span>                src_strides[i] = 0;  <span class="comment">// Broadcast this dimension</span></div>
<div class="line"><span class="lineno"> 6044</span>            } <span class="keywordflow">else</span> {</div>
<div class="line"><span class="lineno"> 6045</span>                src_strides[i] = tensor.<a class="code hl_function" href="classTensor.html#a938d78600782073a1ff2725066b46c85">strides</a>()[src_dim];</div>
<div class="line"><span class="lineno"> 6046</span>            }</div>
<div class="line"><span class="lineno"> 6047</span>        }</div>
<div class="line"><span class="lineno"> 6048</span>    }</div>
<div class="line"><span class="lineno"> 6049</span>    </div>
<div class="line"><span class="lineno"> 6050</span>    <span class="comment">// Fill result with broadcast data</span></div>
<div class="line"><span class="lineno"> 6051</span>    <span class="keywordtype">size_t</span> total_size = result.total_size();</div>
<div class="line"><span class="lineno"> 6052</span>    </div>
<div class="line"><span class="lineno"> 6053</span><span class="preprocessor">    #pragma omp parallel for if(total_size &gt; 10000)</span></div>
<div class="line"><span class="lineno"> 6054</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; total_size; ++i) {</div>
<div class="line"><span class="lineno"> 6055</span>        <span class="comment">// Convert flat index to multi-dimensional coordinates</span></div>
<div class="line"><span class="lineno"> 6056</span>        <a class="code hl_typedef" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices&lt;M&gt;</a> coords;</div>
<div class="line"><span class="lineno"> 6057</span>        <span class="keywordtype">size_t</span> idx = i;</div>
<div class="line"><span class="lineno"> 6058</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> d = M; d &gt; 0; --d) {</div>
<div class="line"><span class="lineno"> 6059</span>            coords[d - 1] = idx % target_shape[d - 1];</div>
<div class="line"><span class="lineno"> 6060</span>            idx /= target_shape[d - 1];</div>
<div class="line"><span class="lineno"> 6061</span>        }</div>
<div class="line"><span class="lineno"> 6062</span>        </div>
<div class="line"><span class="lineno"> 6063</span>        <span class="comment">// Map to source index using broadcast strides</span></div>
<div class="line"><span class="lineno"> 6064</span>        <span class="keywordtype">size_t</span> src_idx = 0;</div>
<div class="line"><span class="lineno"> 6065</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> d = 0; d &lt; M; ++d) {</div>
<div class="line"><span class="lineno"> 6066</span>            src_idx += coords[d] * src_strides[d];</div>
<div class="line"><span class="lineno"> 6067</span>        }</div>
<div class="line"><span class="lineno"> 6068</span>        </div>
<div class="line"><span class="lineno"> 6069</span>        dst_data[i] = src_data[src_idx];</div>
<div class="line"><span class="lineno"> 6070</span>    }</div>
<div class="line"><span class="lineno"> 6071</span>    </div>
<div class="line"><span class="lineno"> 6072</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6073</span>}</div>
<div class="ttc" id="aclassTensor_html_a938d78600782073a1ff2725066b46c85"><div class="ttname"><a href="classTensor.html#a938d78600782073a1ff2725066b46c85">Tensor::strides</a></div><div class="ttdeci">const TensorIndices&lt; N &gt; &amp; strides() const</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00530">tensor.h:530</a></div></div>
<div class="ttc" id="atensor_8h_html_a73f1eab7fbd472760c5d87a8acc9d7be"><div class="ttname"><a href="#a73f1eab7fbd472760c5d87a8acc9d7be">are_broadcastable</a></div><div class="ttdeci">bool are_broadcastable(const TensorIndices&lt; N1 &gt; &amp;shape1, const TensorIndices&lt; N2 &gt; &amp;shape2, std::string *error_msg=nullptr)</div><div class="ttdoc">Check if two tensor shapes are broadcastable.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l05939">tensor.h:5939</a></div></div>
<div class="ttc" id="atensor_8h_html_ab58b5b2b06188fb918bfa78bdfce068b"><div class="ttname"><a href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a></div><div class="ttdeci">std::array&lt; size_t, N &gt; TensorIndices</div><div class="ttdoc">Type alias for tensor indices/coordinates.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00310">tensor.h:310</a></div></div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a34fae58316c67748882059be5f1d153c_cgraph.png" border="0" usemap="#atensor_8h_a34fae58316c67748882059be5f1d153c_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a34fae58316c67748882059be5f1d153c_cgraph" id="atensor_8h_a34fae58316c67748882059be5f1d153c_cgraph">
<area shape="rect" title="Broadcast a tensor to a new shape." alt="" coords="5,56,102,83"/>
<area shape="rect" href="tensor_8h.html#a73f1eab7fbd472760c5d87a8acc9d7be" title="Check if two tensor shapes are broadcastable." alt="" coords="150,5,277,32"/>
<area shape="poly" title=" " alt="" coords="97,53,154,35,155,40,99,58"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="156,56,271,83"/>
<area shape="poly" title=" " alt="" coords="102,67,140,67,140,72,102,72"/>
<area shape="rect" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7" title=" " alt="" coords="151,107,276,133"/>
<area shape="poly" title=" " alt="" coords="99,81,155,99,154,104,97,86"/>
</map>
</div>

</div>
</div>
<a id="a64dfa8c2475ed50ae00ef1d4e1c12fd2" name="a64dfa8c2475ed50ae00ef1d4e1c12fd2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a64dfa8c2475ed50ae00ef1d4e1c12fd2">&#9670;&#160;</a></span>chunk()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T, size_t N&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &gt; chunk </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>chunk_size</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>axis</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Divide tensor into equal-sized chunks (last chunk may be smaller). </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>Input tensor to divide into chunks. </td></tr>
    <tr><td class="paramname">chunk_size</td><td>Size of each chunk along the axis. </td></tr>
    <tr><td class="paramname">axis</td><td>Axis along which to divide. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="linalg_8h.html#a99ba6a0becc538dc0109d3818ca80f3b" title="Type alias for 1D vectors.">Vector</a> of tensors. </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l05728">5728</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 5728</span>                                                                                              {</div>
<div class="line"><span class="lineno"> 5729</span>    <span class="keywordflow">if</span> (axis &gt;= N || chunk_size == 0) {</div>
<div class="line"><span class="lineno"> 5730</span>        <span class="keywordflow">return</span> {tensor};</div>
<div class="line"><span class="lineno"> 5731</span>    }</div>
<div class="line"><span class="lineno"> 5732</span>    </div>
<div class="line"><span class="lineno"> 5733</span>    <span class="keyword">auto</span> dims = tensor.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>();</div>
<div class="line"><span class="lineno"> 5734</span>    <span class="keywordtype">size_t</span> dim_size = dims[axis];</div>
<div class="line"><span class="lineno"> 5735</span>    <span class="keywordtype">size_t</span> num_chunks = (dim_size + chunk_size - 1) / chunk_size;</div>
<div class="line"><span class="lineno"> 5736</span>    </div>
<div class="line"><span class="lineno"> 5737</span>    std::vector&lt;Tensor&lt;T, N&gt;&gt; chunks;</div>
<div class="line"><span class="lineno"> 5738</span>    chunks.reserve(num_chunks);</div>
<div class="line"><span class="lineno"> 5739</span>    </div>
<div class="line"><span class="lineno"> 5740</span>    <span class="comment">// Compute strides for indexing</span></div>
<div class="line"><span class="lineno"> 5741</span>    std::array&lt;size_t, N&gt; strides;</div>
<div class="line"><span class="lineno"> 5742</span>    strides[N-1] = 1;</div>
<div class="line"><span class="lineno"> 5743</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = N-1; i-- &gt; 0;) {</div>
<div class="line"><span class="lineno"> 5744</span>        strides[i] = strides[i+1] * dims[i+1];</div>
<div class="line"><span class="lineno"> 5745</span>    }</div>
<div class="line"><span class="lineno"> 5746</span>    </div>
<div class="line"><span class="lineno"> 5747</span>    <span class="keywordtype">size_t</span> start = 0;</div>
<div class="line"><span class="lineno"> 5748</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> chunk_idx = 0; chunk_idx &lt; num_chunks; ++chunk_idx) {</div>
<div class="line"><span class="lineno"> 5749</span>        <span class="comment">// Each chunk gets chunk_size elements, except last may be smaller</span></div>
<div class="line"><span class="lineno"> 5750</span>        <span class="keywordtype">size_t</span> current_chunk_size = std::min(chunk_size, dim_size - start);</div>
<div class="line"><span class="lineno"> 5751</span>        </div>
<div class="line"><span class="lineno"> 5752</span>        <span class="keywordflow">if</span> (current_chunk_size == 0) <span class="keywordflow">break</span>;</div>
<div class="line"><span class="lineno"> 5753</span>        </div>
<div class="line"><span class="lineno"> 5754</span>        <span class="comment">// Create new dimensions for the chunk</span></div>
<div class="line"><span class="lineno"> 5755</span>        <span class="keyword">auto</span> chunk_dims = dims;</div>
<div class="line"><span class="lineno"> 5756</span>        chunk_dims[axis] = current_chunk_size;</div>
<div class="line"><span class="lineno"> 5757</span>        </div>
<div class="line"><span class="lineno"> 5758</span>        <a class="code hl_class" href="classTensor.html">Tensor&lt;T, N&gt;</a> <a class="code hl_function" href="#a64dfa8c2475ed50ae00ef1d4e1c12fd2">chunk</a>(chunk_dims, tensor.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>(), <span class="keyword">false</span>);</div>
<div class="line"><span class="lineno"> 5759</span>        </div>
<div class="line"><span class="lineno"> 5760</span>        std::array&lt;size_t, N&gt; chunk_strides;</div>
<div class="line"><span class="lineno"> 5761</span>        chunk_strides[N-1] = 1;</div>
<div class="line"><span class="lineno"> 5762</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = N-1; i-- &gt; 0;) {</div>
<div class="line"><span class="lineno"> 5763</span>            chunk_strides[i] = chunk_strides[i+1] * chunk_dims[i+1];</div>
<div class="line"><span class="lineno"> 5764</span>        }</div>
<div class="line"><span class="lineno"> 5765</span>        </div>
<div class="line"><span class="lineno"> 5766</span>        <span class="comment">// Copy data</span></div>
<div class="line"><span class="lineno"> 5767</span>        <span class="keywordtype">size_t</span> chunk_total = <a class="code hl_function" href="#a64dfa8c2475ed50ae00ef1d4e1c12fd2">chunk</a>.total_size();</div>
<div class="line"><span class="lineno"> 5768</span>        <span class="keyword">const</span> T* src_data = tensor.<a class="code hl_function" href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4">data</a>();</div>
<div class="line"><span class="lineno"> 5769</span>        T* dst_data = <a class="code hl_function" href="#a64dfa8c2475ed50ae00ef1d4e1c12fd2">chunk</a>.data();</div>
<div class="line"><span class="lineno"> 5770</span>        </div>
<div class="line"><span class="lineno"> 5771</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; chunk_total; ++i) {</div>
<div class="line"><span class="lineno"> 5772</span>            <span class="comment">// Convert flat index to coordinates in chunk</span></div>
<div class="line"><span class="lineno"> 5773</span>            std::array&lt;size_t, N&gt; coords;</div>
<div class="line"><span class="lineno"> 5774</span>            <span class="keywordtype">size_t</span> remaining = i;</div>
<div class="line"><span class="lineno"> 5775</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> d = 0; d &lt; N; ++d) {</div>
<div class="line"><span class="lineno"> 5776</span>                coords[d] = remaining / chunk_strides[d];</div>
<div class="line"><span class="lineno"> 5777</span>                remaining %= chunk_strides[d];</div>
<div class="line"><span class="lineno"> 5778</span>            }</div>
<div class="line"><span class="lineno"> 5779</span>            </div>
<div class="line"><span class="lineno"> 5780</span>            <span class="comment">// Adjust coordinate on split axis</span></div>
<div class="line"><span class="lineno"> 5781</span>            coords[axis] += start;</div>
<div class="line"><span class="lineno"> 5782</span>            </div>
<div class="line"><span class="lineno"> 5783</span>            <span class="comment">// Convert to flat index in source</span></div>
<div class="line"><span class="lineno"> 5784</span>            <span class="keywordtype">size_t</span> src_idx = 0;</div>
<div class="line"><span class="lineno"> 5785</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> d = 0; d &lt; N; ++d) {</div>
<div class="line"><span class="lineno"> 5786</span>                src_idx += coords[d] * strides[d];</div>
<div class="line"><span class="lineno"> 5787</span>            }</div>
<div class="line"><span class="lineno"> 5788</span>            </div>
<div class="line"><span class="lineno"> 5789</span>            dst_data[i] = src_data[src_idx];</div>
<div class="line"><span class="lineno"> 5790</span>        }</div>
<div class="line"><span class="lineno"> 5791</span>        </div>
<div class="line"><span class="lineno"> 5792</span>        chunks.push_back(std::move(<a class="code hl_function" href="#a64dfa8c2475ed50ae00ef1d4e1c12fd2">chunk</a>));</div>
<div class="line"><span class="lineno"> 5793</span>        start += current_chunk_size;</div>
<div class="line"><span class="lineno"> 5794</span>    }</div>
<div class="line"><span class="lineno"> 5795</span>    </div>
<div class="line"><span class="lineno"> 5796</span>    <span class="keywordflow">return</span> chunks;</div>
<div class="line"><span class="lineno"> 5797</span>}</div>
<div class="ttc" id="atensor_8h_html_a64dfa8c2475ed50ae00ef1d4e1c12fd2"><div class="ttname"><a href="#a64dfa8c2475ed50ae00ef1d4e1c12fd2">chunk</a></div><div class="ttdeci">std::vector&lt; Tensor&lt; T, N &gt; &gt; chunk(const Tensor&lt; T, N &gt; &amp;tensor, size_t chunk_size, size_t axis=0)</div><div class="ttdoc">Divide tensor into equal-sized chunks (last chunk may be smaller).</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l05728">tensor.h:5728</a></div></div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a64dfa8c2475ed50ae00ef1d4e1c12fd2_cgraph.png" border="0" usemap="#atensor_8h_a64dfa8c2475ed50ae00ef1d4e1c12fd2_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a64dfa8c2475ed50ae00ef1d4e1c12fd2_cgraph" id="atensor_8h_a64dfa8c2475ed50ae00ef1d4e1c12fd2_cgraph">
<area shape="rect" title="Divide tensor into equal&#45;sized chunks (last chunk may be smaller)." alt="" coords="5,56,62,83"/>
<area shape="poly" title=" " alt="" coords="9,57,5,47,8,38,18,32,34,29,51,32,60,39,56,43,48,37,33,35,20,37,12,41,10,47,14,54"/>
<area shape="rect" href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4" title=" " alt="" coords="125,5,218,32"/>
<area shape="poly" title=" " alt="" coords="61,57,118,35,120,40,63,62"/>
<area shape="rect" href="classTensor.html#a03d314303958ffc5644796d8025cd012" title=" " alt="" coords="124,56,220,83"/>
<area shape="poly" title=" " alt="" coords="62,67,108,67,108,72,62,72"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="110,107,234,133"/>
<area shape="poly" title=" " alt="" coords="63,77,120,98,118,103,61,82"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a64dfa8c2475ed50ae00ef1d4e1c12fd2_icgraph.png" border="0" usemap="#atensor_8h_a64dfa8c2475ed50ae00ef1d4e1c12fd2_icgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a64dfa8c2475ed50ae00ef1d4e1c12fd2_icgraph" id="atensor_8h_a64dfa8c2475ed50ae00ef1d4e1c12fd2_icgraph">
<area shape="rect" title="Divide tensor into equal&#45;sized chunks (last chunk may be smaller)." alt="" coords="99,29,155,56"/>
<area shape="poly" title=" " alt="" coords="142,16,137,10,127,8,117,10,112,14,111,20,114,28,109,30,106,20,108,11,115,5,127,3,139,5,146,12"/>
<area shape="rect" href="tensor_8h.html#a139335a446015c5f7ad70fa3d2ccfbec" title="Split tensor into chunks along specified axis." alt="" coords="5,29,51,56"/>
<area shape="poly" title=" " alt="" coords="83,45,51,45,51,40,83,40"/>
</map>
</div>

</div>
</div>
<a id="a5f2a03f722ba5a985a3733e2ff823a74" name="a5f2a03f722ba5a985a3733e2ff823a74"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a5f2a03f722ba5a985a3733e2ff823a74">&#9670;&#160;</a></span>col()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; col </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>matrix</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>col_idx</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Extract a single column from a 2D tensor. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>Data type </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">matrix</td><td>2D tensor </td></tr>
    <tr><td class="paramname">col_idx</td><td>Column index to extract </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>1D tensor containing the column</dd></dl>
<div class="fragment"><div class="line"><a class="code hl_class" href="classTensor.html">Tensor&lt;float, 2&gt;</a> mat({5, 3});</div>
<div class="line"><span class="keyword">auto</span> col1 = mat.<a class="code hl_function" href="classTensor.html#a42cef0c31a6dcf0846d2c6e2d24e7240">col</a>(1);  <span class="comment">// Extract 2nd column</span></div>
<div class="ttc" id="aclassTensor_html_a42cef0c31a6dcf0846d2c6e2d24e7240"><div class="ttname"><a href="classTensor.html#a42cef0c31a6dcf0846d2c6e2d24e7240">Tensor::col</a></div><div class="ttdeci">Tensor&lt; T, 1 &gt; col(size_t col_idx) const</div><div class="ttdoc">Extract a single column (only for 2D tensors).</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l05050">tensor.h:5050</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06680">6680</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6680</span>                                                             {</div>
<div class="line"><span class="lineno"> 6681</span>    <span class="keyword">auto</span> dims = matrix.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>();</div>
<div class="line"><span class="lineno"> 6682</span>    <span class="keywordflow">if</span> (col_idx &gt;= dims[1]) {</div>
<div class="line"><span class="lineno"> 6683</span>        <span class="keywordflow">throw</span> std::out_of_range(<span class="stringliteral">&quot;Column index out of bounds&quot;</span>);</div>
<div class="line"><span class="lineno"> 6684</span>    }</div>
<div class="line"><span class="lineno"> 6685</span>    </div>
<div class="line"><span class="lineno"> 6686</span>    <span class="keywordtype">size_t</span> rows = dims[0];</div>
<div class="line"><span class="lineno"> 6687</span>    <span class="keywordtype">size_t</span> cols = dims[1];</div>
<div class="line"><span class="lineno"> 6688</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 1&gt;</a> result({rows}, matrix.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>());</div>
<div class="line"><span class="lineno"> 6689</span>    </div>
<div class="line"><span class="lineno"> 6690</span>    <span class="keyword">const</span> T* src = matrix.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>();</div>
<div class="line"><span class="lineno"> 6691</span>    T* dst = result.data_ptr();</div>
<div class="line"><span class="lineno"> 6692</span>    </div>
<div class="line"><span class="lineno"> 6693</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; rows; ++i) {</div>
<div class="line"><span class="lineno"> 6694</span>        dst[i] = src[i * cols + col_idx];</div>
<div class="line"><span class="lineno"> 6695</span>    }</div>
<div class="line"><span class="lineno"> 6696</span>    </div>
<div class="line"><span class="lineno"> 6697</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6698</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a5f2a03f722ba5a985a3733e2ff823a74_cgraph.png" border="0" usemap="#atensor_8h_a5f2a03f722ba5a985a3733e2ff823a74_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a5f2a03f722ba5a985a3733e2ff823a74_cgraph" id="atensor_8h_a5f2a03f722ba5a985a3733e2ff823a74_cgraph">
<area shape="rect" title="Extract a single column from a 2D tensor." alt="" coords="5,56,44,83"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="96,5,212,32"/>
<area shape="poly" title=" " alt="" coords="43,60,103,36,105,41,45,65"/>
<area shape="rect" href="classTensor.html#a03d314303958ffc5644796d8025cd012" title=" " alt="" coords="106,56,202,83"/>
<area shape="poly" title=" " alt="" coords="44,67,90,67,90,72,44,72"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="92,107,216,133"/>
<area shape="poly" title=" " alt="" coords="45,74,105,98,103,103,43,79"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a5f2a03f722ba5a985a3733e2ff823a74_icgraph.png" border="0" usemap="#atensor_8h_a5f2a03f722ba5a985a3733e2ff823a74_icgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a5f2a03f722ba5a985a3733e2ff823a74_icgraph" id="atensor_8h_a5f2a03f722ba5a985a3733e2ff823a74_icgraph">
<area shape="rect" title="Extract a single column from a 2D tensor." alt="" coords="562,208,601,235"/>
<area shape="rect" href="namespacelinalg.html#a6b7af062b5a9642d788fcc084335b39c" title=" " alt="" coords="368,5,509,32"/>
<area shape="poly" title=" " alt="" coords="575,193,568,159,557,120,539,80,512,46,497,35,500,30,516,42,543,77,562,118,573,158,580,192"/>
<area shape="rect" href="tensor__c_8cpp.html#a1d2268dec0e2609a5de6ddad0045383e" title=" " alt="" coords="375,56,502,83"/>
<area shape="poly" title=" " alt="" coords="570,194,549,144,533,119,513,97,495,86,498,81,516,93,537,115,554,142,575,192"/>
<area shape="rect" href="tensor__c_8cpp.html#a6caf88ca765b604eab7b9bab9f47ee10" title=" " alt="" coords="363,107,514,133"/>
<area shape="poly" title=" " alt="" coords="561,197,540,171,513,148,491,136,494,132,516,143,543,167,565,193"/>
<area shape="rect" href="tensor__c_8cpp.html#a876c89ce000825fa6255ea8c7649aefe" title=" " alt="" coords="375,157,502,184"/>
<area shape="poly" title=" " alt="" coords="547,211,513,199,481,187,483,182,515,193,549,206"/>
<area shape="rect" href="tensor__c_8cpp.html#a5a98f19069ba7a51f436659c6a6941b7" title=" " alt="" coords="382,208,496,235"/>
<area shape="poly" title=" " alt="" coords="547,224,496,224,496,219,547,219"/>
<area shape="rect" href="tensor__c_8cpp.html#a036fdfc552daa9f0aa2030e56775d327" title=" " alt="" coords="370,259,508,285"/>
<area shape="poly" title=" " alt="" coords="549,237,515,249,483,261,481,256,513,244,547,232"/>
<area shape="rect" href="tensor__c_8cpp.html#aafb2ff8a91dff85dbf7c6d8a91297a31" title=" " alt="" coords="382,309,496,336"/>
<area shape="poly" title=" " alt="" coords="565,249,543,276,516,300,494,311,491,306,513,295,540,272,561,246"/>
<area shape="rect" href="namespacelinalg.html#ad07d8335c6ed4ffb675492effc453771" title=" " alt="" coords="396,360,481,387"/>
<area shape="poly" title=" " alt="" coords="575,251,554,301,537,327,516,350,500,361,483,368,480,363,498,356,513,346,533,324,549,299,570,249"/>
<area shape="rect" href="namespacelinalg.html#a61b846dd17050c602c624ff0a898d617" title=" " alt="" coords="394,411,484,437"/>
<area shape="poly" title=" " alt="" coords="580,251,573,285,562,325,543,365,516,401,502,411,486,418,483,413,499,407,512,397,539,362,557,323,568,283,575,250"/>
<area shape="rect" href="namespacelinalg.html#a0e459857cd625f66948d7ae48731b17a" title="Compute numerical rank of a matrix using SVD." alt="" coords="188,360,315,387"/>
<area shape="poly" title=" " alt="" coords="381,376,315,376,315,371,381,371"/>
<area shape="rect" href="tensor__c_8cpp.html#af30504e8e051a714b7a0fdcae0f7c636" title=" " alt="" coords="5,335,140,361"/>
<area shape="poly" title=" " alt="" coords="172,365,139,360,140,355,173,360"/>
<area shape="rect" href="tensor__c_8cpp.html#ab1f7ff7476a784a17149afa2fd100d07" title=" " alt="" coords="12,385,133,412"/>
<area shape="poly" title=" " alt="" coords="173,387,134,393,133,387,172,382"/>
</map>
</div>

</div>
</div>
<a id="a9c62fb825b47530c2ec213d305b7c1d9" name="a9c62fb825b47530c2ec213d305b7c1d9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a9c62fb825b47530c2ec213d305b7c1d9">&#9670;&#160;</a></span>compute_broadcast_shape()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;size_t N1, size_t N2&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">auto compute_broadcast_shape </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a>&lt; N1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>shape1</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a>&lt; N2 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>shape2</em></span>&#160;)-&gt;std::variant&lt; <a class="el" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a>&lt; std::max(N1, N2)&gt;, <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaa">TensorError</a> &gt;</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Compute the broadcast shape of two tensors. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">N1</td><td>Number of dimensions in first tensor </td></tr>
    <tr><td class="paramname">N2</td><td>Number of dimensions in second tensor </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">shape1</td><td>Shape of first tensor </td></tr>
    <tr><td class="paramname">shape2</td><td>Shape of second tensor </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>The broadcast shape (variant with <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaa" title="Error codes for tensor operations.">TensorError</a> on failure) </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l05973">5973</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 5975</span>                                                              {</div>
<div class="line"><span class="lineno"> 5976</span>    <span class="keyword">constexpr</span> <span class="keywordtype">size_t</span> MaxN = std::max(N1, N2);</div>
<div class="line"><span class="lineno"> 5977</span>    <a class="code hl_typedef" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices&lt;MaxN&gt;</a> result;</div>
<div class="line"><span class="lineno"> 5978</span>    </div>
<div class="line"><span class="lineno"> 5979</span>    std::string error_msg;</div>
<div class="line"><span class="lineno"> 5980</span>    <span class="keywordflow">if</span> (!<a class="code hl_function" href="#a73f1eab7fbd472760c5d87a8acc9d7be">are_broadcastable</a>(shape1, shape2, &amp;error_msg)) {</div>
<div class="line"><span class="lineno"> 5981</span>        <span class="keywordflow">return</span> <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa2664c241558d7674e8ed4d5f63d2e463">TensorError::DimensionMismatch</a>;</div>
<div class="line"><span class="lineno"> 5982</span>    }</div>
<div class="line"><span class="lineno"> 5983</span>    </div>
<div class="line"><span class="lineno"> 5984</span>    <span class="keywordtype">size_t</span> offset1 = MaxN - N1;</div>
<div class="line"><span class="lineno"> 5985</span>    <span class="keywordtype">size_t</span> offset2 = MaxN - N2;</div>
<div class="line"><span class="lineno"> 5986</span>    </div>
<div class="line"><span class="lineno"> 5987</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; MaxN; ++i) {</div>
<div class="line"><span class="lineno"> 5988</span>        <span class="keywordtype">size_t</span> dim1 = (i &lt; offset1) ? 1 : shape1[i - offset1];</div>
<div class="line"><span class="lineno"> 5989</span>        <span class="keywordtype">size_t</span> dim2 = (i &lt; offset2) ? 1 : shape2[i - offset2];</div>
<div class="line"><span class="lineno"> 5990</span>        result[i] = std::max(dim1, dim2);</div>
<div class="line"><span class="lineno"> 5991</span>    }</div>
<div class="line"><span class="lineno"> 5992</span>    </div>
<div class="line"><span class="lineno"> 5993</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 5994</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a9c62fb825b47530c2ec213d305b7c1d9_cgraph.png" border="0" usemap="#atensor_8h_a9c62fb825b47530c2ec213d305b7c1d9_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a9c62fb825b47530c2ec213d305b7c1d9_cgraph" id="atensor_8h_a9c62fb825b47530c2ec213d305b7c1d9_cgraph">
<area shape="rect" title="Compute the broadcast shape of two tensors." alt="" coords="5,5,183,32"/>
<area shape="rect" href="tensor_8h.html#a73f1eab7fbd472760c5d87a8acc9d7be" title="Check if two tensor shapes are broadcastable." alt="" coords="231,5,358,32"/>
<area shape="poly" title=" " alt="" coords="183,16,215,16,215,21,183,21"/>
</map>
</div>

</div>
</div>
<a id="a3331b6cf4ac182d022336e4d068a0e58" name="a3331b6cf4ac182d022336e4d068a0e58"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3331b6cf4ac182d022336e4d068a0e58">&#9670;&#160;</a></span>copy()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T, size_t N&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; copy </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create a copy of a tensor (NumPy-compatible). </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>The data type </td></tr>
    <tr><td class="paramname">N</td><td>The number of dimensions </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The input tensor </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor that is a copy of the input </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06123">6123</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6123</span>                                              {</div>
<div class="line"><span class="lineno"> 6124</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, N&gt;</a> result(tensor.<a class="code hl_function" href="classTensor.html#a80b3ffaf92ed36f02d6f4d4230b5d2a0">shape</a>(), tensor.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>());</div>
<div class="line"><span class="lineno"> 6125</span>    std::copy_n(tensor.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>(), tensor.<a class="code hl_function" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7">total_size</a>(), result.data_ptr());</div>
<div class="line"><span class="lineno"> 6126</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6127</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a3331b6cf4ac182d022336e4d068a0e58_cgraph.png" border="0" usemap="#atensor_8h_a3331b6cf4ac182d022336e4d068a0e58_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a3331b6cf4ac182d022336e4d068a0e58_cgraph" id="atensor_8h_a3331b6cf4ac182d022336e4d068a0e58_cgraph">
<area shape="rect" title="Create a copy of a tensor (NumPy&#45;compatible)." alt="" coords="5,81,55,108"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="107,5,222,32"/>
<area shape="poly" title=" " alt="" coords="47,79,101,42,111,37,114,41,104,46,50,83"/>
<area shape="rect" href="classTensor.html#a80b3ffaf92ed36f02d6f4d4230b5d2a0" title=" " alt="" coords="113,56,216,83"/>
<area shape="poly" title=" " alt="" coords="54,88,98,79,99,85,55,93"/>
<area shape="rect" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7" title=" " alt="" coords="103,107,227,133"/>
<area shape="poly" title=" " alt="" coords="55,97,88,103,87,108,54,102"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="103,157,227,184"/>
<area shape="poly" title=" " alt="" coords="50,106,104,143,114,148,111,153,101,148,47,110"/>
</map>
</div>

</div>
</div>
<a id="a43014e3309494c3851da86be3a162194" name="a43014e3309494c3851da86be3a162194"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a43014e3309494c3851da86be3a162194">&#9670;&#160;</a></span>diag()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; diag </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>matrix</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Extract the diagonal of a 2D tensor. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>Data type </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">matrix</td><td>2D tensor </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>1D tensor containing diagonal elements</dd></dl>
<p>For non-square matrices, extracts min(rows, cols) diagonal elements. </p><div class="fragment"><div class="line"><a class="code hl_class" href="classTensor.html">Tensor&lt;float, 2&gt;</a> mat({3, 3});</div>
<div class="line"><span class="keyword">auto</span> diagonal = mat.<a class="code hl_function" href="classTensor.html#af46e252ac24e0557b28c177bd9070596">diag</a>();</div>
<div class="ttc" id="aclassTensor_html_af46e252ac24e0557b28c177bd9070596"><div class="ttname"><a href="classTensor.html#af46e252ac24e0557b28c177bd9070596">Tensor::diag</a></div><div class="ttdeci">Tensor&lt; T, 1 &gt; diag() const</div><div class="ttdoc">Extract diagonal elements (only for 2D tensors).</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l05059">tensor.h:5059</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06713">6713</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6713</span>                                              {</div>
<div class="line"><span class="lineno"> 6714</span>    <span class="keyword">auto</span> dims = matrix.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>();</div>
<div class="line"><span class="lineno"> 6715</span>    <span class="keywordtype">size_t</span> rows = dims[0];</div>
<div class="line"><span class="lineno"> 6716</span>    <span class="keywordtype">size_t</span> cols = dims[1];</div>
<div class="line"><span class="lineno"> 6717</span>    <span class="keywordtype">size_t</span> diag_size = std::min(rows, cols);</div>
<div class="line"><span class="lineno"> 6718</span>    </div>
<div class="line"><span class="lineno"> 6719</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 1&gt;</a> result({diag_size}, matrix.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>());</div>
<div class="line"><span class="lineno"> 6720</span>    </div>
<div class="line"><span class="lineno"> 6721</span>    <span class="keyword">const</span> T* src = matrix.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>();</div>
<div class="line"><span class="lineno"> 6722</span>    T* dst = result.data_ptr();</div>
<div class="line"><span class="lineno"> 6723</span>    </div>
<div class="line"><span class="lineno"> 6724</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; diag_size; ++i) {</div>
<div class="line"><span class="lineno"> 6725</span>        dst[i] = src[i * cols + i];</div>
<div class="line"><span class="lineno"> 6726</span>    }</div>
<div class="line"><span class="lineno"> 6727</span>    </div>
<div class="line"><span class="lineno"> 6728</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6729</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a43014e3309494c3851da86be3a162194_cgraph.png" border="0" usemap="#atensor_8h_a43014e3309494c3851da86be3a162194_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a43014e3309494c3851da86be3a162194_cgraph" id="atensor_8h_a43014e3309494c3851da86be3a162194_cgraph">
<area shape="rect" title="Extract the diagonal of a 2D tensor." alt="" coords="5,56,51,83"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="103,5,218,32"/>
<area shape="poly" title=" " alt="" coords="50,58,108,36,110,41,52,63"/>
<area shape="rect" href="classTensor.html#a03d314303958ffc5644796d8025cd012" title=" " alt="" coords="113,56,209,83"/>
<area shape="poly" title=" " alt="" coords="51,67,97,67,97,72,51,72"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="99,107,223,133"/>
<area shape="poly" title=" " alt="" coords="52,75,110,98,108,103,50,80"/>
</map>
</div>

</div>
</div>
<a id="ae66ddfcd20907014f524982e01698d82" name="ae66ddfcd20907014f524982e01698d82"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ae66ddfcd20907014f524982e01698d82">&#9670;&#160;</a></span>diag_matrix()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; diag_matrix </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>vec</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create a diagonal matrix from a 1D tensor. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>Data type </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">vec</td><td>1D tensor containing diagonal values </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>2D square matrix with vec on diagonal, zeros elsewhere</dd></dl>
<div class="fragment"><div class="line"><a class="code hl_class" href="classTensor.html">Tensor&lt;float, 1&gt;</a> vec({3});</div>
<div class="line"><span class="keyword">auto</span> mat = <a class="code hl_function" href="#ae66ddfcd20907014f524982e01698d82">diag_matrix</a>(vec);  <span class="comment">// Creates 3x3 diagonal matrix</span></div>
<div class="ttc" id="atensor_8h_html_ae66ddfcd20907014f524982e01698d82"><div class="ttname"><a href="#ae66ddfcd20907014f524982e01698d82">diag_matrix</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; diag_matrix(const Tensor&lt; T, 1 &gt; &amp;vec)</div><div class="ttdoc">Create a diagonal matrix from a 1D tensor.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l06743">tensor.h:6743</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06743">6743</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6743</span>                                                  {</div>
<div class="line"><span class="lineno"> 6744</span>    <span class="keywordtype">size_t</span> n = vec.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>()[0];</div>
<div class="line"><span class="lineno"> 6745</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> result({n, n}, vec.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>());</div>
<div class="line"><span class="lineno"> 6746</span>    result.fill(T(0));</div>
<div class="line"><span class="lineno"> 6747</span>    </div>
<div class="line"><span class="lineno"> 6748</span>    <span class="keyword">const</span> T* src = vec.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>();</div>
<div class="line"><span class="lineno"> 6749</span>    T* dst = result.data_ptr();</div>
<div class="line"><span class="lineno"> 6750</span>    </div>
<div class="line"><span class="lineno"> 6751</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; n; ++i) {</div>
<div class="line"><span class="lineno"> 6752</span>        dst[i * n + i] = src[i];</div>
<div class="line"><span class="lineno"> 6753</span>    }</div>
<div class="line"><span class="lineno"> 6754</span>    </div>
<div class="line"><span class="lineno"> 6755</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6756</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_ae66ddfcd20907014f524982e01698d82_cgraph.png" border="0" usemap="#atensor_8h_ae66ddfcd20907014f524982e01698d82_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_ae66ddfcd20907014f524982e01698d82_cgraph" id="atensor_8h_ae66ddfcd20907014f524982e01698d82_cgraph">
<area shape="rect" title="Create a diagonal matrix from a 1D tensor." alt="" coords="5,81,94,108"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="146,5,262,32"/>
<area shape="poly" title=" " alt="" coords="73,78,140,42,153,36,155,41,143,46,75,83"/>
<area shape="rect" href="classTensor.html#a03d314303958ffc5644796d8025cd012" title=" " alt="" coords="156,56,252,83"/>
<area shape="poly" title=" " alt="" coords="94,85,140,77,141,82,95,90"/>
<area shape="rect" href="classTensor.html#a234f74cd16bd13561f7963ba29efb163" title="Fill the tensor with a specified value." alt="" coords="163,107,244,133"/>
<area shape="poly" title=" " alt="" coords="95,99,148,108,147,113,94,105"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="142,157,266,184"/>
<area shape="poly" title=" " alt="" coords="75,106,143,143,155,148,153,153,140,148,73,111"/>
</map>
</div>

</div>
</div>
<a id="a8a0e6e335b72a473208ce2c8f17b4a6e" name="a8a0e6e335b72a473208ce2c8f17b4a6e"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8a0e6e335b72a473208ce2c8f17b4a6e">&#9670;&#160;</a></span>eye()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; eye </td>
          <td>(</td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>n</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>use_gpu</em></span><span class="paramdefsep"> = </span><span class="paramdefval">true</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create an identity matrix (NumPy eye-compatible). </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>The data type </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">n</td><td>Size of the square matrix </td></tr>
    <tr><td class="paramname">use_gpu</td><td>Whether to use GPU </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>An nn identity matrix </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06247">6247</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6247</span>                                                {</div>
<div class="line"><span class="lineno"> 6248</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> result({n, n}, use_gpu);</div>
<div class="line"><span class="lineno"> 6249</span>    result.<a class="code hl_function" href="classTensor.html#a234f74cd16bd13561f7963ba29efb163">fill</a>(T(0));</div>
<div class="line"><span class="lineno"> 6250</span>    T* data = result.data_ptr();</div>
<div class="line"><span class="lineno"> 6251</span>    </div>
<div class="line"><span class="lineno"> 6252</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; n; ++i) {</div>
<div class="line"><span class="lineno"> 6253</span>        data[i * n + i] = T(1);</div>
<div class="line"><span class="lineno"> 6254</span>    }</div>
<div class="line"><span class="lineno"> 6255</span>    </div>
<div class="line"><span class="lineno"> 6256</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6257</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a8a0e6e335b72a473208ce2c8f17b4a6e_cgraph.png" border="0" usemap="#atensor_8h_a8a0e6e335b72a473208ce2c8f17b4a6e_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a8a0e6e335b72a473208ce2c8f17b4a6e_cgraph" id="atensor_8h_a8a0e6e335b72a473208ce2c8f17b4a6e_cgraph">
<area shape="rect" title="Create an identity matrix (NumPy eye&#45;compatible)." alt="" coords="5,5,48,32"/>
<area shape="rect" href="classTensor.html#a234f74cd16bd13561f7963ba29efb163" title="Fill the tensor with a specified value." alt="" coords="96,5,177,32"/>
<area shape="poly" title=" " alt="" coords="48,16,80,16,80,21,48,21"/>
</map>
</div>

</div>
</div>
<a id="a46e409633222975e3723ab74a190a8a5" name="a46e409633222975e3723ab74a190a8a5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a46e409633222975e3723ab74a190a8a5">&#9670;&#160;</a></span>get_active_backend()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="#ae4db5848267c1a5a1413b7f87cf6889d">Backend</a> get_active_backend </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Get the currently active backend. </p>
<dl class="section return"><dt>Returns</dt><dd>The backend being used by default</dd></dl>
<p>This function checks at runtime which backend is available and will be used for new tensor operations. Priority: GPU &gt; BLAS &gt; CPU </p>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l00197">197</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  197</span>                                    {</div>
<div class="line"><span class="lineno">  198</span><span class="preprocessor">#ifdef USE_GPU</span></div>
<div class="line"><span class="lineno">  199</span>    <span class="keywordflow">if</span> (TensorGPU::is_gpu_available()) {</div>
<div class="line"><span class="lineno">  200</span>        <span class="keywordflow">return</span> <a class="code hl_enumvalue" href="#ae4db5848267c1a5a1413b7f87cf6889da52f9ec21735243ad9917cda3ca077d32">Backend::GPU</a>;</div>
<div class="line"><span class="lineno">  201</span>    }</div>
<div class="line"><span class="lineno">  202</span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="lineno">  203</span><span class="preprocessor">#ifdef USE_BLAS</span></div>
<div class="line"><span class="lineno">  204</span>    <span class="keywordflow">return</span> <a class="code hl_enumvalue" href="#ae4db5848267c1a5a1413b7f87cf6889daf0c2cf06f9a01bc3a3ef50b116b18b51">Backend::BLAS</a>;</div>
<div class="line"><span class="lineno">  205</span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="lineno">  206</span>    <span class="keywordflow">return</span> <a class="code hl_enumvalue" href="#ae4db5848267c1a5a1413b7f87cf6889da2b55387dd066c5bac646ac61543d152d">Backend::CPU</a>;</div>
<div class="line"><span class="lineno">  207</span>}</div>
</div><!-- fragment -->
</div>
</div>
<a id="a04c7965d0b8f08cfdb84580050e9e0b5" name="a04c7965d0b8f08cfdb84580050e9e0b5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a04c7965d0b8f08cfdb84580050e9e0b5">&#9670;&#160;</a></span>head()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; head </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>vec</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>n</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Extract first n elements from a 1D tensor. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>Data type </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">vec</td><td>1D tensor </td></tr>
    <tr><td class="paramname">n</td><td>Number of elements to extract </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>1D tensor containing first n elements</dd></dl>
<div class="fragment"><div class="line"><a class="code hl_class" href="classTensor.html">Tensor&lt;float, 1&gt;</a> vec({10});</div>
<div class="line"><span class="keyword">auto</span> first5 = vec.<a class="code hl_function" href="classTensor.html#a89cf45ee5d7ddfdf69a387c2345039c7">head</a>(5);</div>
<div class="ttc" id="aclassTensor_html_a89cf45ee5d7ddfdf69a387c2345039c7"><div class="ttname"><a href="classTensor.html#a89cf45ee5d7ddfdf69a387c2345039c7">Tensor::head</a></div><div class="ttdeci">Tensor&lt; T, 1 &gt; head(size_t n) const</div><div class="ttdoc">Extract first n elements (only for 1D tensors).</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l05083">tensor.h:5083</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06809">6809</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6809</span>                                                     {</div>
<div class="line"><span class="lineno"> 6810</span>    <span class="keywordtype">size_t</span> size = vec.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>()[0];</div>
<div class="line"><span class="lineno"> 6811</span>    <span class="keywordflow">if</span> (n &gt; size) n = size;</div>
<div class="line"><span class="lineno"> 6812</span>    </div>
<div class="line"><span class="lineno"> 6813</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 1&gt;</a> result({n}, vec.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>());</div>
<div class="line"><span class="lineno"> 6814</span>    std::copy_n(vec.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>(), n, result.data_ptr());</div>
<div class="line"><span class="lineno"> 6815</span>    </div>
<div class="line"><span class="lineno"> 6816</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6817</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a04c7965d0b8f08cfdb84580050e9e0b5_cgraph.png" border="0" usemap="#atensor_8h_a04c7965d0b8f08cfdb84580050e9e0b5_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a04c7965d0b8f08cfdb84580050e9e0b5_cgraph" id="atensor_8h_a04c7965d0b8f08cfdb84580050e9e0b5_cgraph">
<area shape="rect" title="Extract first n elements from a 1D tensor." alt="" coords="5,56,55,83"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="107,5,222,32"/>
<area shape="poly" title=" " alt="" coords="54,58,112,36,114,40,56,63"/>
<area shape="rect" href="classTensor.html#a03d314303958ffc5644796d8025cd012" title=" " alt="" coords="117,56,213,83"/>
<area shape="poly" title=" " alt="" coords="55,67,102,67,102,72,55,72"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="103,107,227,133"/>
<area shape="poly" title=" " alt="" coords="56,76,114,98,112,103,54,81"/>
</map>
</div>

</div>
</div>
<a id="a3c3ae83e0bf8e69abff6e2d476d6d4bc" name="a3c3ae83e0bf8e69abff6e2d476d6d4bc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3c3ae83e0bf8e69abff6e2d476d6d4bc">&#9670;&#160;</a></span>is_blas_available()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool is_blas_available </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span><span class="mlabel constexpr">constexpr</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Check if BLAS backend is available. </p>
<dl class="section return"><dt>Returns</dt><dd>true if BLAS support is compiled in </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l00225">225</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  225</span>                                          {</div>
<div class="line"><span class="lineno">  226</span><span class="preprocessor">#ifdef USE_BLAS</span></div>
<div class="line"><span class="lineno">  227</span>    <span class="keywordflow">return</span> <span class="keyword">true</span>;</div>
<div class="line"><span class="lineno">  228</span><span class="preprocessor">#else</span></div>
<div class="line"><span class="lineno">  229</span>    <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><span class="lineno">  230</span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="lineno">  231</span>}</div>
</div><!-- fragment -->
</div>
</div>
<a id="ac3172c311c588e95a83276e2841906af" name="ac3172c311c588e95a83276e2841906af"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac3172c311c588e95a83276e2841906af">&#9670;&#160;</a></span>is_gpu_available()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">bool is_gpu_available </td>
          <td>(</td>
          <td class="paramname"><span class="paramname"><em></em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Check if GPU backend is available. </p>
<dl class="section return"><dt>Returns</dt><dd>true if GPU support is compiled in and GPU is available </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l00213">213</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  213</span>                               {</div>
<div class="line"><span class="lineno">  214</span><span class="preprocessor">#ifdef USE_GPU</span></div>
<div class="line"><span class="lineno">  215</span>    <span class="keywordflow">return</span> TensorGPU::is_gpu_available();</div>
<div class="line"><span class="lineno">  216</span><span class="preprocessor">#else</span></div>
<div class="line"><span class="lineno">  217</span>    <span class="keywordflow">return</span> <span class="keyword">false</span>;</div>
<div class="line"><span class="lineno">  218</span><span class="preprocessor">#endif</span></div>
<div class="line"><span class="lineno">  219</span>}</div>
</div><!-- fragment -->
</div>
</div>
<a id="a0d1116cdf6624cb52514979cd1869e55" name="a0d1116cdf6624cb52514979cd1869e55"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a0d1116cdf6624cb52514979cd1869e55">&#9670;&#160;</a></span>leftCols()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; leftCols </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>matrix</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>n</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Extract leftmost n columns from a 2D tensor. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>Data type </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">matrix</td><td>2D tensor </td></tr>
    <tr><td class="paramname">n</td><td>Number of columns to extract </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>2D tensor containing leftmost n columns</dd></dl>
<div class="fragment"><div class="line"><a class="code hl_class" href="classTensor.html">Tensor&lt;float, 2&gt;</a> mat({5, 10});</div>
<div class="line"><span class="keyword">auto</span> left3 = mat.<a class="code hl_function" href="classTensor.html#aff781405a45c8ec01fde149ecba560b6">leftCols</a>(3);</div>
<div class="ttc" id="aclassTensor_html_aff781405a45c8ec01fde149ecba560b6"><div class="ttname"><a href="classTensor.html#aff781405a45c8ec01fde149ecba560b6">Tensor::leftCols</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; leftCols(size_t n) const</div><div class="ttdoc">Extract leftmost n columns (only for 2D tensors).</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l05123">tensor.h:5123</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06905">6905</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6905</span>                                                            {</div>
<div class="line"><span class="lineno"> 6906</span>    <span class="keyword">auto</span> dims = matrix.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>();</div>
<div class="line"><span class="lineno"> 6907</span>    <span class="keywordtype">size_t</span> rows = dims[0];</div>
<div class="line"><span class="lineno"> 6908</span>    <span class="keywordtype">size_t</span> cols = dims[1];</div>
<div class="line"><span class="lineno"> 6909</span>    <span class="keywordflow">if</span> (n &gt; cols) n = cols;</div>
<div class="line"><span class="lineno"> 6910</span>    </div>
<div class="line"><span class="lineno"> 6911</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> result({rows, n}, matrix.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>());</div>
<div class="line"><span class="lineno"> 6912</span>    </div>
<div class="line"><span class="lineno"> 6913</span>    <span class="keyword">const</span> T* src = matrix.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>();</div>
<div class="line"><span class="lineno"> 6914</span>    T* dst = result.data_ptr();</div>
<div class="line"><span class="lineno"> 6915</span>    </div>
<div class="line"><span class="lineno"> 6916</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; rows; ++i) {</div>
<div class="line"><span class="lineno"> 6917</span>        std::copy_n(src + i * cols, n, dst + i * n);</div>
<div class="line"><span class="lineno"> 6918</span>    }</div>
<div class="line"><span class="lineno"> 6919</span>    </div>
<div class="line"><span class="lineno"> 6920</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6921</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a0d1116cdf6624cb52514979cd1869e55_cgraph.png" border="0" usemap="#atensor_8h_a0d1116cdf6624cb52514979cd1869e55_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a0d1116cdf6624cb52514979cd1869e55_cgraph" id="atensor_8h_a0d1116cdf6624cb52514979cd1869e55_cgraph">
<area shape="rect" title="Extract leftmost n columns from a 2D tensor." alt="" coords="5,56,72,83"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="124,5,240,32"/>
<area shape="poly" title=" " alt="" coords="71,55,127,35,129,40,73,60"/>
<area shape="rect" href="classTensor.html#a03d314303958ffc5644796d8025cd012" title=" " alt="" coords="134,56,230,83"/>
<area shape="poly" title=" " alt="" coords="72,67,118,67,118,72,72,72"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="120,107,244,133"/>
<area shape="poly" title=" " alt="" coords="73,78,129,99,127,104,71,83"/>
</map>
</div>

</div>
</div>
<a id="a47fb1071bbaf297c2b7804f3a16cbce0" name="a47fb1071bbaf297c2b7804f3a16cbce0"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a47fb1071bbaf297c2b7804f3a16cbce0">&#9670;&#160;</a></span>linspace()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; linspace </td>
          <td>(</td>
          <td class="paramtype">T</td>          <td class="paramname"><span class="paramname"><em>start</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T</td>          <td class="paramname"><span class="paramname"><em>stop</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>num</em></span><span class="paramdefsep"> = </span><span class="paramdefval">50</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>use_gpu</em></span><span class="paramdefsep"> = </span><span class="paramdefval">true</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create a tensor with evenly spaced values (NumPy linspace-compatible). </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>The data type </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">start</td><td>Start value </td></tr>
    <tr><td class="paramname">stop</td><td>Stop value </td></tr>
    <tr><td class="paramname">num</td><td>Number of samples (default 50) </td></tr>
    <tr><td class="paramname">use_gpu</td><td>Whether to use GPU </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A 1D tensor with num evenly spaced values </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06193">6193</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6193</span>                                                                             {</div>
<div class="line"><span class="lineno"> 6194</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 1&gt;</a> result({num}, use_gpu);</div>
<div class="line"><span class="lineno"> 6195</span>    T* data = result.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>();</div>
<div class="line"><span class="lineno"> 6196</span>    </div>
<div class="line"><span class="lineno"> 6197</span>    <span class="keywordflow">if</span> (num == 1) {</div>
<div class="line"><span class="lineno"> 6198</span>        data[0] = start;</div>
<div class="line"><span class="lineno"> 6199</span>        <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6200</span>    }</div>
<div class="line"><span class="lineno"> 6201</span>    </div>
<div class="line"><span class="lineno"> 6202</span>    T step = (stop - start) / (num - 1);</div>
<div class="line"><span class="lineno"> 6203</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; num; ++i) {</div>
<div class="line"><span class="lineno"> 6204</span>        data[i] = start + i * step;</div>
<div class="line"><span class="lineno"> 6205</span>    }</div>
<div class="line"><span class="lineno"> 6206</span>    </div>
<div class="line"><span class="lineno"> 6207</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6208</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a47fb1071bbaf297c2b7804f3a16cbce0_cgraph.png" border="0" usemap="#atensor_8h_a47fb1071bbaf297c2b7804f3a16cbce0_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a47fb1071bbaf297c2b7804f3a16cbce0_cgraph" id="atensor_8h_a47fb1071bbaf297c2b7804f3a16cbce0_cgraph">
<area shape="rect" title="Create a tensor with evenly spaced values (NumPy linspace&#45;compatible)." alt="" coords="5,5,75,32"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="123,5,238,32"/>
<area shape="poly" title=" " alt="" coords="75,16,107,16,107,21,75,21"/>
</map>
</div>

</div>
</div>
<a id="ac9b881e42d5eeb214b4ca87579eaaffc" name="ac9b881e42d5eeb214b4ca87579eaaffc"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac9b881e42d5eeb214b4ca87579eaaffc">&#9670;&#160;</a></span>logspace()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; logspace </td>
          <td>(</td>
          <td class="paramtype">T</td>          <td class="paramname"><span class="paramname"><em>start</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T</td>          <td class="paramname"><span class="paramname"><em>stop</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>num</em></span><span class="paramdefsep"> = </span><span class="paramdefval">50</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T</td>          <td class="paramname"><span class="paramname"><em>base</em></span><span class="paramdefsep"> = </span><span class="paramdefval">T(10)</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>use_gpu</em></span><span class="paramdefsep"> = </span><span class="paramdefval">true</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create a tensor with values spaced evenly on a log scale. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>The data type </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">start</td><td>Start value (10^start) </td></tr>
    <tr><td class="paramname">stop</td><td>Stop value (10^stop) </td></tr>
    <tr><td class="paramname">num</td><td>Number of samples (default 50) </td></tr>
    <tr><td class="paramname">base</td><td>Base of the log space (default 10.0) </td></tr>
    <tr><td class="paramname">use_gpu</td><td>Whether to use GPU </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A 1D tensor with num log-spaced values </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06221">6221</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6222</span>                                           {</div>
<div class="line"><span class="lineno"> 6223</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 1&gt;</a> result({num}, use_gpu);</div>
<div class="line"><span class="lineno"> 6224</span>    T* data = result.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>();</div>
<div class="line"><span class="lineno"> 6225</span>    </div>
<div class="line"><span class="lineno"> 6226</span>    <span class="keywordflow">if</span> (num == 1) {</div>
<div class="line"><span class="lineno"> 6227</span>        data[0] = std::pow(base, start);</div>
<div class="line"><span class="lineno"> 6228</span>        <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6229</span>    }</div>
<div class="line"><span class="lineno"> 6230</span>    </div>
<div class="line"><span class="lineno"> 6231</span>    T step = (stop - start) / (num - 1);</div>
<div class="line"><span class="lineno"> 6232</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; num; ++i) {</div>
<div class="line"><span class="lineno"> 6233</span>        data[i] = std::pow(base, start + i * step);</div>
<div class="line"><span class="lineno"> 6234</span>    }</div>
<div class="line"><span class="lineno"> 6235</span>    </div>
<div class="line"><span class="lineno"> 6236</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6237</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_ac9b881e42d5eeb214b4ca87579eaaffc_cgraph.png" border="0" usemap="#atensor_8h_ac9b881e42d5eeb214b4ca87579eaaffc_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_ac9b881e42d5eeb214b4ca87579eaaffc_cgraph" id="atensor_8h_ac9b881e42d5eeb214b4ca87579eaaffc_cgraph">
<area shape="rect" title="Create a tensor with values spaced evenly on a log scale." alt="" coords="5,5,79,32"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="127,5,242,32"/>
<area shape="poly" title=" " alt="" coords="79,16,111,16,111,21,79,21"/>
</map>
</div>

</div>
</div>
<a id="aa8d30c4d06f085bf8078c8644030c633" name="aa8d30c4d06f085bf8078c8644030c633"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aa8d30c4d06f085bf8078c8644030c633">&#9670;&#160;</a></span>normalize_l1()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T, size_t N&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; normalize_l1 </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span><span class="paramdefsep"> = </span><span class="paramdefval">-1</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Normalize tensor using L1 norm (sum of absolute values). </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>Data type </td></tr>
    <tr><td class="paramname">N</td><td>Number of dimensions </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>Input tensor </td></tr>
    <tr><td class="paramname">axis</td><td>Axis along which to normalize (-1 for all elements) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Normalized tensor where L1 norm equals 1</dd></dl>
<p>L1 normalization divides each element by the sum of absolute values. Useful for probability distributions and sparse data. </p>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06306">6306</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6306</span>                                                                     {</div>
<div class="line"><span class="lineno"> 6307</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, N&gt;</a> result(tensor.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>(), tensor.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>());</div>
<div class="line"><span class="lineno"> 6308</span>    <span class="keyword">const</span> T* src = tensor.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>();</div>
<div class="line"><span class="lineno"> 6309</span>    T* dst = result.data_ptr();</div>
<div class="line"><span class="lineno"> 6310</span>    <span class="keywordtype">size_t</span> total = tensor.<a class="code hl_function" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7">total_size</a>();</div>
<div class="line"><span class="lineno"> 6311</span>    </div>
<div class="line"><span class="lineno"> 6312</span>    <span class="keywordflow">if</span> (axis == -1) {</div>
<div class="line"><span class="lineno"> 6313</span>        <span class="comment">// Normalize over all elements</span></div>
<div class="line"><span class="lineno"> 6314</span>        T sum = T(0);</div>
<div class="line"><span class="lineno"> 6315</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; total; ++i) {</div>
<div class="line"><span class="lineno"> 6316</span>            sum += std::abs(src[i]);</div>
<div class="line"><span class="lineno"> 6317</span>        }</div>
<div class="line"><span class="lineno"> 6318</span>        <span class="keywordflow">if</span> (sum &gt; T(0)) {</div>
<div class="line"><span class="lineno"> 6319</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; total; ++i) {</div>
<div class="line"><span class="lineno"> 6320</span>                dst[i] = src[i] / sum;</div>
<div class="line"><span class="lineno"> 6321</span>            }</div>
<div class="line"><span class="lineno"> 6322</span>        } <span class="keywordflow">else</span> {</div>
<div class="line"><span class="lineno"> 6323</span>            std::copy_n(src, total, dst);</div>
<div class="line"><span class="lineno"> 6324</span>        }</div>
<div class="line"><span class="lineno"> 6325</span>    } <span class="keywordflow">else</span> <span class="keywordflow">if</span> <span class="keyword">constexpr</span> (N &gt;= 2) {</div>
<div class="line"><span class="lineno"> 6326</span>        <span class="comment">// Normalize along specific axis</span></div>
<div class="line"><span class="lineno"> 6327</span>        <span class="keyword">auto</span> dims = tensor.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>();</div>
<div class="line"><span class="lineno"> 6328</span>        <span class="keywordtype">size_t</span> axis_size = dims[axis];</div>
<div class="line"><span class="lineno"> 6329</span>        <span class="keywordtype">size_t</span> outer_size = 1;</div>
<div class="line"><span class="lineno"> 6330</span>        <span class="keywordtype">size_t</span> inner_size = 1;</div>
<div class="line"><span class="lineno"> 6331</span>        </div>
<div class="line"><span class="lineno"> 6332</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; axis; ++i) {</div>
<div class="line"><span class="lineno"> 6333</span>            outer_size *= dims[i];</div>
<div class="line"><span class="lineno"> 6334</span>        }</div>
<div class="line"><span class="lineno"> 6335</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = axis + 1; i &lt; N; ++i) {</div>
<div class="line"><span class="lineno"> 6336</span>            inner_size *= dims[i];</div>
<div class="line"><span class="lineno"> 6337</span>        }</div>
<div class="line"><span class="lineno"> 6338</span>        </div>
<div class="line"><span class="lineno"> 6339</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> outer = 0; <a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a> &lt; outer_size; ++<a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a>) {</div>
<div class="line"><span class="lineno"> 6340</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> inner = 0; inner &lt; inner_size; ++inner) {</div>
<div class="line"><span class="lineno"> 6341</span>                <span class="comment">// Compute sum for this slice</span></div>
<div class="line"><span class="lineno"> 6342</span>                T sum = T(0);</div>
<div class="line"><span class="lineno"> 6343</span>                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> ax = 0; ax &lt; axis_size; ++ax) {</div>
<div class="line"><span class="lineno"> 6344</span>                    <span class="keywordtype">size_t</span> idx = <a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a> * axis_size * inner_size + ax * inner_size + inner;</div>
<div class="line"><span class="lineno"> 6345</span>                    sum += std::abs(src[idx]);</div>
<div class="line"><span class="lineno"> 6346</span>                }</div>
<div class="line"><span class="lineno"> 6347</span>                </div>
<div class="line"><span class="lineno"> 6348</span>                <span class="comment">// Normalize</span></div>
<div class="line"><span class="lineno"> 6349</span>                <span class="keywordflow">if</span> (sum &gt; T(0)) {</div>
<div class="line"><span class="lineno"> 6350</span>                    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> ax = 0; ax &lt; axis_size; ++ax) {</div>
<div class="line"><span class="lineno"> 6351</span>                        <span class="keywordtype">size_t</span> idx = <a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a> * axis_size * inner_size + ax * inner_size + inner;</div>
<div class="line"><span class="lineno"> 6352</span>                        dst[idx] = src[idx] / sum;</div>
<div class="line"><span class="lineno"> 6353</span>                    }</div>
<div class="line"><span class="lineno"> 6354</span>                } <span class="keywordflow">else</span> {</div>
<div class="line"><span class="lineno"> 6355</span>                    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> ax = 0; ax &lt; axis_size; ++ax) {</div>
<div class="line"><span class="lineno"> 6356</span>                        <span class="keywordtype">size_t</span> idx = <a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a> * axis_size * inner_size + ax * inner_size + inner;</div>
<div class="line"><span class="lineno"> 6357</span>                        dst[idx] = src[idx];</div>
<div class="line"><span class="lineno"> 6358</span>                    }</div>
<div class="line"><span class="lineno"> 6359</span>                }</div>
<div class="line"><span class="lineno"> 6360</span>            }</div>
<div class="line"><span class="lineno"> 6361</span>        }</div>
<div class="line"><span class="lineno"> 6362</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><span class="lineno"> 6363</span>        std::copy_n(src, total, dst);</div>
<div class="line"><span class="lineno"> 6364</span>    }</div>
<div class="line"><span class="lineno"> 6365</span>    </div>
<div class="line"><span class="lineno"> 6366</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6367</span>}</div>
<div class="ttc" id="anamespacelinalg_html_a8a8d04b2734fdcad37cc861687fbb6fc"><div class="ttname"><a href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">linalg::outer</a></div><div class="ttdeci">Matrix&lt; T &gt; outer(const Vector&lt; T &gt; &amp;a, const Vector&lt; T &gt; &amp;b)</div><div class="ttdef"><b>Definition</b> <a href="linalg_8h_source.html#l00226">linalg.h:226</a></div></div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_aa8d30c4d06f085bf8078c8644030c633_cgraph.png" border="0" usemap="#atensor_8h_aa8d30c4d06f085bf8078c8644030c633_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_aa8d30c4d06f085bf8078c8644030c633_cgraph" id="atensor_8h_aa8d30c4d06f085bf8078c8644030c633_cgraph">
<area shape="rect" title="Normalize tensor using L1 norm (sum of absolute values)." alt="" coords="5,81,100,108"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="152,5,268,32"/>
<area shape="poly" title=" " alt="" coords="77,79,146,42,159,36,161,41,149,46,79,83"/>
<area shape="rect" href="classTensor.html#a03d314303958ffc5644796d8025cd012" title=" " alt="" coords="162,56,258,83"/>
<area shape="poly" title=" " alt="" coords="100,84,146,77,147,82,101,90"/>
<area shape="rect" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7" title=" " alt="" coords="148,107,272,133"/>
<area shape="poly" title=" " alt="" coords="101,100,133,105,132,110,100,105"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="148,157,272,184"/>
<area shape="poly" title=" " alt="" coords="79,106,149,143,161,148,159,153,146,148,77,111"/>
</map>
</div>

</div>
</div>
<a id="a7718d2096a1190de7777bc65f9a86deb" name="a7718d2096a1190de7777bc65f9a86deb"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a7718d2096a1190de7777bc65f9a86deb">&#9670;&#160;</a></span>normalize_l2()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T, size_t N&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; normalize_l2 </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span><span class="paramdefsep"> = </span><span class="paramdefval">-1</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Normalize tensor using L2 norm (Euclidean norm). </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>Data type </td></tr>
    <tr><td class="paramname">N</td><td>Number of dimensions </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>Input tensor </td></tr>
    <tr><td class="paramname">axis</td><td>Axis along which to normalize (-1 for all elements) </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Normalized tensor where L2 norm equals 1</dd></dl>
<p>L2 normalization divides each element by the square root of the sum of squares. Common in machine learning for feature normalization. </p>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06381">6381</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6381</span>                                                                     {</div>
<div class="line"><span class="lineno"> 6382</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, N&gt;</a> result(tensor.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>(), tensor.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>());</div>
<div class="line"><span class="lineno"> 6383</span>    <span class="keyword">const</span> T* src = tensor.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>();</div>
<div class="line"><span class="lineno"> 6384</span>    T* dst = result.data_ptr();</div>
<div class="line"><span class="lineno"> 6385</span>    <span class="keywordtype">size_t</span> total = tensor.<a class="code hl_function" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7">total_size</a>();</div>
<div class="line"><span class="lineno"> 6386</span>    </div>
<div class="line"><span class="lineno"> 6387</span>    <span class="keywordflow">if</span> (axis == -1) {</div>
<div class="line"><span class="lineno"> 6388</span>        <span class="comment">// Normalize over all elements</span></div>
<div class="line"><span class="lineno"> 6389</span>        T sum_sq = T(0);</div>
<div class="line"><span class="lineno"> 6390</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; total; ++i) {</div>
<div class="line"><span class="lineno"> 6391</span>            sum_sq += src[i] * src[i];</div>
<div class="line"><span class="lineno"> 6392</span>        }</div>
<div class="line"><span class="lineno"> 6393</span>        T <a class="code hl_function" href="namespacelinalg.html#a16562e1c4018bf2a58455158a8022fb9">norm</a> = std::sqrt(sum_sq);</div>
<div class="line"><span class="lineno"> 6394</span>        <span class="keywordflow">if</span> (norm &gt; T(0)) {</div>
<div class="line"><span class="lineno"> 6395</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; total; ++i) {</div>
<div class="line"><span class="lineno"> 6396</span>                dst[i] = src[i] / <a class="code hl_function" href="namespacelinalg.html#a16562e1c4018bf2a58455158a8022fb9">norm</a>;</div>
<div class="line"><span class="lineno"> 6397</span>            }</div>
<div class="line"><span class="lineno"> 6398</span>        } <span class="keywordflow">else</span> {</div>
<div class="line"><span class="lineno"> 6399</span>            std::copy_n(src, total, dst);</div>
<div class="line"><span class="lineno"> 6400</span>        }</div>
<div class="line"><span class="lineno"> 6401</span>    } <span class="keywordflow">else</span> <span class="keywordflow">if</span> <span class="keyword">constexpr</span> (N &gt;= 2) {</div>
<div class="line"><span class="lineno"> 6402</span>        <span class="comment">// Normalize along specific axis</span></div>
<div class="line"><span class="lineno"> 6403</span>        <span class="keyword">auto</span> dims = tensor.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>();</div>
<div class="line"><span class="lineno"> 6404</span>        <span class="keywordtype">size_t</span> axis_size = dims[axis];</div>
<div class="line"><span class="lineno"> 6405</span>        <span class="keywordtype">size_t</span> outer_size = 1;</div>
<div class="line"><span class="lineno"> 6406</span>        <span class="keywordtype">size_t</span> inner_size = 1;</div>
<div class="line"><span class="lineno"> 6407</span>        </div>
<div class="line"><span class="lineno"> 6408</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; axis; ++i) {</div>
<div class="line"><span class="lineno"> 6409</span>            outer_size *= dims[i];</div>
<div class="line"><span class="lineno"> 6410</span>        }</div>
<div class="line"><span class="lineno"> 6411</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = axis + 1; i &lt; N; ++i) {</div>
<div class="line"><span class="lineno"> 6412</span>            inner_size *= dims[i];</div>
<div class="line"><span class="lineno"> 6413</span>        }</div>
<div class="line"><span class="lineno"> 6414</span>        </div>
<div class="line"><span class="lineno"> 6415</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> outer = 0; <a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a> &lt; outer_size; ++<a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a>) {</div>
<div class="line"><span class="lineno"> 6416</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> inner = 0; inner &lt; inner_size; ++inner) {</div>
<div class="line"><span class="lineno"> 6417</span>                <span class="comment">// Compute sum of squares for this slice</span></div>
<div class="line"><span class="lineno"> 6418</span>                T sum_sq = T(0);</div>
<div class="line"><span class="lineno"> 6419</span>                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> ax = 0; ax &lt; axis_size; ++ax) {</div>
<div class="line"><span class="lineno"> 6420</span>                    <span class="keywordtype">size_t</span> idx = <a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a> * axis_size * inner_size + ax * inner_size + inner;</div>
<div class="line"><span class="lineno"> 6421</span>                    sum_sq += src[idx] * src[idx];</div>
<div class="line"><span class="lineno"> 6422</span>                }</div>
<div class="line"><span class="lineno"> 6423</span>                </div>
<div class="line"><span class="lineno"> 6424</span>                T <a class="code hl_function" href="namespacelinalg.html#a16562e1c4018bf2a58455158a8022fb9">norm</a> = std::sqrt(sum_sq);</div>
<div class="line"><span class="lineno"> 6425</span>                </div>
<div class="line"><span class="lineno"> 6426</span>                <span class="comment">// Normalize</span></div>
<div class="line"><span class="lineno"> 6427</span>                <span class="keywordflow">if</span> (norm &gt; T(0)) {</div>
<div class="line"><span class="lineno"> 6428</span>                    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> ax = 0; ax &lt; axis_size; ++ax) {</div>
<div class="line"><span class="lineno"> 6429</span>                        <span class="keywordtype">size_t</span> idx = <a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a> * axis_size * inner_size + ax * inner_size + inner;</div>
<div class="line"><span class="lineno"> 6430</span>                        dst[idx] = src[idx] / <a class="code hl_function" href="namespacelinalg.html#a16562e1c4018bf2a58455158a8022fb9">norm</a>;</div>
<div class="line"><span class="lineno"> 6431</span>                    }</div>
<div class="line"><span class="lineno"> 6432</span>                } <span class="keywordflow">else</span> {</div>
<div class="line"><span class="lineno"> 6433</span>                    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> ax = 0; ax &lt; axis_size; ++ax) {</div>
<div class="line"><span class="lineno"> 6434</span>                        <span class="keywordtype">size_t</span> idx = <a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a> * axis_size * inner_size + ax * inner_size + inner;</div>
<div class="line"><span class="lineno"> 6435</span>                        dst[idx] = src[idx];</div>
<div class="line"><span class="lineno"> 6436</span>                    }</div>
<div class="line"><span class="lineno"> 6437</span>                }</div>
<div class="line"><span class="lineno"> 6438</span>            }</div>
<div class="line"><span class="lineno"> 6439</span>        }</div>
<div class="line"><span class="lineno"> 6440</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><span class="lineno"> 6441</span>        std::copy_n(src, total, dst);</div>
<div class="line"><span class="lineno"> 6442</span>    }</div>
<div class="line"><span class="lineno"> 6443</span>    </div>
<div class="line"><span class="lineno"> 6444</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6445</span>}</div>
<div class="ttc" id="anamespacelinalg_html_a16562e1c4018bf2a58455158a8022fb9"><div class="ttname"><a href="namespacelinalg.html#a16562e1c4018bf2a58455158a8022fb9">linalg::norm</a></div><div class="ttdeci">T norm(const Vector&lt; T &gt; &amp;v)</div><div class="ttdoc">Compute the L2 norm (Euclidean norm) of a vector.</div><div class="ttdef"><b>Definition</b> <a href="linalg_8h_source.html#l00103">linalg.h:103</a></div></div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a7718d2096a1190de7777bc65f9a86deb_cgraph.png" border="0" usemap="#atensor_8h_a7718d2096a1190de7777bc65f9a86deb_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a7718d2096a1190de7777bc65f9a86deb_cgraph" id="atensor_8h_a7718d2096a1190de7777bc65f9a86deb_cgraph">
<area shape="rect" title="Normalize tensor using L2 norm (Euclidean norm)." alt="" coords="5,81,100,108"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="152,5,268,32"/>
<area shape="poly" title=" " alt="" coords="77,79,146,42,159,36,161,41,149,46,79,83"/>
<area shape="rect" href="classTensor.html#a03d314303958ffc5644796d8025cd012" title=" " alt="" coords="162,56,258,83"/>
<area shape="poly" title=" " alt="" coords="100,84,146,77,147,82,101,90"/>
<area shape="rect" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7" title=" " alt="" coords="148,107,272,133"/>
<area shape="poly" title=" " alt="" coords="101,100,133,105,132,110,100,105"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="148,157,272,184"/>
<area shape="poly" title=" " alt="" coords="79,106,149,143,161,148,159,153,146,148,77,111"/>
</map>
</div>

</div>
</div>
<a id="a1782e0dff417e1292f8a6f1e3e1975f1" name="a1782e0dff417e1292f8a6f1e3e1975f1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1782e0dff417e1292f8a6f1e3e1975f1">&#9670;&#160;</a></span>normalize_minmax()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T, size_t N&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; normalize_minmax </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span><span class="paramdefsep"> = </span><span class="paramdefval">-1</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T</td>          <td class="paramname"><span class="paramname"><em>min_val</em></span><span class="paramdefsep"> = </span><span class="paramdefval">T(0)</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T</td>          <td class="paramname"><span class="paramname"><em>max_val</em></span><span class="paramdefsep"> = </span><span class="paramdefval">T(1)</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T</td>          <td class="paramname"><span class="paramname"><em>eps</em></span><span class="paramdefsep"> = </span><span class="paramdefval">T(1e-8)</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Min-Max normalization: scales values to [min_val, max_val] range. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>Data type </td></tr>
    <tr><td class="paramname">N</td><td>Number of dimensions </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>Input tensor </td></tr>
    <tr><td class="paramname">axis</td><td>Axis along which to normalize (-1 for all elements) </td></tr>
    <tr><td class="paramname">min_val</td><td>Minimum value of output range (default 0) </td></tr>
    <tr><td class="paramname">max_val</td><td>Maximum value of output range (default 1) </td></tr>
    <tr><td class="paramname">eps</td><td>Small constant to avoid division by zero </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Scaled tensor in the range [min_val, max_val]</dd></dl>
<p>Min-max scaling is useful when you need values in a specific range. </p>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06546">6546</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6547</span>                                                                                    {</div>
<div class="line"><span class="lineno"> 6548</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, N&gt;</a> result(tensor.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>(), tensor.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>());</div>
<div class="line"><span class="lineno"> 6549</span>    <span class="keyword">const</span> T* src = tensor.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>();</div>
<div class="line"><span class="lineno"> 6550</span>    T* dst = result.data_ptr();</div>
<div class="line"><span class="lineno"> 6551</span>    <span class="keywordtype">size_t</span> total = tensor.<a class="code hl_function" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7">total_size</a>();</div>
<div class="line"><span class="lineno"> 6552</span>    </div>
<div class="line"><span class="lineno"> 6553</span>    <span class="keywordflow">if</span> (axis == -1) {</div>
<div class="line"><span class="lineno"> 6554</span>        <span class="comment">// Normalize over all elements</span></div>
<div class="line"><span class="lineno"> 6555</span>        T min_elem = src[0];</div>
<div class="line"><span class="lineno"> 6556</span>        T max_elem = src[0];</div>
<div class="line"><span class="lineno"> 6557</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 1; i &lt; total; ++i) {</div>
<div class="line"><span class="lineno"> 6558</span>            <span class="keywordflow">if</span> (src[i] &lt; min_elem) min_elem = src[i];</div>
<div class="line"><span class="lineno"> 6559</span>            <span class="keywordflow">if</span> (src[i] &gt; max_elem) max_elem = src[i];</div>
<div class="line"><span class="lineno"> 6560</span>        }</div>
<div class="line"><span class="lineno"> 6561</span>        </div>
<div class="line"><span class="lineno"> 6562</span>        T range = max_elem - min_elem;</div>
<div class="line"><span class="lineno"> 6563</span>        <span class="keywordflow">if</span> (range &gt; eps) {</div>
<div class="line"><span class="lineno"> 6564</span>            T scale = (max_val - min_val) / range;</div>
<div class="line"><span class="lineno"> 6565</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; total; ++i) {</div>
<div class="line"><span class="lineno"> 6566</span>                dst[i] = min_val + (src[i] - min_elem) * scale;</div>
<div class="line"><span class="lineno"> 6567</span>            }</div>
<div class="line"><span class="lineno"> 6568</span>        } <span class="keywordflow">else</span> {</div>
<div class="line"><span class="lineno"> 6569</span>            <span class="comment">// All values are the same</span></div>
<div class="line"><span class="lineno"> 6570</span>            T mid = (min_val + max_val) / T(2);</div>
<div class="line"><span class="lineno"> 6571</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; total; ++i) {</div>
<div class="line"><span class="lineno"> 6572</span>                dst[i] = mid;</div>
<div class="line"><span class="lineno"> 6573</span>            }</div>
<div class="line"><span class="lineno"> 6574</span>        }</div>
<div class="line"><span class="lineno"> 6575</span>    } <span class="keywordflow">else</span> <span class="keywordflow">if</span> <span class="keyword">constexpr</span> (N &gt;= 2) {</div>
<div class="line"><span class="lineno"> 6576</span>        <span class="comment">// Normalize along specific axis</span></div>
<div class="line"><span class="lineno"> 6577</span>        <span class="keyword">auto</span> dims = tensor.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>();</div>
<div class="line"><span class="lineno"> 6578</span>        <span class="keywordtype">size_t</span> axis_size = dims[axis];</div>
<div class="line"><span class="lineno"> 6579</span>        <span class="keywordtype">size_t</span> outer_size = 1;</div>
<div class="line"><span class="lineno"> 6580</span>        <span class="keywordtype">size_t</span> inner_size = 1;</div>
<div class="line"><span class="lineno"> 6581</span>        </div>
<div class="line"><span class="lineno"> 6582</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; axis; ++i) {</div>
<div class="line"><span class="lineno"> 6583</span>            outer_size *= dims[i];</div>
<div class="line"><span class="lineno"> 6584</span>        }</div>
<div class="line"><span class="lineno"> 6585</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = axis + 1; i &lt; N; ++i) {</div>
<div class="line"><span class="lineno"> 6586</span>            inner_size *= dims[i];</div>
<div class="line"><span class="lineno"> 6587</span>        }</div>
<div class="line"><span class="lineno"> 6588</span>        </div>
<div class="line"><span class="lineno"> 6589</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> outer = 0; <a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a> &lt; outer_size; ++<a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a>) {</div>
<div class="line"><span class="lineno"> 6590</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> inner = 0; inner &lt; inner_size; ++inner) {</div>
<div class="line"><span class="lineno"> 6591</span>                <span class="comment">// Find min and max for this slice</span></div>
<div class="line"><span class="lineno"> 6592</span>                <span class="keywordtype">size_t</span> first_idx = <a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a> * axis_size * inner_size + inner;</div>
<div class="line"><span class="lineno"> 6593</span>                T min_elem = src[first_idx];</div>
<div class="line"><span class="lineno"> 6594</span>                T max_elem = src[first_idx];</div>
<div class="line"><span class="lineno"> 6595</span>                </div>
<div class="line"><span class="lineno"> 6596</span>                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> ax = 1; ax &lt; axis_size; ++ax) {</div>
<div class="line"><span class="lineno"> 6597</span>                    <span class="keywordtype">size_t</span> idx = <a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a> * axis_size * inner_size + ax * inner_size + inner;</div>
<div class="line"><span class="lineno"> 6598</span>                    <span class="keywordflow">if</span> (src[idx] &lt; min_elem) min_elem = src[idx];</div>
<div class="line"><span class="lineno"> 6599</span>                    <span class="keywordflow">if</span> (src[idx] &gt; max_elem) max_elem = src[idx];</div>
<div class="line"><span class="lineno"> 6600</span>                }</div>
<div class="line"><span class="lineno"> 6601</span>                </div>
<div class="line"><span class="lineno"> 6602</span>                T range = max_elem - min_elem;</div>
<div class="line"><span class="lineno"> 6603</span>                </div>
<div class="line"><span class="lineno"> 6604</span>                <span class="comment">// Normalize</span></div>
<div class="line"><span class="lineno"> 6605</span>                <span class="keywordflow">if</span> (range &gt; eps) {</div>
<div class="line"><span class="lineno"> 6606</span>                    T scale = (max_val - min_val) / range;</div>
<div class="line"><span class="lineno"> 6607</span>                    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> ax = 0; ax &lt; axis_size; ++ax) {</div>
<div class="line"><span class="lineno"> 6608</span>                        <span class="keywordtype">size_t</span> idx = <a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a> * axis_size * inner_size + ax * inner_size + inner;</div>
<div class="line"><span class="lineno"> 6609</span>                        dst[idx] = min_val + (src[idx] - min_elem) * scale;</div>
<div class="line"><span class="lineno"> 6610</span>                    }</div>
<div class="line"><span class="lineno"> 6611</span>                } <span class="keywordflow">else</span> {</div>
<div class="line"><span class="lineno"> 6612</span>                    T mid = (min_val + max_val) / T(2);</div>
<div class="line"><span class="lineno"> 6613</span>                    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> ax = 0; ax &lt; axis_size; ++ax) {</div>
<div class="line"><span class="lineno"> 6614</span>                        <span class="keywordtype">size_t</span> idx = <a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a> * axis_size * inner_size + ax * inner_size + inner;</div>
<div class="line"><span class="lineno"> 6615</span>                        dst[idx] = mid;</div>
<div class="line"><span class="lineno"> 6616</span>                    }</div>
<div class="line"><span class="lineno"> 6617</span>                }</div>
<div class="line"><span class="lineno"> 6618</span>            }</div>
<div class="line"><span class="lineno"> 6619</span>        }</div>
<div class="line"><span class="lineno"> 6620</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><span class="lineno"> 6621</span>        std::copy_n(src, total, dst);</div>
<div class="line"><span class="lineno"> 6622</span>    }</div>
<div class="line"><span class="lineno"> 6623</span>    </div>
<div class="line"><span class="lineno"> 6624</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6625</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a1782e0dff417e1292f8a6f1e3e1975f1_cgraph.png" border="0" usemap="#atensor_8h_a1782e0dff417e1292f8a6f1e3e1975f1_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a1782e0dff417e1292f8a6f1e3e1975f1_cgraph" id="atensor_8h_a1782e0dff417e1292f8a6f1e3e1975f1_cgraph">
<area shape="rect" title="Min&#45;Max normalization: scales values to [min_val, max_val] range." alt="" coords="5,81,136,108"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="188,5,304,32"/>
<area shape="poly" title=" " alt="" coords="101,78,183,42,196,36,198,41,185,46,103,83"/>
<area shape="rect" href="classTensor.html#a03d314303958ffc5644796d8025cd012" title=" " alt="" coords="198,56,294,83"/>
<area shape="poly" title=" " alt="" coords="136,83,182,76,183,81,137,88"/>
<area shape="rect" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7" title=" " alt="" coords="184,107,308,133"/>
<area shape="poly" title=" " alt="" coords="137,101,169,106,168,111,136,107"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="184,157,308,184"/>
<area shape="poly" title=" " alt="" coords="103,106,185,143,198,149,196,153,183,148,101,111"/>
</map>
</div>

</div>
</div>
<a id="a57c931d0d77f610850f315fdd9acef39" name="a57c931d0d77f610850f315fdd9acef39"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a57c931d0d77f610850f315fdd9acef39">&#9670;&#160;</a></span>normalize_zscore()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T, size_t N&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; normalize_zscore </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">int</td>          <td class="paramname"><span class="paramname"><em>axis</em></span><span class="paramdefsep"> = </span><span class="paramdefval">-1</span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">T</td>          <td class="paramname"><span class="paramname"><em>eps</em></span><span class="paramdefsep"> = </span><span class="paramdefval">T(1e-8)</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Z-score normalization (standardization): (x - mean) / std. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>Data type </td></tr>
    <tr><td class="paramname">N</td><td>Number of dimensions </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>Input tensor </td></tr>
    <tr><td class="paramname">axis</td><td>Axis along which to normalize (-1 for all elements) </td></tr>
    <tr><td class="paramname">eps</td><td>Small constant to avoid division by zero </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Standardized tensor with mean ~0 and std ~1</dd></dl>
<p>Z-score normalization is common in statistical analysis and machine learning. </p>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06459">6459</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6459</span>                                                                                          {</div>
<div class="line"><span class="lineno"> 6460</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, N&gt;</a> result(tensor.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>(), tensor.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>());</div>
<div class="line"><span class="lineno"> 6461</span>    <span class="keyword">const</span> T* src = tensor.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>();</div>
<div class="line"><span class="lineno"> 6462</span>    T* dst = result.data_ptr();</div>
<div class="line"><span class="lineno"> 6463</span>    <span class="keywordtype">size_t</span> total = tensor.<a class="code hl_function" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7">total_size</a>();</div>
<div class="line"><span class="lineno"> 6464</span>    </div>
<div class="line"><span class="lineno"> 6465</span>    <span class="keywordflow">if</span> (axis == -1) {</div>
<div class="line"><span class="lineno"> 6466</span>        <span class="comment">// Normalize over all elements</span></div>
<div class="line"><span class="lineno"> 6467</span>        T mean = T(0);</div>
<div class="line"><span class="lineno"> 6468</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; total; ++i) {</div>
<div class="line"><span class="lineno"> 6469</span>            mean += src[i];</div>
<div class="line"><span class="lineno"> 6470</span>        }</div>
<div class="line"><span class="lineno"> 6471</span>        mean /= total;</div>
<div class="line"><span class="lineno"> 6472</span>        </div>
<div class="line"><span class="lineno"> 6473</span>        T var = T(0);</div>
<div class="line"><span class="lineno"> 6474</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; total; ++i) {</div>
<div class="line"><span class="lineno"> 6475</span>            T diff = src[i] - mean;</div>
<div class="line"><span class="lineno"> 6476</span>            var += diff * diff;</div>
<div class="line"><span class="lineno"> 6477</span>        }</div>
<div class="line"><span class="lineno"> 6478</span>        var /= total;</div>
<div class="line"><span class="lineno"> 6479</span>        T std_dev = std::sqrt(var + eps);</div>
<div class="line"><span class="lineno"> 6480</span>        </div>
<div class="line"><span class="lineno"> 6481</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; total; ++i) {</div>
<div class="line"><span class="lineno"> 6482</span>            dst[i] = (src[i] - mean) / std_dev;</div>
<div class="line"><span class="lineno"> 6483</span>        }</div>
<div class="line"><span class="lineno"> 6484</span>    } <span class="keywordflow">else</span> <span class="keywordflow">if</span> <span class="keyword">constexpr</span> (N &gt;= 2) {</div>
<div class="line"><span class="lineno"> 6485</span>        <span class="comment">// Normalize along specific axis</span></div>
<div class="line"><span class="lineno"> 6486</span>        <span class="keyword">auto</span> dims = tensor.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>();</div>
<div class="line"><span class="lineno"> 6487</span>        <span class="keywordtype">size_t</span> axis_size = dims[axis];</div>
<div class="line"><span class="lineno"> 6488</span>        <span class="keywordtype">size_t</span> outer_size = 1;</div>
<div class="line"><span class="lineno"> 6489</span>        <span class="keywordtype">size_t</span> inner_size = 1;</div>
<div class="line"><span class="lineno"> 6490</span>        </div>
<div class="line"><span class="lineno"> 6491</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; axis; ++i) {</div>
<div class="line"><span class="lineno"> 6492</span>            outer_size *= dims[i];</div>
<div class="line"><span class="lineno"> 6493</span>        }</div>
<div class="line"><span class="lineno"> 6494</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = axis + 1; i &lt; N; ++i) {</div>
<div class="line"><span class="lineno"> 6495</span>            inner_size *= dims[i];</div>
<div class="line"><span class="lineno"> 6496</span>        }</div>
<div class="line"><span class="lineno"> 6497</span>        </div>
<div class="line"><span class="lineno"> 6498</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> outer = 0; <a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a> &lt; outer_size; ++<a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a>) {</div>
<div class="line"><span class="lineno"> 6499</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> inner = 0; inner &lt; inner_size; ++inner) {</div>
<div class="line"><span class="lineno"> 6500</span>                <span class="comment">// Compute mean for this slice</span></div>
<div class="line"><span class="lineno"> 6501</span>                T mean = T(0);</div>
<div class="line"><span class="lineno"> 6502</span>                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> ax = 0; ax &lt; axis_size; ++ax) {</div>
<div class="line"><span class="lineno"> 6503</span>                    <span class="keywordtype">size_t</span> idx = <a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a> * axis_size * inner_size + ax * inner_size + inner;</div>
<div class="line"><span class="lineno"> 6504</span>                    mean += src[idx];</div>
<div class="line"><span class="lineno"> 6505</span>                }</div>
<div class="line"><span class="lineno"> 6506</span>                mean /= axis_size;</div>
<div class="line"><span class="lineno"> 6507</span>                </div>
<div class="line"><span class="lineno"> 6508</span>                <span class="comment">// Compute variance</span></div>
<div class="line"><span class="lineno"> 6509</span>                T var = T(0);</div>
<div class="line"><span class="lineno"> 6510</span>                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> ax = 0; ax &lt; axis_size; ++ax) {</div>
<div class="line"><span class="lineno"> 6511</span>                    <span class="keywordtype">size_t</span> idx = <a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a> * axis_size * inner_size + ax * inner_size + inner;</div>
<div class="line"><span class="lineno"> 6512</span>                    T diff = src[idx] - mean;</div>
<div class="line"><span class="lineno"> 6513</span>                    var += diff * diff;</div>
<div class="line"><span class="lineno"> 6514</span>                }</div>
<div class="line"><span class="lineno"> 6515</span>                var /= axis_size;</div>
<div class="line"><span class="lineno"> 6516</span>                T std_dev = std::sqrt(var + eps);</div>
<div class="line"><span class="lineno"> 6517</span>                </div>
<div class="line"><span class="lineno"> 6518</span>                <span class="comment">// Normalize</span></div>
<div class="line"><span class="lineno"> 6519</span>                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> ax = 0; ax &lt; axis_size; ++ax) {</div>
<div class="line"><span class="lineno"> 6520</span>                    <span class="keywordtype">size_t</span> idx = <a class="code hl_function" href="namespacelinalg.html#a8a8d04b2734fdcad37cc861687fbb6fc">outer</a> * axis_size * inner_size + ax * inner_size + inner;</div>
<div class="line"><span class="lineno"> 6521</span>                    dst[idx] = (src[idx] - mean) / std_dev;</div>
<div class="line"><span class="lineno"> 6522</span>                }</div>
<div class="line"><span class="lineno"> 6523</span>            }</div>
<div class="line"><span class="lineno"> 6524</span>        }</div>
<div class="line"><span class="lineno"> 6525</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><span class="lineno"> 6526</span>        std::copy_n(src, total, dst);</div>
<div class="line"><span class="lineno"> 6527</span>    }</div>
<div class="line"><span class="lineno"> 6528</span>    </div>
<div class="line"><span class="lineno"> 6529</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6530</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a57c931d0d77f610850f315fdd9acef39_cgraph.png" border="0" usemap="#atensor_8h_a57c931d0d77f610850f315fdd9acef39_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a57c931d0d77f610850f315fdd9acef39_cgraph" id="atensor_8h_a57c931d0d77f610850f315fdd9acef39_cgraph">
<area shape="rect" title="Z&#45;score normalization (standardization): (x &#45; mean) / std." alt="" coords="5,81,129,108"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="181,5,296,32"/>
<area shape="poly" title=" " alt="" coords="96,78,176,42,188,36,191,41,178,46,98,83"/>
<area shape="rect" href="classTensor.html#a03d314303958ffc5644796d8025cd012" title=" " alt="" coords="191,56,287,83"/>
<area shape="poly" title=" " alt="" coords="129,83,175,76,176,81,129,88"/>
<area shape="rect" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7" title=" " alt="" coords="177,107,301,133"/>
<area shape="poly" title=" " alt="" coords="129,101,162,106,161,111,129,106"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="177,157,301,184"/>
<area shape="poly" title=" " alt="" coords="98,106,178,143,191,148,188,153,176,148,96,111"/>
</map>
</div>

</div>
</div>
<a id="a37ee39b629ca93dc83259b6c8591d0d9" name="a37ee39b629ca93dc83259b6c8591d0d9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a37ee39b629ca93dc83259b6c8591d0d9">&#9670;&#160;</a></span>ones()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T, size_t N&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; ones </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a>&lt; N &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>shape</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>use_gpu</em></span><span class="paramdefsep"> = </span><span class="paramdefval">true</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create a tensor filled with ones (NumPy-compatible). </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>The data type </td></tr>
    <tr><td class="paramname">N</td><td>The number of dimensions </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">shape</td><td>The shape of the tensor </td></tr>
    <tr><td class="paramname">use_gpu</td><td>Whether to use GPU </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor filled with ones </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06153">6153</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6153</span>                                                                      {</div>
<div class="line"><span class="lineno"> 6154</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, N&gt;</a> result(shape, use_gpu);</div>
<div class="line"><span class="lineno"> 6155</span>    result.fill(T(1));</div>
<div class="line"><span class="lineno"> 6156</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6157</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a37ee39b629ca93dc83259b6c8591d0d9_cgraph.png" border="0" usemap="#atensor_8h_a37ee39b629ca93dc83259b6c8591d0d9_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a37ee39b629ca93dc83259b6c8591d0d9_cgraph" id="atensor_8h_a37ee39b629ca93dc83259b6c8591d0d9_cgraph">
<area shape="rect" title="Create a tensor filled with ones (NumPy&#45;compatible)." alt="" coords="5,5,55,32"/>
<area shape="rect" href="classTensor.html#a234f74cd16bd13561f7963ba29efb163" title="Fill the tensor with a specified value." alt="" coords="103,5,184,32"/>
<area shape="poly" title=" " alt="" coords="55,16,87,16,87,21,55,21"/>
</map>
</div>

</div>
</div>
<a id="a98854ecedcd00bad8152e2a1064ccfd5" name="a98854ecedcd00bad8152e2a1064ccfd5"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a98854ecedcd00bad8152e2a1064ccfd5">&#9670;&#160;</a></span>operator*()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T, size_t N&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; operator* </td>
          <td>(</td>
          <td class="paramtype">const T &amp;</td>          <td class="paramname"><span class="paramname"><em>scalar</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Scalar * <a class="el" href="classTensor.html" title="Forward declaration for autograd.">Tensor</a> (element-wise multiplication). </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">scalar</td><td>The scalar value. </td></tr>
    <tr><td class="paramname">tensor</td><td>The tensor. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with the result. </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l05177">5177</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 5177</span>                                                                    {</div>
<div class="line"><span class="lineno"> 5178</span>    <span class="keywordflow">return</span> tensor * scalar;</div>
<div class="line"><span class="lineno"> 5179</span>}</div>
</div><!-- fragment -->
</div>
</div>
<a id="ab4f017dc744d8a8c5be14a419efc0b65" name="ab4f017dc744d8a8c5be14a419efc0b65"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ab4f017dc744d8a8c5be14a419efc0b65">&#9670;&#160;</a></span>operator+()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T, size_t N&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; operator+ </td>
          <td>(</td>
          <td class="paramtype">const T &amp;</td>          <td class="paramname"><span class="paramname"><em>scalar</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Scalar + <a class="el" href="classTensor.html" title="Forward declaration for autograd.">Tensor</a> (element-wise addition). </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">scalar</td><td>The scalar value. </td></tr>
    <tr><td class="paramname">tensor</td><td>The tensor. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with the result. </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l05148">5148</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 5148</span>                                                                    {</div>
<div class="line"><span class="lineno"> 5149</span>    <span class="keywordflow">return</span> tensor + scalar;</div>
<div class="line"><span class="lineno"> 5150</span>}</div>
</div><!-- fragment -->
</div>
</div>
<a id="aab7ab5d6f397d5c819291ee64a3285a9" name="aab7ab5d6f397d5c819291ee64a3285a9"></a>
<h2 class="memtitle"><span class="permalink"><a href="#aab7ab5d6f397d5c819291ee64a3285a9">&#9670;&#160;</a></span>operator-()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T, size_t N&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; operator- </td>
          <td>(</td>
          <td class="paramtype">const T &amp;</td>          <td class="paramname"><span class="paramname"><em>scalar</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Scalar - <a class="el" href="classTensor.html" title="Forward declaration for autograd.">Tensor</a> (element-wise subtraction). </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">scalar</td><td>The scalar value. </td></tr>
    <tr><td class="paramname">tensor</td><td>The tensor. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with the result. </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l05159">5159</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 5159</span>                                                                    {</div>
<div class="line"><span class="lineno"> 5160</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, N&gt;</a> result(tensor.<a class="code hl_variable" href="classTensor.html#a43fadce1ce3dd9ddb47c8b82168edb52">dims_</a>, tensor.<a class="code hl_variable" href="classTensor.html#aa3214ec02474d17494e1eb95d5006262">use_gpu_</a>);</div>
<div class="line"><span class="lineno"> 5161</span>    <span class="keywordtype">size_t</span> total = result.total_size();</div>
<div class="line"><span class="lineno"> 5162</span>    </div>
<div class="line"><span class="lineno"> 5163</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; total; ++i) {</div>
<div class="line"><span class="lineno"> 5164</span>        result.data_[i] = scalar - tensor.<a class="code hl_variable" href="classTensor.html#acf7ced620891506216fc0112a743e04b">data_</a>[i];</div>
<div class="line"><span class="lineno"> 5165</span>    }</div>
<div class="line"><span class="lineno"> 5166</span>    </div>
<div class="line"><span class="lineno"> 5167</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 5168</span>}</div>
<div class="ttc" id="aclassTensor_html_a43fadce1ce3dd9ddb47c8b82168edb52"><div class="ttname"><a href="classTensor.html#a43fadce1ce3dd9ddb47c8b82168edb52">Tensor::dims_</a></div><div class="ttdeci">TensorIndices&lt; N &gt; dims_</div><div class="ttdoc">Dimensions of the tensor.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00447">tensor.h:447</a></div></div>
<div class="ttc" id="aclassTensor_html_aa3214ec02474d17494e1eb95d5006262"><div class="ttname"><a href="classTensor.html#aa3214ec02474d17494e1eb95d5006262">Tensor::use_gpu_</a></div><div class="ttdeci">bool use_gpu_</div><div class="ttdoc">Flag to indicate if GPU should be used.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00449">tensor.h:449</a></div></div>
<div class="ttc" id="aclassTensor_html_acf7ced620891506216fc0112a743e04b"><div class="ttname"><a href="classTensor.html#acf7ced620891506216fc0112a743e04b">Tensor::data_</a></div><div class="ttdeci">std::unique_ptr&lt; T[]&gt; data_</div><div class="ttdoc">Flat data storage in row-major order.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00446">tensor.h:446</a></div></div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_aab7ab5d6f397d5c819291ee64a3285a9_cgraph.png" border="0" usemap="#atensor_8h_aab7ab5d6f397d5c819291ee64a3285a9_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_aab7ab5d6f397d5c819291ee64a3285a9_cgraph" id="atensor_8h_aab7ab5d6f397d5c819291ee64a3285a9_cgraph">
<area shape="rect" title=" " alt="" coords="5,5,78,32"/>
<area shape="rect" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7" title=" " alt="" coords="126,5,250,32"/>
<area shape="poly" title=" " alt="" coords="78,16,110,16,110,21,78,21"/>
</map>
</div>

</div>
</div>
<a id="a68ab7ecde44431a4d8e941737a5b2cba" name="a68ab7ecde44431a4d8e941737a5b2cba"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a68ab7ecde44431a4d8e941737a5b2cba">&#9670;&#160;</a></span>operator/()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T, size_t N&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; operator/ </td>
          <td>(</td>
          <td class="paramtype">const T &amp;</td>          <td class="paramname"><span class="paramname"><em>scalar</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">
<p>Scalar / <a class="el" href="classTensor.html" title="Forward declaration for autograd.">Tensor</a> (element-wise division). </p><dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">scalar</td><td>The scalar value. </td></tr>
    <tr><td class="paramname">tensor</td><td>The tensor. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor with the result. </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l05188">5188</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 5188</span>                                                                    {</div>
<div class="line"><span class="lineno"> 5189</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, N&gt;</a> result(tensor.<a class="code hl_variable" href="classTensor.html#a43fadce1ce3dd9ddb47c8b82168edb52">dims_</a>, tensor.<a class="code hl_variable" href="classTensor.html#aa3214ec02474d17494e1eb95d5006262">use_gpu_</a>);</div>
<div class="line"><span class="lineno"> 5190</span>    <span class="keywordtype">size_t</span> total = result.total_size();</div>
<div class="line"><span class="lineno"> 5191</span>    </div>
<div class="line"><span class="lineno"> 5192</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; total; ++i) {</div>
<div class="line"><span class="lineno"> 5193</span>        result.data_[i] = scalar / tensor.<a class="code hl_variable" href="classTensor.html#acf7ced620891506216fc0112a743e04b">data_</a>[i];</div>
<div class="line"><span class="lineno"> 5194</span>    }</div>
<div class="line"><span class="lineno"> 5195</span>    </div>
<div class="line"><span class="lineno"> 5196</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 5197</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a68ab7ecde44431a4d8e941737a5b2cba_cgraph.png" border="0" usemap="#atensor_8h_a68ab7ecde44431a4d8e941737a5b2cba_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a68ab7ecde44431a4d8e941737a5b2cba_cgraph" id="atensor_8h_a68ab7ecde44431a4d8e941737a5b2cba_cgraph">
<area shape="rect" title=" " alt="" coords="5,5,78,32"/>
<area shape="rect" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7" title=" " alt="" coords="126,5,250,32"/>
<area shape="poly" title=" " alt="" coords="78,16,110,16,110,21,78,21"/>
</map>
</div>

</div>
</div>
<a id="ad71687cadd6e7bdae0f2d66fc9f437e1" name="ad71687cadd6e7bdae0f2d66fc9f437e1"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad71687cadd6e7bdae0f2d66fc9f437e1">&#9670;&#160;</a></span>repeat_along_axis()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T, size_t N&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; repeat_along_axis </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>repeats</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>axis</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Construct tensor by repeating along specified axis. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>Input tensor to repeat. </td></tr>
    <tr><td class="paramname">repeats</td><td>Number of times to repeat along the axis. </td></tr>
    <tr><td class="paramname">axis</td><td>Axis along which to repeat. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Repeated tensor. </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">repeats</td><td>Number of repetitions. </td></tr>
    <tr><td class="paramname">axis</td><td>Axis along which to repeat. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Repeated tensor. </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l05870">5870</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 5870</span>                                                                                            {</div>
<div class="line"><span class="lineno"> 5871</span>    <span class="keywordflow">if</span> (axis &gt;= N) {</div>
<div class="line"><span class="lineno"> 5872</span>        <span class="keywordflow">return</span> tensor;</div>
<div class="line"><span class="lineno"> 5873</span>    }</div>
<div class="line"><span class="lineno"> 5874</span>    </div>
<div class="line"><span class="lineno"> 5875</span>    <span class="keyword">auto</span> tensor_dims = tensor.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>();</div>
<div class="line"><span class="lineno"> 5876</span>    std::array&lt;size_t, N&gt; new_dims = tensor_dims;</div>
<div class="line"><span class="lineno"> 5877</span>    new_dims[axis] *= repeats;</div>
<div class="line"><span class="lineno"> 5878</span>    </div>
<div class="line"><span class="lineno"> 5879</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, N&gt;</a> result(new_dims, tensor.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>(), <span class="keyword">false</span>);</div>
<div class="line"><span class="lineno"> 5880</span>    </div>
<div class="line"><span class="lineno"> 5881</span>    <span class="keyword">const</span> T* tensor_data = tensor.<a class="code hl_function" href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4">data</a>();</div>
<div class="line"><span class="lineno"> 5882</span>    T* result_data = result.data();</div>
<div class="line"><span class="lineno"> 5883</span>    </div>
<div class="line"><span class="lineno"> 5884</span>    <span class="comment">// Compute strides</span></div>
<div class="line"><span class="lineno"> 5885</span>    std::array&lt;size_t, N&gt; tensor_strides;</div>
<div class="line"><span class="lineno"> 5886</span>    std::array&lt;size_t, N&gt; result_strides;</div>
<div class="line"><span class="lineno"> 5887</span>    tensor_strides[N-1] = 1;</div>
<div class="line"><span class="lineno"> 5888</span>    result_strides[N-1] = 1;</div>
<div class="line"><span class="lineno"> 5889</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = N-1; i-- &gt; 0;) {</div>
<div class="line"><span class="lineno"> 5890</span>        tensor_strides[i] = tensor_strides[i+1] * tensor_dims[i+1];</div>
<div class="line"><span class="lineno"> 5891</span>        result_strides[i] = result_strides[i+1] * new_dims[i+1];</div>
<div class="line"><span class="lineno"> 5892</span>    }</div>
<div class="line"><span class="lineno"> 5893</span>    </div>
<div class="line"><span class="lineno"> 5894</span>    <span class="comment">// Copy data with repetition</span></div>
<div class="line"><span class="lineno"> 5895</span>    <span class="keywordtype">size_t</span> result_total = result.total_size();</div>
<div class="line"><span class="lineno"> 5896</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> idx = 0; idx &lt; result_total; ++idx) {</div>
<div class="line"><span class="lineno"> 5897</span>        <span class="comment">// Convert flat index to coordinates</span></div>
<div class="line"><span class="lineno"> 5898</span>        std::array&lt;size_t, N&gt; coords;</div>
<div class="line"><span class="lineno"> 5899</span>        <span class="keywordtype">size_t</span> remaining = idx;</div>
<div class="line"><span class="lineno"> 5900</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; N; ++i) {</div>
<div class="line"><span class="lineno"> 5901</span>            coords[i] = remaining / result_strides[i];</div>
<div class="line"><span class="lineno"> 5902</span>            remaining %= result_strides[i];</div>
<div class="line"><span class="lineno"> 5903</span>        }</div>
<div class="line"><span class="lineno"> 5904</span>        </div>
<div class="line"><span class="lineno"> 5905</span>        <span class="comment">// Map coordinate back to source</span></div>
<div class="line"><span class="lineno"> 5906</span>        coords[axis] /= repeats;</div>
<div class="line"><span class="lineno"> 5907</span>        </div>
<div class="line"><span class="lineno"> 5908</span>        <span class="comment">// Convert to flat index in source</span></div>
<div class="line"><span class="lineno"> 5909</span>        <span class="keywordtype">size_t</span> src_idx = 0;</div>
<div class="line"><span class="lineno"> 5910</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; N; ++i) {</div>
<div class="line"><span class="lineno"> 5911</span>            src_idx += coords[i] * tensor_strides[i];</div>
<div class="line"><span class="lineno"> 5912</span>        }</div>
<div class="line"><span class="lineno"> 5913</span>        </div>
<div class="line"><span class="lineno"> 5914</span>        result_data[idx] = tensor_data[src_idx];</div>
<div class="line"><span class="lineno"> 5915</span>    }</div>
<div class="line"><span class="lineno"> 5916</span>    </div>
<div class="line"><span class="lineno"> 5917</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 5918</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_ad71687cadd6e7bdae0f2d66fc9f437e1_cgraph.png" border="0" usemap="#atensor_8h_ad71687cadd6e7bdae0f2d66fc9f437e1_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_ad71687cadd6e7bdae0f2d66fc9f437e1_cgraph" id="atensor_8h_ad71687cadd6e7bdae0f2d66fc9f437e1_cgraph">
<area shape="rect" title="Construct tensor by repeating along specified axis." alt="" coords="5,81,132,108"/>
<area shape="rect" href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4" title=" " alt="" coords="195,5,288,32"/>
<area shape="poly" title=" " alt="" coords="98,78,179,42,191,36,194,41,181,46,100,83"/>
<area shape="rect" href="classTensor.html#a03d314303958ffc5644796d8025cd012" title=" " alt="" coords="194,56,290,83"/>
<area shape="poly" title=" " alt="" coords="132,83,178,76,179,81,132,88"/>
<area shape="rect" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7" title=" " alt="" coords="180,107,304,133"/>
<area shape="poly" title=" " alt="" coords="132,101,165,106,164,111,132,107"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="180,157,304,184"/>
<area shape="poly" title=" " alt="" coords="100,106,181,143,194,148,191,153,179,148,98,111"/>
</map>
</div>

</div>
</div>
<a id="a280a6c1ac0d132b0a98af81c1fe371d8" name="a280a6c1ac0d132b0a98af81c1fe371d8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a280a6c1ac0d132b0a98af81c1fe371d8">&#9670;&#160;</a></span>reshape_to()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T, size_t N, size_t M&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">auto reshape_to </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a>&lt; M &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>new_shape</em></span>&#160;)-&gt;std::variant&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T, M &gt;, <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaa">TensorError</a> &gt;</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Reshape a tensor (returns variant for error handling). </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>The data type </td></tr>
    <tr><td class="paramname">N</td><td>Original number of dimensions </td></tr>
    <tr><td class="paramname">M</td><td>New number of dimensions </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>The input tensor </td></tr>
    <tr><td class="paramname">new_shape</td><td>The target shape </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A reshaped tensor or <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaa" title="Error codes for tensor operations.">TensorError</a> if sizes don't match</dd></dl>
<dl class="section note"><dt>Note</dt><dd>This is an alias for the reshape method but returns a variant </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06271">6271</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6272</span>                                             {</div>
<div class="line"><span class="lineno"> 6273</span>    </div>
<div class="line"><span class="lineno"> 6274</span>    <span class="comment">// Check if total size matches</span></div>
<div class="line"><span class="lineno"> 6275</span>    <span class="keywordtype">size_t</span> old_size = tensor.<a class="code hl_function" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7">total_size</a>();</div>
<div class="line"><span class="lineno"> 6276</span>    <span class="keywordtype">size_t</span> new_size = 1;</div>
<div class="line"><span class="lineno"> 6277</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; M; ++i) {</div>
<div class="line"><span class="lineno"> 6278</span>        new_size *= new_shape[i];</div>
<div class="line"><span class="lineno"> 6279</span>    }</div>
<div class="line"><span class="lineno"> 6280</span>    </div>
<div class="line"><span class="lineno"> 6281</span>    <span class="keywordflow">if</span> (old_size != new_size) {</div>
<div class="line"><span class="lineno"> 6282</span>        <span class="keywordflow">return</span> <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa2664c241558d7674e8ed4d5f63d2e463">TensorError::DimensionMismatch</a>;</div>
<div class="line"><span class="lineno"> 6283</span>    }</div>
<div class="line"><span class="lineno"> 6284</span>    </div>
<div class="line"><span class="lineno"> 6285</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, M&gt;</a> result(new_shape, tensor.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>());</div>
<div class="line"><span class="lineno"> 6286</span>    std::copy_n(tensor.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>(), old_size, result.data_ptr());</div>
<div class="line"><span class="lineno"> 6287</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6288</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a280a6c1ac0d132b0a98af81c1fe371d8_cgraph.png" border="0" usemap="#atensor_8h_a280a6c1ac0d132b0a98af81c1fe371d8_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a280a6c1ac0d132b0a98af81c1fe371d8_cgraph" id="atensor_8h_a280a6c1ac0d132b0a98af81c1fe371d8_cgraph">
<area shape="rect" title="Reshape a tensor (returns variant for error handling)." alt="" coords="5,5,91,32"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="139,5,254,32"/>
<area shape="poly" title=" " alt="" coords="91,16,123,16,123,21,91,21"/>
</map>
</div>

</div>
</div>
<a id="a3798be100af6c60da8c8489ba3ac808a" name="a3798be100af6c60da8c8489ba3ac808a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a3798be100af6c60da8c8489ba3ac808a">&#9670;&#160;</a></span>rightCols()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; rightCols </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>matrix</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>n</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Extract rightmost n columns from a 2D tensor. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>Data type </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">matrix</td><td>2D tensor </td></tr>
    <tr><td class="paramname">n</td><td>Number of columns to extract </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>2D tensor containing rightmost n columns</dd></dl>
<div class="fragment"><div class="line"><a class="code hl_class" href="classTensor.html">Tensor&lt;float, 2&gt;</a> mat({5, 10});</div>
<div class="line"><span class="keyword">auto</span> right3 = mat.<a class="code hl_function" href="classTensor.html#aa25623075f40e0244dd4c2a649e2b3d5">rightCols</a>(3);</div>
<div class="ttc" id="aclassTensor_html_aa25623075f40e0244dd4c2a649e2b3d5"><div class="ttname"><a href="classTensor.html#aa25623075f40e0244dd4c2a649e2b3d5">Tensor::rightCols</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; rightCols(size_t n) const</div><div class="ttdoc">Extract rightmost n columns (only for 2D tensors).</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l05133">tensor.h:5133</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06936">6936</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6936</span>                                                             {</div>
<div class="line"><span class="lineno"> 6937</span>    <span class="keyword">auto</span> dims = matrix.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>();</div>
<div class="line"><span class="lineno"> 6938</span>    <span class="keywordtype">size_t</span> rows = dims[0];</div>
<div class="line"><span class="lineno"> 6939</span>    <span class="keywordtype">size_t</span> cols = dims[1];</div>
<div class="line"><span class="lineno"> 6940</span>    <span class="keywordflow">if</span> (n &gt; cols) n = cols;</div>
<div class="line"><span class="lineno"> 6941</span>    </div>
<div class="line"><span class="lineno"> 6942</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> result({rows, n}, matrix.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>());</div>
<div class="line"><span class="lineno"> 6943</span>    </div>
<div class="line"><span class="lineno"> 6944</span>    <span class="keyword">const</span> T* src = matrix.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>();</div>
<div class="line"><span class="lineno"> 6945</span>    T* dst = result.data_ptr();</div>
<div class="line"><span class="lineno"> 6946</span>    </div>
<div class="line"><span class="lineno"> 6947</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; rows; ++i) {</div>
<div class="line"><span class="lineno"> 6948</span>        std::copy_n(src + i * cols + (cols - n), n, dst + i * n);</div>
<div class="line"><span class="lineno"> 6949</span>    }</div>
<div class="line"><span class="lineno"> 6950</span>    </div>
<div class="line"><span class="lineno"> 6951</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6952</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a3798be100af6c60da8c8489ba3ac808a_cgraph.png" border="0" usemap="#atensor_8h_a3798be100af6c60da8c8489ba3ac808a_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a3798be100af6c60da8c8489ba3ac808a_cgraph" id="atensor_8h_a3798be100af6c60da8c8489ba3ac808a_cgraph">
<area shape="rect" title="Extract rightmost n columns from a 2D tensor." alt="" coords="5,56,79,83"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="131,5,246,32"/>
<area shape="poly" title=" " alt="" coords="78,54,133,35,134,40,80,59"/>
<area shape="rect" href="classTensor.html#a03d314303958ffc5644796d8025cd012" title=" " alt="" coords="141,56,237,83"/>
<area shape="poly" title=" " alt="" coords="79,67,125,67,125,72,79,72"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="127,107,251,133"/>
<area shape="poly" title=" " alt="" coords="80,79,134,99,133,104,78,84"/>
</map>
</div>

</div>
</div>
<a id="adf94b1b28dd9932dd278abaa3cb7a9ee" name="adf94b1b28dd9932dd278abaa3cb7a9ee"></a>
<h2 class="memtitle"><span class="permalink"><a href="#adf94b1b28dd9932dd278abaa3cb7a9ee">&#9670;&#160;</a></span>row()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; row </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>matrix</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>row_idx</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Extract a single row from a 2D tensor. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>Data type </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">matrix</td><td>2D tensor </td></tr>
    <tr><td class="paramname">row_idx</td><td>Row index to extract </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>1D tensor containing the row</dd></dl>
<p>This is a convenience method equivalent to select(0, row_idx) for matrices. </p><div class="fragment"><div class="line"><a class="code hl_class" href="classTensor.html">Tensor&lt;float, 2&gt;</a> mat({5, 3});</div>
<div class="line"><span class="keyword">auto</span> row2 = mat.<a class="code hl_function" href="classTensor.html#a4ff4d01c7fdd48791ebe12a02dbeb655">row</a>(2);  <span class="comment">// Extract 3rd row</span></div>
<div class="ttc" id="aclassTensor_html_a4ff4d01c7fdd48791ebe12a02dbeb655"><div class="ttname"><a href="classTensor.html#a4ff4d01c7fdd48791ebe12a02dbeb655">Tensor::row</a></div><div class="ttdeci">Tensor&lt; T, 1 &gt; row(size_t row_idx) const</div><div class="ttdoc">Extract a single row (only for 2D tensors).</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l05040">tensor.h:5040</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06648">6648</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6648</span>                                                             {</div>
<div class="line"><span class="lineno"> 6649</span>    <span class="keyword">auto</span> dims = matrix.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>();</div>
<div class="line"><span class="lineno"> 6650</span>    <span class="keywordflow">if</span> (row_idx &gt;= dims[0]) {</div>
<div class="line"><span class="lineno"> 6651</span>        <span class="keywordflow">throw</span> std::out_of_range(<span class="stringliteral">&quot;Row index out of bounds&quot;</span>);</div>
<div class="line"><span class="lineno"> 6652</span>    }</div>
<div class="line"><span class="lineno"> 6653</span>    </div>
<div class="line"><span class="lineno"> 6654</span>    <span class="keywordtype">size_t</span> cols = dims[1];</div>
<div class="line"><span class="lineno"> 6655</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 1&gt;</a> result({cols}, matrix.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>());</div>
<div class="line"><span class="lineno"> 6656</span>    </div>
<div class="line"><span class="lineno"> 6657</span>    <span class="keyword">const</span> T* src = matrix.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>();</div>
<div class="line"><span class="lineno"> 6658</span>    T* dst = result.data_ptr();</div>
<div class="line"><span class="lineno"> 6659</span>    </div>
<div class="line"><span class="lineno"> 6660</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; cols; ++j) {</div>
<div class="line"><span class="lineno"> 6661</span>        dst[j] = src[row_idx * cols + j];</div>
<div class="line"><span class="lineno"> 6662</span>    }</div>
<div class="line"><span class="lineno"> 6663</span>    </div>
<div class="line"><span class="lineno"> 6664</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6665</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_adf94b1b28dd9932dd278abaa3cb7a9ee_cgraph.png" border="0" usemap="#atensor_8h_adf94b1b28dd9932dd278abaa3cb7a9ee_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_adf94b1b28dd9932dd278abaa3cb7a9ee_cgraph" id="atensor_8h_adf94b1b28dd9932dd278abaa3cb7a9ee_cgraph">
<area shape="rect" title="Extract a single row from a 2D tensor." alt="" coords="5,56,48,83"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="100,5,216,32"/>
<area shape="poly" title=" " alt="" coords="47,59,106,36,108,41,49,64"/>
<area shape="rect" href="classTensor.html#a03d314303958ffc5644796d8025cd012" title=" " alt="" coords="110,56,206,83"/>
<area shape="poly" title=" " alt="" coords="48,67,94,67,94,72,48,72"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="96,107,220,133"/>
<area shape="poly" title=" " alt="" coords="49,75,108,98,106,103,47,80"/>
</map>
</div>
<div class="dynheader">
Here is the caller graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_adf94b1b28dd9932dd278abaa3cb7a9ee_icgraph.png" border="0" usemap="#atensor_8h_adf94b1b28dd9932dd278abaa3cb7a9ee_icgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_adf94b1b28dd9932dd278abaa3cb7a9ee_icgraph" id="atensor_8h_adf94b1b28dd9932dd278abaa3cb7a9ee_icgraph">
<area shape="rect" title="Extract a single row from a 2D tensor." alt="" coords="566,183,609,209"/>
<area shape="rect" href="namespacelinalg.html#a6b7af062b5a9642d788fcc084335b39c" title=" " alt="" coords="370,5,511,32"/>
<area shape="poly" title=" " alt="" coords="578,168,558,106,540,74,517,46,500,35,503,30,520,42,545,71,563,104,583,166"/>
<area shape="rect" href="tensor__c_8cpp.html#a1d2268dec0e2609a5de6ddad0045383e" title=" " alt="" coords="377,56,504,83"/>
<area shape="poly" title=" " alt="" coords="572,170,549,132,534,113,517,97,497,86,500,81,520,93,538,109,554,129,576,167"/>
<area shape="rect" href="tensor__c_8cpp.html#a9a603f0a92bc4eedac4296187b7532e6" title=" " alt="" coords="363,107,518,133"/>
<area shape="poly" title=" " alt="" coords="558,175,517,148,491,136,493,132,520,143,561,170"/>
<area shape="rect" href="tensor__c_8cpp.html#a876c89ce000825fa6255ea8c7649aefe" title=" " alt="" coords="377,157,504,184"/>
<area shape="poly" title=" " alt="" coords="551,192,504,184,505,179,552,187"/>
<area shape="rect" href="tensor__c_8cpp.html#a5a98f19069ba7a51f436659c6a6941b7" title=" " alt="" coords="384,208,498,235"/>
<area shape="poly" title=" " alt="" coords="552,205,498,214,497,209,551,199"/>
<area shape="rect" href="tensor__c_8cpp.html#ae244e8a6c44fcfe2f940110ce69250cb" title=" " alt="" coords="370,259,512,285"/>
<area shape="poly" title=" " alt="" coords="561,222,520,249,493,260,491,256,517,244,558,217"/>
<area shape="rect" href="tensor__c_8cpp.html#aafb2ff8a91dff85dbf7c6d8a91297a31" title=" " alt="" coords="384,309,498,336"/>
<area shape="poly" title=" " alt="" coords="576,225,554,263,538,283,520,299,500,311,497,306,517,295,534,279,549,260,572,222"/>
<area shape="rect" href="namespacelinalg.html#ad07d8335c6ed4ffb675492effc453771" title=" " alt="" coords="398,360,483,387"/>
<area shape="poly" title=" " alt="" coords="583,226,563,288,545,321,520,350,503,361,484,369,482,364,501,357,517,346,540,318,558,286,578,224"/>
<area shape="rect" href="namespacelinalg.html#a0e459857cd625f66948d7ae48731b17a" title="Compute numerical rank of a matrix using SVD." alt="" coords="188,360,315,387"/>
<area shape="poly" title=" " alt="" coords="383,376,316,376,316,371,383,371"/>
<area shape="rect" href="tensor__c_8cpp.html#af30504e8e051a714b7a0fdcae0f7c636" title=" " alt="" coords="5,335,140,361"/>
<area shape="poly" title=" " alt="" coords="172,365,139,360,140,355,173,360"/>
<area shape="rect" href="tensor__c_8cpp.html#ab1f7ff7476a784a17149afa2fd100d07" title=" " alt="" coords="12,385,133,412"/>
<area shape="poly" title=" " alt="" coords="173,387,134,393,133,387,172,382"/>
</map>
</div>

</div>
</div>
<a id="abcbf52cee83938743ba0195663090841" name="abcbf52cee83938743ba0195663090841"></a>
<h2 class="memtitle"><span class="permalink"><a href="#abcbf52cee83938743ba0195663090841">&#9670;&#160;</a></span>searchsorted()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; size_t, 1 &gt; searchsorted </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>values</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>search_values</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Binary search to find indices where elements should be inserted (1D only). </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">values</td><td>Sorted tensor to search in. </td></tr>
    <tr><td class="paramname">search_values</td><td>Values to search for. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="classTensor.html" title="Forward declaration for autograd.">Tensor</a> of insertion indices. </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l05610">5610</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 5610</span>                                                                                              {</div>
<div class="line"><span class="lineno"> 5611</span>    <span class="keywordtype">size_t</span> n = values.<a class="code hl_function" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7">total_size</a>();</div>
<div class="line"><span class="lineno"> 5612</span>    <span class="keywordtype">size_t</span> m = search_values.<a class="code hl_function" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7">total_size</a>();</div>
<div class="line"><span class="lineno"> 5613</span>    </div>
<div class="line"><span class="lineno"> 5614</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;size_t, 1&gt;</a> result({m}, <span class="keyword">false</span>, <span class="keyword">false</span>);</div>
<div class="line"><span class="lineno"> 5615</span>    </div>
<div class="line"><span class="lineno"> 5616</span>    <span class="keyword">const</span> T* values_data = values.<a class="code hl_function" href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4">data</a>();</div>
<div class="line"><span class="lineno"> 5617</span>    <span class="keyword">const</span> T* search_data = search_values.<a class="code hl_function" href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4">data</a>();</div>
<div class="line"><span class="lineno"> 5618</span>    <span class="keywordtype">size_t</span>* result_data = result.data();</div>
<div class="line"><span class="lineno"> 5619</span>    </div>
<div class="line"><span class="lineno"> 5620</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; m; ++i) {</div>
<div class="line"><span class="lineno"> 5621</span>        T val = search_data[i];</div>
<div class="line"><span class="lineno"> 5622</span>        <span class="keyword">auto</span> it = std::lower_bound(values_data, values_data + n, val);</div>
<div class="line"><span class="lineno"> 5623</span>        result_data[i] = it - values_data;</div>
<div class="line"><span class="lineno"> 5624</span>    }</div>
<div class="line"><span class="lineno"> 5625</span>    </div>
<div class="line"><span class="lineno"> 5626</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 5627</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_abcbf52cee83938743ba0195663090841_cgraph.png" border="0" usemap="#atensor_8h_abcbf52cee83938743ba0195663090841_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_abcbf52cee83938743ba0195663090841_cgraph" id="atensor_8h_abcbf52cee83938743ba0195663090841_cgraph">
<area shape="rect" title="Binary search to find indices where elements should be inserted (1D only)." alt="" coords="5,31,102,57"/>
<area shape="rect" href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4" title=" " alt="" coords="165,5,258,32"/>
<area shape="poly" title=" " alt="" coords="102,34,149,26,150,31,102,39"/>
<area shape="rect" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7" title=" " alt="" coords="150,56,274,83"/>
<area shape="poly" title=" " alt="" coords="102,49,135,54,134,60,102,54"/>
</map>
</div>

</div>
</div>
<a id="a4bfe3189f926716838813a01b6c37038" name="a4bfe3189f926716838813a01b6c37038"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a4bfe3189f926716838813a01b6c37038">&#9670;&#160;</a></span>sort()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; sort </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>ascending</em></span><span class="paramdefsep"> = </span><span class="paramdefval">true</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Sort tensor elements and return sorted tensor (1D only). </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>Input tensor to sort. </td></tr>
    <tr><td class="paramname">ascending</td><td>If true, sort in ascending order; otherwise descending. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Sorted 1D tensor. </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l05502">5502</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 5502</span>                                                                     {</div>
<div class="line"><span class="lineno"> 5503</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 1&gt;</a> result = tensor;</div>
<div class="line"><span class="lineno"> 5504</span>    <span class="keywordtype">size_t</span> n = result.<a class="code hl_function" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7">total_size</a>();</div>
<div class="line"><span class="lineno"> 5505</span>    T* data = result.<a class="code hl_function" href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4">data</a>();</div>
<div class="line"><span class="lineno"> 5506</span>    </div>
<div class="line"><span class="lineno"> 5507</span>    <span class="keywordflow">if</span> (ascending) {</div>
<div class="line"><span class="lineno"> 5508</span>        std::sort(data, data + n);</div>
<div class="line"><span class="lineno"> 5509</span>    } <span class="keywordflow">else</span> {</div>
<div class="line"><span class="lineno"> 5510</span>        std::sort(data, data + n, std::greater&lt;T&gt;());</div>
<div class="line"><span class="lineno"> 5511</span>    }</div>
<div class="line"><span class="lineno"> 5512</span>    </div>
<div class="line"><span class="lineno"> 5513</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 5514</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a4bfe3189f926716838813a01b6c37038_cgraph.png" border="0" usemap="#atensor_8h_a4bfe3189f926716838813a01b6c37038_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a4bfe3189f926716838813a01b6c37038_cgraph" id="atensor_8h_a4bfe3189f926716838813a01b6c37038_cgraph">
<area shape="rect" title="Sort tensor elements and return sorted tensor (1D only)." alt="" coords="5,31,49,57"/>
<area shape="rect" href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4" title=" " alt="" coords="112,5,206,32"/>
<area shape="poly" title=" " alt="" coords="49,37,96,28,97,33,50,43"/>
<area shape="rect" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7" title=" " alt="" coords="97,56,221,83"/>
<area shape="poly" title=" " alt="" coords="50,45,82,52,81,57,49,51"/>
</map>
</div>

</div>
</div>
<a id="a139335a446015c5f7ad70fa3d2ccfbec" name="a139335a446015c5f7ad70fa3d2ccfbec"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a139335a446015c5f7ad70fa3d2ccfbec">&#9670;&#160;</a></span>split()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T, size_t N&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">std::vector&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &gt; split </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>num_chunks</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>axis</em></span><span class="paramdefsep"> = </span><span class="paramdefval">0</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Split tensor into chunks along specified axis. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>Input tensor to split. </td></tr>
    <tr><td class="paramname">num_chunks</td><td>Number of chunks to split into. </td></tr>
    <tr><td class="paramname">axis</td><td>Axis along which to split. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="linalg_8h.html#a99ba6a0becc538dc0109d3818ca80f3b" title="Type alias for 1D vectors.">Vector</a> of tensors. </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l05641">5641</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 5641</span>                                                                                              {</div>
<div class="line"><span class="lineno"> 5642</span>    <span class="keywordflow">if</span> (axis &gt;= N || num_chunks == 0) {</div>
<div class="line"><span class="lineno"> 5643</span>        <span class="keywordflow">return</span> {tensor};</div>
<div class="line"><span class="lineno"> 5644</span>    }</div>
<div class="line"><span class="lineno"> 5645</span>    </div>
<div class="line"><span class="lineno"> 5646</span>    <span class="keyword">auto</span> dims = tensor.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>();</div>
<div class="line"><span class="lineno"> 5647</span>    <span class="keywordtype">size_t</span> dim_size = dims[axis];</div>
<div class="line"><span class="lineno"> 5648</span>    </div>
<div class="line"><span class="lineno"> 5649</span>    <span class="keywordflow">if</span> (num_chunks &gt; dim_size) {</div>
<div class="line"><span class="lineno"> 5650</span>        num_chunks = dim_size;</div>
<div class="line"><span class="lineno"> 5651</span>    }</div>
<div class="line"><span class="lineno"> 5652</span>    </div>
<div class="line"><span class="lineno"> 5653</span>    std::vector&lt;Tensor&lt;T, N&gt;&gt; chunks;</div>
<div class="line"><span class="lineno"> 5654</span>    chunks.reserve(num_chunks);</div>
<div class="line"><span class="lineno"> 5655</span>    </div>
<div class="line"><span class="lineno"> 5656</span>    <span class="comment">// Calculate chunk sizes</span></div>
<div class="line"><span class="lineno"> 5657</span>    <span class="keywordtype">size_t</span> base_size = dim_size / num_chunks;</div>
<div class="line"><span class="lineno"> 5658</span>    <span class="keywordtype">size_t</span> remainder = dim_size % num_chunks;</div>
<div class="line"><span class="lineno"> 5659</span>    </div>
<div class="line"><span class="lineno"> 5660</span>    <span class="keywordtype">size_t</span> start = 0;</div>
<div class="line"><span class="lineno"> 5661</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> chunk_idx = 0; chunk_idx &lt; num_chunks; ++chunk_idx) {</div>
<div class="line"><span class="lineno"> 5662</span>        <span class="comment">// First &#39;remainder&#39; chunks get an extra element</span></div>
<div class="line"><span class="lineno"> 5663</span>        <span class="keywordtype">size_t</span> chunk_size = base_size + (chunk_idx &lt; remainder ? 1 : 0);</div>
<div class="line"><span class="lineno"> 5664</span>        </div>
<div class="line"><span class="lineno"> 5665</span>        <span class="keywordflow">if</span> (chunk_size == 0) <span class="keywordflow">break</span>;</div>
<div class="line"><span class="lineno"> 5666</span>        </div>
<div class="line"><span class="lineno"> 5667</span>        <span class="comment">// Create new dimensions for the chunk</span></div>
<div class="line"><span class="lineno"> 5668</span>        <span class="keyword">auto</span> chunk_dims = dims;</div>
<div class="line"><span class="lineno"> 5669</span>        chunk_dims[axis] = chunk_size;</div>
<div class="line"><span class="lineno"> 5670</span>        </div>
<div class="line"><span class="lineno"> 5671</span>        <a class="code hl_class" href="classTensor.html">Tensor&lt;T, N&gt;</a> <a class="code hl_function" href="#a64dfa8c2475ed50ae00ef1d4e1c12fd2">chunk</a>(chunk_dims, tensor.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>(), <span class="keyword">false</span>);</div>
<div class="line"><span class="lineno"> 5672</span>        </div>
<div class="line"><span class="lineno"> 5673</span>        <span class="comment">// Copy data - need to handle arbitrary dimensions</span></div>
<div class="line"><span class="lineno"> 5674</span>        <span class="comment">// For simplicity, we&#39;ll copy using flat indexing with stride calculations</span></div>
<div class="line"><span class="lineno"> 5675</span>        std::array&lt;size_t, N&gt; strides;</div>
<div class="line"><span class="lineno"> 5676</span>        strides[N-1] = 1;</div>
<div class="line"><span class="lineno"> 5677</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = N-1; i-- &gt; 0;) {</div>
<div class="line"><span class="lineno"> 5678</span>            strides[i] = strides[i+1] * dims[i+1];</div>
<div class="line"><span class="lineno"> 5679</span>        }</div>
<div class="line"><span class="lineno"> 5680</span>        </div>
<div class="line"><span class="lineno"> 5681</span>        std::array&lt;size_t, N&gt; chunk_strides;</div>
<div class="line"><span class="lineno"> 5682</span>        chunk_strides[N-1] = 1;</div>
<div class="line"><span class="lineno"> 5683</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = N-1; i-- &gt; 0;) {</div>
<div class="line"><span class="lineno"> 5684</span>            chunk_strides[i] = chunk_strides[i+1] * chunk_dims[i+1];</div>
<div class="line"><span class="lineno"> 5685</span>        }</div>
<div class="line"><span class="lineno"> 5686</span>        </div>
<div class="line"><span class="lineno"> 5687</span>        <span class="comment">// Iterate over the chunk</span></div>
<div class="line"><span class="lineno"> 5688</span>        <span class="keywordtype">size_t</span> chunk_total = <a class="code hl_function" href="#a64dfa8c2475ed50ae00ef1d4e1c12fd2">chunk</a>.total_size();</div>
<div class="line"><span class="lineno"> 5689</span>        <span class="keyword">const</span> T* src_data = tensor.<a class="code hl_function" href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4">data</a>();</div>
<div class="line"><span class="lineno"> 5690</span>        T* dst_data = <a class="code hl_function" href="#a64dfa8c2475ed50ae00ef1d4e1c12fd2">chunk</a>.data();</div>
<div class="line"><span class="lineno"> 5691</span>        </div>
<div class="line"><span class="lineno"> 5692</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; chunk_total; ++i) {</div>
<div class="line"><span class="lineno"> 5693</span>            <span class="comment">// Convert flat index to coordinates in chunk</span></div>
<div class="line"><span class="lineno"> 5694</span>            std::array&lt;size_t, N&gt; coords;</div>
<div class="line"><span class="lineno"> 5695</span>            <span class="keywordtype">size_t</span> remaining = i;</div>
<div class="line"><span class="lineno"> 5696</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> d = 0; d &lt; N; ++d) {</div>
<div class="line"><span class="lineno"> 5697</span>                coords[d] = remaining / chunk_strides[d];</div>
<div class="line"><span class="lineno"> 5698</span>                remaining %= chunk_strides[d];</div>
<div class="line"><span class="lineno"> 5699</span>            }</div>
<div class="line"><span class="lineno"> 5700</span>            </div>
<div class="line"><span class="lineno"> 5701</span>            <span class="comment">// Adjust coordinate on split axis</span></div>
<div class="line"><span class="lineno"> 5702</span>            coords[axis] += start;</div>
<div class="line"><span class="lineno"> 5703</span>            </div>
<div class="line"><span class="lineno"> 5704</span>            <span class="comment">// Convert to flat index in source</span></div>
<div class="line"><span class="lineno"> 5705</span>            <span class="keywordtype">size_t</span> src_idx = 0;</div>
<div class="line"><span class="lineno"> 5706</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> d = 0; d &lt; N; ++d) {</div>
<div class="line"><span class="lineno"> 5707</span>                src_idx += coords[d] * strides[d];</div>
<div class="line"><span class="lineno"> 5708</span>            }</div>
<div class="line"><span class="lineno"> 5709</span>            </div>
<div class="line"><span class="lineno"> 5710</span>            dst_data[i] = src_data[src_idx];</div>
<div class="line"><span class="lineno"> 5711</span>        }</div>
<div class="line"><span class="lineno"> 5712</span>        </div>
<div class="line"><span class="lineno"> 5713</span>        chunks.push_back(std::move(<a class="code hl_function" href="#a64dfa8c2475ed50ae00ef1d4e1c12fd2">chunk</a>));</div>
<div class="line"><span class="lineno"> 5714</span>        start += chunk_size;</div>
<div class="line"><span class="lineno"> 5715</span>    }</div>
<div class="line"><span class="lineno"> 5716</span>    </div>
<div class="line"><span class="lineno"> 5717</span>    <span class="keywordflow">return</span> chunks;</div>
<div class="line"><span class="lineno"> 5718</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a139335a446015c5f7ad70fa3d2ccfbec_cgraph.png" border="0" usemap="#atensor_8h_a139335a446015c5f7ad70fa3d2ccfbec_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a139335a446015c5f7ad70fa3d2ccfbec_cgraph" id="atensor_8h_a139335a446015c5f7ad70fa3d2ccfbec_cgraph">
<area shape="rect" title="Split tensor into chunks along specified axis." alt="" coords="5,80,51,107"/>
<area shape="rect" href="tensor_8h.html#a64dfa8c2475ed50ae00ef1d4e1c12fd2" title="Divide tensor into equal&#45;sized chunks (last chunk may be smaller)." alt="" coords="99,55,155,82"/>
<area shape="poly" title=" " alt="" coords="50,85,83,77,84,82,52,91"/>
<area shape="rect" href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4" title=" " alt="" coords="218,6,312,32"/>
<area shape="poly" title=" " alt="" coords="35,78,59,46,77,29,98,17,123,8,151,4,203,5,203,10,151,9,125,13,100,21,80,33,63,49,39,82"/>
<area shape="rect" href="classTensor.html#a03d314303958ffc5644796d8025cd012" title=" " alt="" coords="217,80,313,107"/>
<area shape="poly" title=" " alt="" coords="51,91,202,91,202,96,51,96"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="203,143,327,170"/>
<area shape="poly" title=" " alt="" coords="52,97,198,136,196,141,50,102"/>
<area shape="poly" title=" " alt="" coords="109,55,106,46,108,37,115,31,127,28,139,31,146,37,142,41,137,36,127,34,117,35,112,40,111,46,114,54"/>
<area shape="poly" title=" " alt="" coords="155,56,211,36,212,41,157,61"/>
<area shape="poly" title=" " alt="" coords="156,71,202,80,201,85,155,76"/>
<area shape="poly" title=" " alt="" coords="149,80,204,117,229,132,226,137,202,121,146,84"/>
</map>
</div>

</div>
</div>
<a id="a90d629271a42d730c36b7be1f66deae8" name="a90d629271a42d730c36b7be1f66deae8"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a90d629271a42d730c36b7be1f66deae8">&#9670;&#160;</a></span>tail()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; tail </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>vec</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>n</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Extract last n elements from a 1D tensor. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>Data type </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">vec</td><td>1D tensor </td></tr>
    <tr><td class="paramname">n</td><td>Number of elements to extract </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>1D tensor containing last n elements</dd></dl>
<div class="fragment"><div class="line"><a class="code hl_class" href="classTensor.html">Tensor&lt;float, 1&gt;</a> vec({10});</div>
<div class="line"><span class="keyword">auto</span> last5 = vec.<a class="code hl_function" href="classTensor.html#a44953b617ae85b4e9cc7906454bee59d">tail</a>(5);</div>
<div class="ttc" id="aclassTensor_html_a44953b617ae85b4e9cc7906454bee59d"><div class="ttname"><a href="classTensor.html#a44953b617ae85b4e9cc7906454bee59d">Tensor::tail</a></div><div class="ttdeci">Tensor&lt; T, 1 &gt; tail(size_t n) const</div><div class="ttdoc">Extract last n elements (only for 1D tensors).</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l05093">tensor.h:5093</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06832">6832</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6832</span>                                                     {</div>
<div class="line"><span class="lineno"> 6833</span>    <span class="keywordtype">size_t</span> size = vec.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>()[0];</div>
<div class="line"><span class="lineno"> 6834</span>    <span class="keywordflow">if</span> (n &gt; size) n = size;</div>
<div class="line"><span class="lineno"> 6835</span>    </div>
<div class="line"><span class="lineno"> 6836</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 1&gt;</a> result({n}, vec.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>());</div>
<div class="line"><span class="lineno"> 6837</span>    std::copy_n(vec.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>() + (size - n), n, result.data_ptr());</div>
<div class="line"><span class="lineno"> 6838</span>    </div>
<div class="line"><span class="lineno"> 6839</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6840</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a90d629271a42d730c36b7be1f66deae8_cgraph.png" border="0" usemap="#atensor_8h_a90d629271a42d730c36b7be1f66deae8_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a90d629271a42d730c36b7be1f66deae8_cgraph" id="atensor_8h_a90d629271a42d730c36b7be1f66deae8_cgraph">
<area shape="rect" title="Extract last n elements from a 1D tensor." alt="" coords="5,56,44,83"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="96,5,212,32"/>
<area shape="poly" title=" " alt="" coords="43,60,103,36,105,41,45,65"/>
<area shape="rect" href="classTensor.html#a03d314303958ffc5644796d8025cd012" title=" " alt="" coords="106,56,202,83"/>
<area shape="poly" title=" " alt="" coords="44,67,90,67,90,72,44,72"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="92,107,216,133"/>
<area shape="poly" title=" " alt="" coords="45,74,105,98,103,103,43,79"/>
</map>
</div>

</div>
</div>
<a id="ac2791cd88647d71068c02d8824a38ff2" name="ac2791cd88647d71068c02d8824a38ff2"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ac2791cd88647d71068c02d8824a38ff2">&#9670;&#160;</a></span>tile()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T, size_t N&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; tile </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">const std::array&lt; size_t, N &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>repeats</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Repeat tensor multiple times along each dimension. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>Input tensor to tile. </td></tr>
    <tr><td class="paramname">repeats</td><td>Number of repetitions for each dimension. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Tiled tensor with expanded dimensions. </dd></dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">repeats</td><td>Array specifying number of repetitions for each dimension. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Tiled tensor. </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l05808">5808</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 5808</span>                                                                                  {</div>
<div class="line"><span class="lineno"> 5809</span>    <span class="keyword">auto</span> tensor_dims = tensor.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>();</div>
<div class="line"><span class="lineno"> 5810</span>    std::array&lt;size_t, N&gt; new_dims;</div>
<div class="line"><span class="lineno"> 5811</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; N; ++i) {</div>
<div class="line"><span class="lineno"> 5812</span>        new_dims[i] = tensor_dims[i] * repeats[i];</div>
<div class="line"><span class="lineno"> 5813</span>    }</div>
<div class="line"><span class="lineno"> 5814</span>    </div>
<div class="line"><span class="lineno"> 5815</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, N&gt;</a> result(new_dims, tensor.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>(), <span class="keyword">false</span>);</div>
<div class="line"><span class="lineno"> 5816</span>    </div>
<div class="line"><span class="lineno"> 5817</span>    <span class="keyword">const</span> T* tensor_data = tensor.<a class="code hl_function" href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4">data</a>();</div>
<div class="line"><span class="lineno"> 5818</span>    T* result_data = result.data();</div>
<div class="line"><span class="lineno"> 5819</span>    </div>
<div class="line"><span class="lineno"> 5820</span>    <span class="comment">// Compute strides for indexing</span></div>
<div class="line"><span class="lineno"> 5821</span>    std::array&lt;size_t, N&gt; tensor_strides;</div>
<div class="line"><span class="lineno"> 5822</span>    std::array&lt;size_t, N&gt; result_strides;</div>
<div class="line"><span class="lineno"> 5823</span>    tensor_strides[N-1] = 1;</div>
<div class="line"><span class="lineno"> 5824</span>    result_strides[N-1] = 1;</div>
<div class="line"><span class="lineno"> 5825</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = N-1; i-- &gt; 0;) {</div>
<div class="line"><span class="lineno"> 5826</span>        tensor_strides[i] = tensor_strides[i+1] * tensor_dims[i+1];</div>
<div class="line"><span class="lineno"> 5827</span>        result_strides[i] = result_strides[i+1] * new_dims[i+1];</div>
<div class="line"><span class="lineno"> 5828</span>    }</div>
<div class="line"><span class="lineno"> 5829</span>    </div>
<div class="line"><span class="lineno"> 5830</span>    <span class="comment">// Fill result with tiled values</span></div>
<div class="line"><span class="lineno"> 5831</span>    <span class="keywordtype">size_t</span> result_total = result.total_size();</div>
<div class="line"><span class="lineno"> 5832</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> idx = 0; idx &lt; result_total; ++idx) {</div>
<div class="line"><span class="lineno"> 5833</span>        <span class="comment">// Convert flat index to coordinates</span></div>
<div class="line"><span class="lineno"> 5834</span>        std::array&lt;size_t, N&gt; coords;</div>
<div class="line"><span class="lineno"> 5835</span>        <span class="keywordtype">size_t</span> remaining = idx;</div>
<div class="line"><span class="lineno"> 5836</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; N; ++i) {</div>
<div class="line"><span class="lineno"> 5837</span>            coords[i] = remaining / result_strides[i];</div>
<div class="line"><span class="lineno"> 5838</span>            remaining %= result_strides[i];</div>
<div class="line"><span class="lineno"> 5839</span>        }</div>
<div class="line"><span class="lineno"> 5840</span>        </div>
<div class="line"><span class="lineno"> 5841</span>        <span class="comment">// Map to source coordinates</span></div>
<div class="line"><span class="lineno"> 5842</span>        std::array&lt;size_t, N&gt; src_coords;</div>
<div class="line"><span class="lineno"> 5843</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; N; ++i) {</div>
<div class="line"><span class="lineno"> 5844</span>            src_coords[i] = coords[i] % tensor_dims[i];</div>
<div class="line"><span class="lineno"> 5845</span>        }</div>
<div class="line"><span class="lineno"> 5846</span>        </div>
<div class="line"><span class="lineno"> 5847</span>        <span class="comment">// Convert source coordinates to flat index</span></div>
<div class="line"><span class="lineno"> 5848</span>        <span class="keywordtype">size_t</span> src_idx = 0;</div>
<div class="line"><span class="lineno"> 5849</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; N; ++i) {</div>
<div class="line"><span class="lineno"> 5850</span>            src_idx += src_coords[i] * tensor_strides[i];</div>
<div class="line"><span class="lineno"> 5851</span>        }</div>
<div class="line"><span class="lineno"> 5852</span>        </div>
<div class="line"><span class="lineno"> 5853</span>        result_data[idx] = tensor_data[src_idx];</div>
<div class="line"><span class="lineno"> 5854</span>    }</div>
<div class="line"><span class="lineno"> 5855</span>    </div>
<div class="line"><span class="lineno"> 5856</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 5857</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_ac2791cd88647d71068c02d8824a38ff2_cgraph.png" border="0" usemap="#atensor_8h_ac2791cd88647d71068c02d8824a38ff2_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_ac2791cd88647d71068c02d8824a38ff2_cgraph" id="atensor_8h_ac2791cd88647d71068c02d8824a38ff2_cgraph">
<area shape="rect" title="Repeat tensor multiple times along each dimension." alt="" coords="5,81,44,108"/>
<area shape="rect" href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4" title=" " alt="" coords="107,5,201,32"/>
<area shape="poly" title=" " alt="" coords="40,79,90,42,100,36,103,41,93,46,43,83"/>
<area shape="rect" href="classTensor.html#a03d314303958ffc5644796d8025cd012" title=" " alt="" coords="106,56,202,83"/>
<area shape="poly" title=" " alt="" coords="43,88,90,79,91,84,45,94"/>
<area shape="rect" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7" title=" " alt="" coords="92,107,216,133"/>
<area shape="poly" title=" " alt="" coords="45,96,77,102,76,107,43,101"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="92,157,216,184"/>
<area shape="poly" title=" " alt="" coords="43,106,93,143,103,148,100,153,90,148,40,111"/>
</map>
</div>

</div>
</div>
<a id="a8003198c60408cf62b8a805020f1a749" name="a8003198c60408cf62b8a805020f1a749"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a8003198c60408cf62b8a805020f1a749">&#9670;&#160;</a></span>to_string()</h2>

<div class="memitem">
<div class="memproto">
<table class="mlabels">
  <tr>
  <td class="mlabels-left">
      <table class="memname">
        <tr>
          <td class="memname">std::string to_string </td>
          <td>(</td>
          <td class="paramtype"><a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaa">TensorError</a></td>          <td class="paramname"><span class="paramname"><em>error</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
  </td>
  <td class="mlabels-right">
<span class="mlabels"><span class="mlabel inline">inline</span></span>  </td>
  </tr>
</table>
</div><div class="memdoc">

<p>Convert <a class="el" href="#a2db6a67f5b95f95cb23a9d7b28deceaa" title="Error codes for tensor operations.">TensorError</a> to human-readable string. </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">error</td><td>The error code to convert </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A string description of the error </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l00257">257</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno">  257</span>                                              {</div>
<div class="line"><span class="lineno">  258</span>    <span class="keywordflow">switch</span> (error) {</div>
<div class="line"><span class="lineno">  259</span>        <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa2664c241558d7674e8ed4d5f63d2e463">TensorError::DimensionMismatch</a>:</div>
<div class="line"><span class="lineno">  260</span>            <span class="keywordflow">return</span> <span class="stringliteral">&quot;Tensor dimensions must match&quot;</span>;</div>
<div class="line"><span class="lineno">  261</span>        <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaabb290efc01a42c7ed881f46a0477eca6">TensorError::ContractionMismatch</a>:</div>
<div class="line"><span class="lineno">  262</span>            <span class="keywordflow">return</span> <span class="stringliteral">&quot;Contraction dimension must match&quot;</span>;</div>
<div class="line"><span class="lineno">  263</span>        <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa253ca7dd096ee0956cccee4d376cab8b">TensorError::InvalidArgument</a>:</div>
<div class="line"><span class="lineno">  264</span>            <span class="keywordflow">return</span> <span class="stringliteral">&quot;Invalid argument provided&quot;</span>;</div>
<div class="line"><span class="lineno">  265</span>        <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaade2e45aece7bcbb9fe7540cc9e11c40f">TensorError::SingularMatrix</a>:</div>
<div class="line"><span class="lineno">  266</span>            <span class="keywordflow">return</span> <span class="stringliteral">&quot;Matrix is singular (non-invertible)&quot;</span>;</div>
<div class="line"><span class="lineno">  267</span>        <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa5a386c59a2af4745f1107846201959ed">TensorError::NotPositiveDefinite</a>:</div>
<div class="line"><span class="lineno">  268</span>            <span class="keywordflow">return</span> <span class="stringliteral">&quot;Matrix is not positive definite&quot;</span>;</div>
<div class="line"><span class="lineno">  269</span>        <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa69d8864d8802ee76419e96eaa669295a">TensorError::NotSquare</a>:</div>
<div class="line"><span class="lineno">  270</span>            <span class="keywordflow">return</span> <span class="stringliteral">&quot;Operation requires square matrix&quot;</span>;</div>
<div class="line"><span class="lineno">  271</span>        <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa953002ae82f05e5c52b3e676992dacc6">TensorError::EmptyMatrix</a>:</div>
<div class="line"><span class="lineno">  272</span>            <span class="keywordflow">return</span> <span class="stringliteral">&quot;Matrix is empty&quot;</span>;</div>
<div class="line"><span class="lineno">  273</span>        <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaaa1df5a085496d7c89611f837bf1d52ef">TensorError::LapackError</a>:</div>
<div class="line"><span class="lineno">  274</span>            <span class="keywordflow">return</span> <span class="stringliteral">&quot;LAPACK routine error&quot;</span>;</div>
<div class="line"><span class="lineno">  275</span>        <span class="keywordflow">case</span> <a class="code hl_enumvalue" href="#a2db6a67f5b95f95cb23a9d7b28deceaaa997ca4ce119685f40f03a9a8a6c5346e">TensorError::NotImplemented</a>:</div>
<div class="line"><span class="lineno">  276</span>            <span class="keywordflow">return</span> <span class="stringliteral">&quot;Feature not yet implemented&quot;</span>;</div>
<div class="line"><span class="lineno">  277</span>        <span class="keywordflow">default</span>:</div>
<div class="line"><span class="lineno">  278</span>            <span class="keywordflow">return</span> <span class="stringliteral">&quot;Unknown error&quot;</span>;</div>
<div class="line"><span class="lineno">  279</span>    }</div>
<div class="line"><span class="lineno">  280</span>}</div>
</div><!-- fragment -->
</div>
</div>
<a id="a952343525fb5d9376af0645793e8f1d4" name="a952343525fb5d9376af0645793e8f1d4"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a952343525fb5d9376af0645793e8f1d4">&#9670;&#160;</a></span>topk()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname">std::pair&lt; <a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt;, <a class="el" href="classTensor.html">Tensor</a>&lt; size_t, 1 &gt; &gt; topk </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>k</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>largest</em></span><span class="paramdefsep"> = </span><span class="paramdefval">true</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Find k largest or smallest elements and their indices (1D only). </p>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">tensor</td><td>Input tensor to find top k elements. </td></tr>
    <tr><td class="paramname">k</td><td>Number of elements to return. </td></tr>
    <tr><td class="paramname">largest</td><td>If true, return k largest; otherwise k smallest. </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>Pair of tensors: (values, indices). </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l05559">5559</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 5559</span>                                                                                                         {</div>
<div class="line"><span class="lineno"> 5560</span>    <span class="keywordtype">size_t</span> n = tensor.<a class="code hl_function" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7">total_size</a>();</div>
<div class="line"><span class="lineno"> 5561</span>    <span class="keywordflow">if</span> (k &gt; n) k = n;</div>
<div class="line"><span class="lineno"> 5562</span>    </div>
<div class="line"><span class="lineno"> 5563</span>    <span class="keyword">auto</span> sorted_indices = <a class="code hl_function" href="#a1ce61bbd53890adec19f5b19f946ef26">argsort</a>(tensor, !largest);  <span class="comment">// Sort opposite of what we want</span></div>
<div class="line"><span class="lineno"> 5564</span>    </div>
<div class="line"><span class="lineno"> 5565</span>    <span class="comment">// Take first k elements</span></div>
<div class="line"><span class="lineno"> 5566</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 1&gt;</a> values({k}, <span class="keyword">false</span>, <span class="keyword">false</span>);</div>
<div class="line"><span class="lineno"> 5567</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;size_t, 1&gt;</a> indices({k}, <span class="keyword">false</span>, <span class="keyword">false</span>);</div>
<div class="line"><span class="lineno"> 5568</span>    </div>
<div class="line"><span class="lineno"> 5569</span>    <span class="keyword">const</span> T* tensor_data = tensor.<a class="code hl_function" href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4">data</a>();</div>
<div class="line"><span class="lineno"> 5570</span>    <span class="keyword">const</span> <span class="keywordtype">size_t</span>* sorted_data = sorted_indices.data();</div>
<div class="line"><span class="lineno"> 5571</span>    T* values_data = values.data();</div>
<div class="line"><span class="lineno"> 5572</span>    <span class="keywordtype">size_t</span>* indices_data = indices.data();</div>
<div class="line"><span class="lineno"> 5573</span>    </div>
<div class="line"><span class="lineno"> 5574</span>    <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; k; ++i) {</div>
<div class="line"><span class="lineno"> 5575</span>        <span class="keywordtype">size_t</span> idx = sorted_data[i];</div>
<div class="line"><span class="lineno"> 5576</span>        values_data[i] = tensor_data[idx];</div>
<div class="line"><span class="lineno"> 5577</span>        indices_data[i] = idx;</div>
<div class="line"><span class="lineno"> 5578</span>    }</div>
<div class="line"><span class="lineno"> 5579</span>    </div>
<div class="line"><span class="lineno"> 5580</span>    <span class="keywordflow">return</span> {values, indices};</div>
<div class="line"><span class="lineno"> 5581</span>}</div>
<div class="ttc" id="atensor_8h_html_a1ce61bbd53890adec19f5b19f946ef26"><div class="ttname"><a href="#a1ce61bbd53890adec19f5b19f946ef26">argsort</a></div><div class="ttdeci">Tensor&lt; size_t, 1 &gt; argsort(const Tensor&lt; T, 1 &gt; &amp;tensor, bool ascending=true)</div><div class="ttdoc">Return indices that would sort the tensor (1D only).</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l05523">tensor.h:5523</a></div></div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a952343525fb5d9376af0645793e8f1d4_cgraph.png" border="0" usemap="#atensor_8h_a952343525fb5d9376af0645793e8f1d4_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a952343525fb5d9376af0645793e8f1d4_cgraph" id="atensor_8h_a952343525fb5d9376af0645793e8f1d4_cgraph">
<area shape="rect" title="Find k largest or smallest elements and their indices (1D only)." alt="" coords="5,31,52,57"/>
<area shape="rect" href="tensor_8h.html#a1ce61bbd53890adec19f5b19f946ef26" title="Return indices that would sort the tensor (1D only)." alt="" coords="100,31,161,57"/>
<area shape="poly" title=" " alt="" coords="52,41,84,41,84,47,52,47"/>
<area shape="rect" href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4" title=" " alt="" coords="224,5,318,32"/>
<area shape="poly" title=" " alt="" coords="51,31,99,16,155,11,209,11,209,16,155,16,100,21,53,36"/>
<area shape="rect" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7" title=" " alt="" coords="209,68,333,95"/>
<area shape="poly" title=" " alt="" coords="53,51,100,67,147,74,194,78,193,83,147,79,99,72,51,56"/>
<area shape="poly" title=" " alt="" coords="161,36,209,27,210,32,162,41"/>
<area shape="poly" title=" " alt="" coords="162,50,204,61,203,66,161,55"/>
</map>
</div>

</div>
</div>
<a id="a1cb2cae503ca515b1780c72fd05b21db" name="a1cb2cae503ca515b1780c72fd05b21db"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a1cb2cae503ca515b1780c72fd05b21db">&#9670;&#160;</a></span>topRows()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; topRows </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 2 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>matrix</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">size_t</td>          <td class="paramname"><span class="paramname"><em>n</em></span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Extract top n rows from a 2D tensor. </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>Data type </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">matrix</td><td>2D tensor </td></tr>
    <tr><td class="paramname">n</td><td>Number of rows to extract </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>2D tensor containing top n rows</dd></dl>
<div class="fragment"><div class="line"><a class="code hl_class" href="classTensor.html">Tensor&lt;float, 2&gt;</a> mat({10, 5});</div>
<div class="line"><span class="keyword">auto</span> top3 = mat.<a class="code hl_function" href="classTensor.html#af09f3224c551629f43c48c18a1fe87ee">topRows</a>(3);</div>
<div class="ttc" id="aclassTensor_html_af09f3224c551629f43c48c18a1fe87ee"><div class="ttname"><a href="classTensor.html#af09f3224c551629f43c48c18a1fe87ee">Tensor::topRows</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; topRows(size_t n) const</div><div class="ttdoc">Extract top n rows (only for 2D tensors).</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l05103">tensor.h:5103</a></div></div>
</div><!-- fragment --> 
<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06855">6855</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6855</span>                                                           {</div>
<div class="line"><span class="lineno"> 6856</span>    <span class="keyword">auto</span> dims = matrix.<a class="code hl_function" href="classTensor.html#a03d314303958ffc5644796d8025cd012">dims</a>();</div>
<div class="line"><span class="lineno"> 6857</span>    <span class="keywordtype">size_t</span> rows = dims[0];</div>
<div class="line"><span class="lineno"> 6858</span>    <span class="keywordtype">size_t</span> cols = dims[1];</div>
<div class="line"><span class="lineno"> 6859</span>    <span class="keywordflow">if</span> (n &gt; rows) n = rows;</div>
<div class="line"><span class="lineno"> 6860</span>    </div>
<div class="line"><span class="lineno"> 6861</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> result({n, cols}, matrix.<a class="code hl_function" href="classTensor.html#a83ae42925e21d2871d755407d7505c10">uses_gpu</a>());</div>
<div class="line"><span class="lineno"> 6862</span>    std::copy_n(matrix.<a class="code hl_function" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a">data_ptr</a>(), n * cols, result.data_ptr());</div>
<div class="line"><span class="lineno"> 6863</span>    </div>
<div class="line"><span class="lineno"> 6864</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6865</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a1cb2cae503ca515b1780c72fd05b21db_cgraph.png" border="0" usemap="#atensor_8h_a1cb2cae503ca515b1780c72fd05b21db_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a1cb2cae503ca515b1780c72fd05b21db_cgraph" id="atensor_8h_a1cb2cae503ca515b1780c72fd05b21db_cgraph">
<area shape="rect" title="Extract top n rows from a 2D tensor." alt="" coords="5,56,79,83"/>
<area shape="rect" href="classTensor.html#a3f3c97d177cb960a4423afc3dafc612a" title=" " alt="" coords="131,5,246,32"/>
<area shape="poly" title=" " alt="" coords="78,54,133,35,134,40,80,59"/>
<area shape="rect" href="classTensor.html#a03d314303958ffc5644796d8025cd012" title=" " alt="" coords="141,56,237,83"/>
<area shape="poly" title=" " alt="" coords="79,67,125,67,125,72,79,72"/>
<area shape="rect" href="classTensor.html#a83ae42925e21d2871d755407d7505c10" title=" " alt="" coords="127,107,251,133"/>
<area shape="poly" title=" " alt="" coords="80,79,134,99,133,104,78,84"/>
</map>
</div>

</div>
</div>
<a id="ad136045cd6f420421ea5618b726778f3" name="ad136045cd6f420421ea5618b726778f3"></a>
<h2 class="memtitle"><span class="permalink"><a href="#ad136045cd6f420421ea5618b726778f3">&#9670;&#160;</a></span>unique()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; unique </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="classTensor.html">Tensor</a>&lt; T, 1 &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>tensor</em></span></td><td>)</td>
          <td></td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Find unique elements in tensor (1D only). </p>
<dl class="section return"><dt>Returns</dt><dd><a class="el" href="classTensor.html" title="Forward declaration for autograd.">Tensor</a> containing unique elements in sorted order. </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l05588">5588</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 5588</span>                                                {</div>
<div class="line"><span class="lineno"> 5589</span>    <span class="keywordtype">size_t</span> n = tensor.<a class="code hl_function" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7">total_size</a>();</div>
<div class="line"><span class="lineno"> 5590</span>    <span class="keyword">const</span> T* data = tensor.<a class="code hl_function" href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4">data</a>();</div>
<div class="line"><span class="lineno"> 5591</span>    std::vector&lt;T&gt; vec(data, data + n);</div>
<div class="line"><span class="lineno"> 5592</span>    </div>
<div class="line"><span class="lineno"> 5593</span>    std::sort(vec.begin(), vec.end());</div>
<div class="line"><span class="lineno"> 5594</span>    <span class="keyword">auto</span> last = std::unique(vec.begin(), vec.end());</div>
<div class="line"><span class="lineno"> 5595</span>    vec.erase(last, vec.end());</div>
<div class="line"><span class="lineno"> 5596</span>    </div>
<div class="line"><span class="lineno"> 5597</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 1&gt;</a> result({vec.size()}, <span class="keyword">false</span>, <span class="keyword">false</span>);</div>
<div class="line"><span class="lineno"> 5598</span>    std::copy(vec.begin(), vec.end(), result.data());</div>
<div class="line"><span class="lineno"> 5599</span>    </div>
<div class="line"><span class="lineno"> 5600</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 5601</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_ad136045cd6f420421ea5618b726778f3_cgraph.png" border="0" usemap="#atensor_8h_ad136045cd6f420421ea5618b726778f3_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_ad136045cd6f420421ea5618b726778f3_cgraph" id="atensor_8h_ad136045cd6f420421ea5618b726778f3_cgraph">
<area shape="rect" title="Find unique elements in tensor (1D only)." alt="" coords="5,31,65,57"/>
<area shape="rect" href="classTensor.html#a07bf856a863505d2960b0bfad9c3b3f4" title=" " alt="" coords="128,5,222,32"/>
<area shape="poly" title=" " alt="" coords="64,36,112,27,113,33,65,41"/>
<area shape="rect" href="classTensor.html#aad6aeb4859940befd0c46f0b99388bd7" title=" " alt="" coords="113,56,237,83"/>
<area shape="poly" title=" " alt="" coords="65,47,98,53,97,58,64,52"/>
</map>
</div>

</div>
</div>
<a id="a249e6ed21f6e3540a11b62433237175a" name="a249e6ed21f6e3540a11b62433237175a"></a>
<h2 class="memtitle"><span class="permalink"><a href="#a249e6ed21f6e3540a11b62433237175a">&#9670;&#160;</a></span>zeros()</h2>

<div class="memitem">
<div class="memproto">
<div class="memtemplate">
template&lt;typename T, size_t N&gt; </div>
      <table class="memname">
        <tr>
          <td class="memname"><a class="el" href="classTensor.html">Tensor</a>&lt; T, N &gt; zeros </td>
          <td>(</td>
          <td class="paramtype">const <a class="el" href="#ab58b5b2b06188fb918bfa78bdfce068b">TensorIndices</a>&lt; N &gt; &amp;</td>          <td class="paramname"><span class="paramname"><em>shape</em></span>, </td>
        </tr>
        <tr>
          <td class="paramkey"></td>
          <td></td>
          <td class="paramtype">bool</td>          <td class="paramname"><span class="paramname"><em>use_gpu</em></span><span class="paramdefsep"> = </span><span class="paramdefval">true</span>&#160;)</td>
        </tr>
      </table>
</div><div class="memdoc">

<p>Create a tensor filled with zeros (NumPy-compatible). </p>
<dl class="tparams"><dt>Template Parameters</dt><dd>
  <table class="tparams">
    <tr><td class="paramname">T</td><td>The data type </td></tr>
    <tr><td class="paramname">N</td><td>The number of dimensions </td></tr>
  </table>
  </dd>
</dl>
<dl class="params"><dt>Parameters</dt><dd>
  <table class="params">
    <tr><td class="paramname">shape</td><td>The shape of the tensor </td></tr>
    <tr><td class="paramname">use_gpu</td><td>Whether to use GPU </td></tr>
  </table>
  </dd>
</dl>
<dl class="section return"><dt>Returns</dt><dd>A new tensor filled with zeros </dd></dl>

<p class="definition">Definition at line <a class="el" href="tensor_8h_source.html#l06138">6138</a> of file <a class="el" href="tensor_8h_source.html">tensor.h</a>.</p>
<div class="fragment"><div class="line"><span class="lineno"> 6138</span>                                                                       {</div>
<div class="line"><span class="lineno"> 6139</span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, N&gt;</a> result(shape, use_gpu);</div>
<div class="line"><span class="lineno"> 6140</span>    result.fill(T(0));</div>
<div class="line"><span class="lineno"> 6141</span>    <span class="keywordflow">return</span> result;</div>
<div class="line"><span class="lineno"> 6142</span>}</div>
</div><!-- fragment --><div class="dynheader">
Here is the call graph for this function:</div>
<div class="dyncontent">
<div class="center"><img src="tensor_8h_a249e6ed21f6e3540a11b62433237175a_cgraph.png" border="0" usemap="#atensor_8h_a249e6ed21f6e3540a11b62433237175a_cgraph" loading="lazy" alt=""/></div>
<map name="atensor_8h_a249e6ed21f6e3540a11b62433237175a_cgraph" id="atensor_8h_a249e6ed21f6e3540a11b62433237175a_cgraph">
<area shape="rect" title="Create a tensor filled with zeros (NumPy&#45;compatible)." alt="" coords="5,5,59,32"/>
<area shape="rect" href="classTensor.html#a234f74cd16bd13561f7963ba29efb163" title="Fill the tensor with a specified value." alt="" coords="107,5,188,32"/>
<area shape="poly" title=" " alt="" coords="59,16,91,16,91,21,59,21"/>
</map>
</div>

</div>
</div>
</div><!-- contents -->
</div><!-- doc-content -->
<div id="page-nav" class="page-nav-panel">
<div id="page-nav-resize-handle"></div>
<div id="page-nav-tree">
<div id="page-nav-contents">
</div><!-- page-nav-contents -->
</div><!-- page-nav-tree -->
</div><!-- page-nav -->
</div><!-- container -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a href="tensor_8h.html">tensor.h</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.15.0 </li>
  </ul>
</div>
</body>
</html>
