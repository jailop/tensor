<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "https://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en-US">
<head>
<meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=11"/>
<meta name="generator" content="Doxygen 1.15.0"/>
<meta name="viewport" content="width=device-width, initial-scale=1"/>
<title>Tensor Library: include/nn_layers.h Source File</title>
<link href="tabs.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="jquery.js"></script>
<script type="text/javascript" src="dynsections.js"></script>
<script type="text/javascript" src="clipboard.js"></script>
<link href="navtree.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="navtreedata.js"></script>
<script type="text/javascript" src="navtree.js"></script>
<script type="text/javascript" src="cookie.js"></script>
<link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<link href="doxygen.css" rel="stylesheet" type="text/css" />
</head>
<body>
<div id="top"><!-- do not remove this div, it is closed by doxygen! -->
<div id="titlearea">
<table cellspacing="0" cellpadding="0">
 <tbody>
 <tr id="projectrow">
  <td id="projectalign">
   <div id="projectname">Tensor Library
   </div>
   <div id="projectbrief">High-performance C++ tensor library with GPU, BLAS, autograd, and linear algebra support</div>
  </td>
 </tr>
 </tbody>
</table>
</div>
<!-- end header part -->
<!-- Generated by Doxygen 1.15.0 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search/",'.html');
</script>
<script type="text/javascript">
$(function() { codefold.init(); });
</script>
<script type="text/javascript" src="menudata.js"></script>
<script type="text/javascript" src="menu.js"></script>
<script type="text/javascript">
$(function() {
  initMenu('',true,false,'search.php','Search',true);
  $(function() { init_search(); });
});
</script>
<div id="main-nav"></div>
</div><!-- top -->
<div id="side-nav" class="ui-resizable side-nav-resizable">
  <div id="nav-tree">
    <div id="nav-tree-contents">
      <div id="nav-sync" class="sync"></div>
    </div>
  </div>
  <div id="splitbar" style="-moz-user-select:none;" 
       class="ui-resizable-handle">
  </div>
</div>
<script type="text/javascript">
$(function(){initNavTree('nn__layers_8h_source.html','',''); });
</script>
<div id="container">
<div id="doc-content">
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<div id="MSearchResults">
<div class="SRPage">
<div id="SRIndex">
<div id="SRResults"></div>
<div class="SRStatus" id="Loading">Loading...</div>
<div class="SRStatus" id="Searching">Searching...</div>
<div class="SRStatus" id="NoMatches">No Matches</div>
</div>
</div>
</div>
</div>

<div class="header">
  <div class="headertitle"><div class="title">nn_layers.h</div></div>
</div><!--header-->
<div class="contents">
<a href="nn__layers_8h.html">Go to the documentation of this file.</a><div class="fragment"><div class="line"><a id="l00001" name="l00001"></a><span class="lineno">    1</span></div>
<div class="line"><a id="l00009" name="l00009"></a><span class="lineno">    9</span> </div>
<div class="line"><a id="l00010" name="l00010"></a><span class="lineno">   10</span><span class="preprocessor">#ifndef NN_LAYERS_H</span></div>
<div class="line"><a id="l00011" name="l00011"></a><span class="lineno">   11</span><span class="preprocessor">#define NN_LAYERS_H</span></div>
<div class="line"><a id="l00012" name="l00012"></a><span class="lineno">   12</span> </div>
<div class="line"><a id="l00013" name="l00013"></a><span class="lineno">   13</span><span class="preprocessor">#include &quot;<a class="code" href="tensor_8h.html">tensor.h</a>&quot;</span></div>
<div class="line"><a id="l00014" name="l00014"></a><span class="lineno">   14</span><span class="preprocessor">#include &quot;<a class="code" href="tensor__types_8h.html">tensor_types.h</a>&quot;</span></div>
<div class="line"><a id="l00015" name="l00015"></a><span class="lineno">   15</span><span class="preprocessor">#include &lt;random&gt;</span></div>
<div class="line"><a id="l00016" name="l00016"></a><span class="lineno">   16</span><span class="preprocessor">#include &lt;cmath&gt;</span></div>
<div class="line"><a id="l00017" name="l00017"></a><span class="lineno">   17</span> </div>
<div class="foldopen" id="foldopen00018" data-start="{" data-end="}">
<div class="line"><a id="l00018" name="l00018"></a><span class="lineno"><a class="line" href="namespacetensor4d.html">   18</a></span><span class="keyword">namespace </span><a class="code hl_namespace" href="namespacetensor4d.html">tensor4d</a> {</div>
<div class="foldopen" id="foldopen00019" data-start="{" data-end="}">
<div class="line"><a id="l00019" name="l00019"></a><span class="lineno"><a class="line" href="namespacetensor4d_1_1nn.html">   19</a></span><span class="keyword">namespace </span><a class="code hl_namespace" href="namespacetensor4d_1_1nn.html">nn</a> {</div>
<div class="line"><a id="l00020" name="l00020"></a><span class="lineno">   20</span> </div>
<div class="line"><a id="l00021" name="l00021"></a><span class="lineno">   21</span><span class="comment">// Forward declarations</span></div>
<div class="line"><a id="l00022" name="l00022"></a><span class="lineno">   22</span><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</div>
<div class="line"><a id="l00023" name="l00023"></a><span class="lineno">   23</span><span class="keyword">class </span><a class="code hl_class" href="classtensor4d_1_1nn_1_1Layer.html">Layer</a>;</div>
<div class="line"><a id="l00024" name="l00024"></a><span class="lineno">   24</span></div>
<div class="line"><a id="l00028" name="l00028"></a><span class="lineno">   28</span><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00029" data-start="{" data-end="};">
<div class="line"><a id="l00029" name="l00029"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Layer.html">   29</a></span><span class="keyword">class </span><a class="code hl_class" href="classtensor4d_1_1nn_1_1Layer.html">Layer</a> {</div>
<div class="line"><a id="l00030" name="l00030"></a><span class="lineno">   30</span><span class="keyword">public</span>:</div>
<div class="line"><a id="l00031" name="l00031"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Layer.html#aabd4feffefbe1a92d584484413289a05">   31</a></span>    <span class="keyword">virtual</span> <a class="code hl_function" href="classtensor4d_1_1nn_1_1Layer.html#aabd4feffefbe1a92d584484413289a05">~Layer</a>() = <span class="keywordflow">default</span>;</div>
<div class="line"><a id="l00032" name="l00032"></a><span class="lineno">   32</span>    </div>
<div class="line"><a id="l00038" name="l00038"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Layer.html#a2d171fcf4e726e2bd0f6c9399288436b">   38</a></span>    <span class="keyword">virtual</span> <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_function" href="classtensor4d_1_1nn_1_1Layer.html#a2d171fcf4e726e2bd0f6c9399288436b">forward</a>(<span class="keyword">const</span> <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>&amp; input) = 0;</div>
<div class="line"><a id="l00039" name="l00039"></a><span class="lineno">   39</span>    </div>
<div class="line"><a id="l00045" name="l00045"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Layer.html#a3d9932a950faa4534cc8c468c9152f22">   45</a></span>    <span class="keyword">virtual</span> <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_function" href="classtensor4d_1_1nn_1_1Layer.html#a3d9932a950faa4534cc8c468c9152f22">backward</a>(<span class="keyword">const</span> <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>&amp; grad_output) = 0;</div>
<div class="line"><a id="l00046" name="l00046"></a><span class="lineno">   46</span>    </div>
<div class="line"><a id="l00051" name="l00051"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Layer.html#a5a29143edf7136c7a3d944846f23d05d">   51</a></span>    <span class="keyword">virtual</span> std::vector&lt;Tensor&lt;T, 2&gt;*&gt; <a class="code hl_function" href="classtensor4d_1_1nn_1_1Layer.html#a5a29143edf7136c7a3d944846f23d05d">parameters</a>() { <span class="keywordflow">return</span> {}; }</div>
<div class="line"><a id="l00052" name="l00052"></a><span class="lineno">   52</span>    </div>
<div class="line"><a id="l00057" name="l00057"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Layer.html#a9f069156fc18ad5035bcfa99ddfdda83">   57</a></span>    <span class="keyword">virtual</span> <span class="keywordtype">void</span> <a class="code hl_function" href="classtensor4d_1_1nn_1_1Layer.html#a9f069156fc18ad5035bcfa99ddfdda83">train</a>(<span class="keywordtype">bool</span> mode = <span class="keyword">true</span>) { <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Layer.html#a5046b1e468f41cc660af5f541be017d6">training_</a> = mode; }</div>
<div class="line"><a id="l00058" name="l00058"></a><span class="lineno">   58</span>    </div>
<div class="line"><a id="l00062" name="l00062"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Layer.html#ae5d280d927fb2b5757ae8de43af64a79">   62</a></span>    <span class="keywordtype">bool</span> <a class="code hl_function" href="classtensor4d_1_1nn_1_1Layer.html#ae5d280d927fb2b5757ae8de43af64a79">is_training</a>()<span class="keyword"> const </span>{ <span class="keywordflow">return</span> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Layer.html#a5046b1e468f41cc660af5f541be017d6">training_</a>; }</div>
<div class="line"><a id="l00063" name="l00063"></a><span class="lineno">   63</span>    </div>
<div class="line"><a id="l00064" name="l00064"></a><span class="lineno">   64</span><span class="keyword">protected</span>:</div>
<div class="line"><a id="l00065" name="l00065"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Layer.html#a5046b1e468f41cc660af5f541be017d6">   65</a></span>    <span class="keywordtype">bool</span> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Layer.html#a5046b1e468f41cc660af5f541be017d6">training_</a> = <span class="keyword">true</span>;</div>
<div class="line"><a id="l00066" name="l00066"></a><span class="lineno">   66</span>};</div>
</div>
<div class="line"><a id="l00067" name="l00067"></a><span class="lineno">   67</span></div>
<div class="line"><a id="l00073" name="l00073"></a><span class="lineno">   73</span><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00074" data-start="{" data-end="};">
<div class="line"><a id="l00074" name="l00074"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Linear.html">   74</a></span><span class="keyword">class </span><a class="code hl_function" href="classtensor4d_1_1nn_1_1Linear.html#af3a3fecbb2390303fc899b9b2285ea24">Linear</a> : <span class="keyword">public</span> <a class="code hl_class" href="classtensor4d_1_1nn_1_1Layer.html">Layer</a>&lt;T&gt; {</div>
<div class="line"><a id="l00075" name="l00075"></a><span class="lineno">   75</span><span class="keyword">public</span>:</div>
<div class="foldopen" id="foldopen00082" data-start="{" data-end="}">
<div class="line"><a id="l00082" name="l00082"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Linear.html#af3a3fecbb2390303fc899b9b2285ea24">   82</a></span>    <a class="code hl_function" href="classtensor4d_1_1nn_1_1Linear.html#af3a3fecbb2390303fc899b9b2285ea24">Linear</a>(<span class="keywordtype">size_t</span> in_features, <span class="keywordtype">size_t</span> out_features, <span class="keywordtype">bool</span> use_bias = <span class="keyword">true</span>)</div>
<div class="line"><a id="l00083" name="l00083"></a><span class="lineno">   83</span>        : <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a7e262da58b4b499b6eeab66bdd6f84c5">in_features_</a>(in_features), <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a873ae71e9bf64f75ab818dc40c32442e">out_features_</a>(out_features), <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a3f45dfd88be3f8cb6348b6dc317ebc4a">use_bias_</a>(use_bias),</div>
<div class="line"><a id="l00084" name="l00084"></a><span class="lineno">   84</span>          <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a794be1290e09a38a6daad16f19aa7126">weights_</a>({out_features, in_features}, <span class="keyword">false</span>), </div>
<div class="line"><a id="l00085" name="l00085"></a><span class="lineno">   85</span>          <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#aea284ce51288593c283f10f739ae1696">bias_</a>({1, out_features}, <span class="keyword">false</span>),</div>
<div class="line"><a id="l00086" name="l00086"></a><span class="lineno">   86</span>          <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a9af9fd6d9d5322f77ce1297c3edb82c7">input_</a>({1, in_features}, <span class="keyword">false</span>),</div>
<div class="line"><a id="l00087" name="l00087"></a><span class="lineno">   87</span>          <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a6e7fab012ef8b37597f46e3c82694df4">grad_weights_</a>({out_features, in_features}, <span class="keyword">false</span>),</div>
<div class="line"><a id="l00088" name="l00088"></a><span class="lineno">   88</span>          <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#aa24e546b58f66fc945024eb35e5d20f2">grad_bias_</a>({1, out_features}, <span class="keyword">false</span>) {</div>
<div class="line"><a id="l00089" name="l00089"></a><span class="lineno">   89</span>        </div>
<div class="line"><a id="l00090" name="l00090"></a><span class="lineno">   90</span>        <span class="comment">// Initialize weights with Xavier/Glorot initialization</span></div>
<div class="line"><a id="l00091" name="l00091"></a><span class="lineno">   91</span>        T stddev = std::sqrt(2.0 / (in_features + out_features));</div>
<div class="line"><a id="l00092" name="l00092"></a><span class="lineno">   92</span>        </div>
<div class="line"><a id="l00093" name="l00093"></a><span class="lineno">   93</span>        std::random_device rd;</div>
<div class="line"><a id="l00094" name="l00094"></a><span class="lineno">   94</span>        std::mt19937 gen(rd());</div>
<div class="line"><a id="l00095" name="l00095"></a><span class="lineno">   95</span>        std::normal_distribution&lt;T&gt; dist(0.0, stddev);</div>
<div class="line"><a id="l00096" name="l00096"></a><span class="lineno">   96</span>        </div>
<div class="line"><a id="l00097" name="l00097"></a><span class="lineno">   97</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; out_features; ++i) {</div>
<div class="line"><a id="l00098" name="l00098"></a><span class="lineno">   98</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; in_features; ++j) {</div>
<div class="line"><a id="l00099" name="l00099"></a><span class="lineno">   99</span>                <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a794be1290e09a38a6daad16f19aa7126">weights_</a>[{i, j}] = dist(gen);</div>
<div class="line"><a id="l00100" name="l00100"></a><span class="lineno">  100</span>            }</div>
<div class="line"><a id="l00101" name="l00101"></a><span class="lineno">  101</span>        }</div>
<div class="line"><a id="l00102" name="l00102"></a><span class="lineno">  102</span>        </div>
<div class="line"><a id="l00103" name="l00103"></a><span class="lineno">  103</span>        <span class="keywordflow">if</span> (<a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a3f45dfd88be3f8cb6348b6dc317ebc4a">use_bias_</a>) {</div>
<div class="line"><a id="l00104" name="l00104"></a><span class="lineno">  104</span>            <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#aea284ce51288593c283f10f739ae1696">bias_</a>.fill(0);</div>
<div class="line"><a id="l00105" name="l00105"></a><span class="lineno">  105</span>        }</div>
<div class="line"><a id="l00106" name="l00106"></a><span class="lineno">  106</span>    }</div>
</div>
<div class="line"><a id="l00107" name="l00107"></a><span class="lineno">  107</span>    </div>
<div class="foldopen" id="foldopen00108" data-start="{" data-end="}">
<div class="line"><a id="l00108" name="l00108"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Linear.html#a0af1f08655e4b88cc7adc4e7d8a323e3">  108</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_function" href="classtensor4d_1_1nn_1_1Linear.html#a0af1f08655e4b88cc7adc4e7d8a323e3">forward</a>(<span class="keyword">const</span> <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>&amp; input)<span class="keyword"> override </span>{</div>
<div class="line"><a id="l00109" name="l00109"></a><span class="lineno">  109</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a9af9fd6d9d5322f77ce1297c3edb82c7">input_</a> = input;</div>
<div class="line"><a id="l00110" name="l00110"></a><span class="lineno">  110</span>        </div>
<div class="line"><a id="l00111" name="l00111"></a><span class="lineno">  111</span>        <span class="comment">// output = input @ weights^T</span></div>
<div class="line"><a id="l00112" name="l00112"></a><span class="lineno">  112</span>        <span class="keyword">auto</span> weights_t = <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a794be1290e09a38a6daad16f19aa7126">weights_</a>.transpose();</div>
<div class="line"><a id="l00113" name="l00113"></a><span class="lineno">  113</span>        <span class="keyword">auto</span> result_var = input.<a class="code hl_function" href="classTensor.html#a88d5a081d321cbd88ca46ed42ca1112c">matmul</a>(weights_t);</div>
<div class="line"><a id="l00114" name="l00114"></a><span class="lineno">  114</span>        <span class="keyword">auto</span> output = std::get&lt;Tensor&lt;T, 2&gt;&gt;(result_var);</div>
<div class="line"><a id="l00115" name="l00115"></a><span class="lineno">  115</span>        </div>
<div class="line"><a id="l00116" name="l00116"></a><span class="lineno">  116</span>        <span class="comment">// Add bias if present (manually broadcast)</span></div>
<div class="line"><a id="l00117" name="l00117"></a><span class="lineno">  117</span>        <span class="keywordflow">if</span> (<a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a3f45dfd88be3f8cb6348b6dc317ebc4a">use_bias_</a>) {</div>
<div class="line"><a id="l00118" name="l00118"></a><span class="lineno">  118</span>            <span class="keyword">auto</span> shape = output.shape();</div>
<div class="line"><a id="l00119" name="l00119"></a><span class="lineno">  119</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; shape[0]; ++i) {</div>
<div class="line"><a id="l00120" name="l00120"></a><span class="lineno">  120</span>                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; shape[1]; ++j) {</div>
<div class="line"><a id="l00121" name="l00121"></a><span class="lineno">  121</span>                    output[{i, j}] += <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#aea284ce51288593c283f10f739ae1696">bias_</a>[{0, j}];</div>
<div class="line"><a id="l00122" name="l00122"></a><span class="lineno">  122</span>                }</div>
<div class="line"><a id="l00123" name="l00123"></a><span class="lineno">  123</span>            }</div>
<div class="line"><a id="l00124" name="l00124"></a><span class="lineno">  124</span>        }</div>
<div class="line"><a id="l00125" name="l00125"></a><span class="lineno">  125</span>        </div>
<div class="line"><a id="l00126" name="l00126"></a><span class="lineno">  126</span>        <span class="keywordflow">return</span> output;</div>
<div class="line"><a id="l00127" name="l00127"></a><span class="lineno">  127</span>    }</div>
</div>
<div class="line"><a id="l00128" name="l00128"></a><span class="lineno">  128</span>    </div>
<div class="foldopen" id="foldopen00129" data-start="{" data-end="}">
<div class="line"><a id="l00129" name="l00129"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Linear.html#a5364162aed6bb8c7758d88142ac74c1b">  129</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_function" href="classtensor4d_1_1nn_1_1Linear.html#a5364162aed6bb8c7758d88142ac74c1b">backward</a>(<span class="keyword">const</span> <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>&amp; grad_output)<span class="keyword"> override </span>{</div>
<div class="line"><a id="l00130" name="l00130"></a><span class="lineno">  130</span>        <span class="comment">// Gradient w.r.t. weights: grad_output^T @ input</span></div>
<div class="line"><a id="l00131" name="l00131"></a><span class="lineno">  131</span>        <span class="keyword">auto</span> grad_output_t = grad_output.<a class="code hl_function" href="classTensor.html#aed9419fabd015e2c1c35ff6723c1600a">transpose</a>();</div>
<div class="line"><a id="l00132" name="l00132"></a><span class="lineno">  132</span>        <span class="keyword">auto</span> grad_weights_var = grad_output_t.matmul(<a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a9af9fd6d9d5322f77ce1297c3edb82c7">input_</a>);</div>
<div class="line"><a id="l00133" name="l00133"></a><span class="lineno">  133</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a6e7fab012ef8b37597f46e3c82694df4">grad_weights_</a> = std::get&lt;Tensor&lt;T, 2&gt;&gt;(grad_weights_var);</div>
<div class="line"><a id="l00134" name="l00134"></a><span class="lineno">  134</span>        </div>
<div class="line"><a id="l00135" name="l00135"></a><span class="lineno">  135</span>        <span class="comment">// Gradient w.r.t. bias: sum over batch dimension</span></div>
<div class="line"><a id="l00136" name="l00136"></a><span class="lineno">  136</span>        <span class="keywordflow">if</span> (<a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a3f45dfd88be3f8cb6348b6dc317ebc4a">use_bias_</a>) {</div>
<div class="line"><a id="l00137" name="l00137"></a><span class="lineno">  137</span>            <span class="keyword">auto</span> batch_size = grad_output.<a class="code hl_function" href="classTensor.html#a80b3ffaf92ed36f02d6f4d4230b5d2a0">shape</a>()[0];</div>
<div class="line"><a id="l00138" name="l00138"></a><span class="lineno">  138</span>            <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#aa24e546b58f66fc945024eb35e5d20f2">grad_bias_</a> = <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>({1, <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a873ae71e9bf64f75ab818dc40c32442e">out_features_</a>});</div>
<div class="line"><a id="l00139" name="l00139"></a><span class="lineno">  139</span>            <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#aa24e546b58f66fc945024eb35e5d20f2">grad_bias_</a>.fill(0);</div>
<div class="line"><a id="l00140" name="l00140"></a><span class="lineno">  140</span>            </div>
<div class="line"><a id="l00141" name="l00141"></a><span class="lineno">  141</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> b = 0; b &lt; batch_size; ++b) {</div>
<div class="line"><a id="l00142" name="l00142"></a><span class="lineno">  142</span>                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a873ae71e9bf64f75ab818dc40c32442e">out_features_</a>; ++i) {</div>
<div class="line"><a id="l00143" name="l00143"></a><span class="lineno">  143</span>                    <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#aa24e546b58f66fc945024eb35e5d20f2">grad_bias_</a>[{0, i}] += grad_output[{b, i}];</div>
<div class="line"><a id="l00144" name="l00144"></a><span class="lineno">  144</span>                }</div>
<div class="line"><a id="l00145" name="l00145"></a><span class="lineno">  145</span>            }</div>
<div class="line"><a id="l00146" name="l00146"></a><span class="lineno">  146</span>        }</div>
<div class="line"><a id="l00147" name="l00147"></a><span class="lineno">  147</span>        </div>
<div class="line"><a id="l00148" name="l00148"></a><span class="lineno">  148</span>        <span class="comment">// Gradient w.r.t. input: grad_output @ weights</span></div>
<div class="line"><a id="l00149" name="l00149"></a><span class="lineno">  149</span>        <span class="keyword">auto</span> grad_input_var = grad_output.<a class="code hl_function" href="classTensor.html#a88d5a081d321cbd88ca46ed42ca1112c">matmul</a>(<a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a794be1290e09a38a6daad16f19aa7126">weights_</a>);</div>
<div class="line"><a id="l00150" name="l00150"></a><span class="lineno">  150</span>        <span class="keywordflow">return</span> std::get&lt;Tensor&lt;T, 2&gt;&gt;(grad_input_var);</div>
<div class="line"><a id="l00151" name="l00151"></a><span class="lineno">  151</span>    }</div>
</div>
<div class="line"><a id="l00152" name="l00152"></a><span class="lineno">  152</span>    </div>
<div class="foldopen" id="foldopen00153" data-start="{" data-end="}">
<div class="line"><a id="l00153" name="l00153"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Linear.html#aa0fab014d4634b17ea27cda3e120d238">  153</a></span>    std::vector&lt;Tensor&lt;T, 2&gt;*&gt; <a class="code hl_function" href="classtensor4d_1_1nn_1_1Linear.html#aa0fab014d4634b17ea27cda3e120d238">parameters</a>()<span class="keyword"> override </span>{</div>
<div class="line"><a id="l00154" name="l00154"></a><span class="lineno">  154</span>        std::vector&lt;Tensor&lt;T, 2&gt;*&gt; params;</div>
<div class="line"><a id="l00155" name="l00155"></a><span class="lineno">  155</span>        params.push_back(&amp;<a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a794be1290e09a38a6daad16f19aa7126">weights_</a>);</div>
<div class="line"><a id="l00156" name="l00156"></a><span class="lineno">  156</span>        <span class="keywordflow">if</span> (<a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a3f45dfd88be3f8cb6348b6dc317ebc4a">use_bias_</a>) {</div>
<div class="line"><a id="l00157" name="l00157"></a><span class="lineno">  157</span>            params.push_back(&amp;<a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#aea284ce51288593c283f10f739ae1696">bias_</a>);</div>
<div class="line"><a id="l00158" name="l00158"></a><span class="lineno">  158</span>        }</div>
<div class="line"><a id="l00159" name="l00159"></a><span class="lineno">  159</span>        <span class="keywordflow">return</span> params;</div>
<div class="line"><a id="l00160" name="l00160"></a><span class="lineno">  160</span>    }</div>
</div>
<div class="line"><a id="l00161" name="l00161"></a><span class="lineno">  161</span>    </div>
<div class="line"><a id="l00162" name="l00162"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Linear.html#a08cc48c658f333a45ca0ea084f69ec54">  162</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>&amp; <a class="code hl_function" href="classtensor4d_1_1nn_1_1Linear.html#a08cc48c658f333a45ca0ea084f69ec54">weights</a>() { <span class="keywordflow">return</span> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a794be1290e09a38a6daad16f19aa7126">weights_</a>; }</div>
<div class="line"><a id="l00163" name="l00163"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Linear.html#afefc9f73184487c8cb0abb37641a6932">  163</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>&amp; <a class="code hl_function" href="classtensor4d_1_1nn_1_1Linear.html#afefc9f73184487c8cb0abb37641a6932">bias</a>() { <span class="keywordflow">return</span> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#aea284ce51288593c283f10f739ae1696">bias_</a>; }</div>
<div class="line"><a id="l00164" name="l00164"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Linear.html#a0fab0d83bb52b8ed52b9d4679f5a4ead">  164</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>&amp; <a class="code hl_function" href="classtensor4d_1_1nn_1_1Linear.html#a0fab0d83bb52b8ed52b9d4679f5a4ead">grad_weights</a>() { <span class="keywordflow">return</span> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a6e7fab012ef8b37597f46e3c82694df4">grad_weights_</a>; }</div>
<div class="line"><a id="l00165" name="l00165"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Linear.html#a24f7dbc86ee05b08278886cf1e8bf357">  165</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>&amp; <a class="code hl_function" href="classtensor4d_1_1nn_1_1Linear.html#a24f7dbc86ee05b08278886cf1e8bf357">grad_bias</a>() { <span class="keywordflow">return</span> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#aa24e546b58f66fc945024eb35e5d20f2">grad_bias_</a>; }</div>
<div class="line"><a id="l00166" name="l00166"></a><span class="lineno">  166</span>    </div>
<div class="line"><a id="l00167" name="l00167"></a><span class="lineno">  167</span><span class="keyword">private</span>:</div>
<div class="line"><a id="l00168" name="l00168"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Linear.html#a7e262da58b4b499b6eeab66bdd6f84c5">  168</a></span>    <span class="keywordtype">size_t</span> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a7e262da58b4b499b6eeab66bdd6f84c5">in_features_</a>;</div>
<div class="line"><a id="l00169" name="l00169"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Linear.html#a873ae71e9bf64f75ab818dc40c32442e">  169</a></span>    <span class="keywordtype">size_t</span> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a873ae71e9bf64f75ab818dc40c32442e">out_features_</a>;</div>
<div class="line"><a id="l00170" name="l00170"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Linear.html#a3f45dfd88be3f8cb6348b6dc317ebc4a">  170</a></span>    <span class="keywordtype">bool</span> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a3f45dfd88be3f8cb6348b6dc317ebc4a">use_bias_</a>;</div>
<div class="line"><a id="l00171" name="l00171"></a><span class="lineno">  171</span>    </div>
<div class="line"><a id="l00172" name="l00172"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Linear.html#a794be1290e09a38a6daad16f19aa7126">  172</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a794be1290e09a38a6daad16f19aa7126">weights_</a>;</div>
<div class="line"><a id="l00173" name="l00173"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Linear.html#aea284ce51288593c283f10f739ae1696">  173</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#aea284ce51288593c283f10f739ae1696">bias_</a>;</div>
<div class="line"><a id="l00174" name="l00174"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Linear.html#a9af9fd6d9d5322f77ce1297c3edb82c7">  174</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a9af9fd6d9d5322f77ce1297c3edb82c7">input_</a>;</div>
<div class="line"><a id="l00175" name="l00175"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Linear.html#a6e7fab012ef8b37597f46e3c82694df4">  175</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#a6e7fab012ef8b37597f46e3c82694df4">grad_weights_</a>;</div>
<div class="line"><a id="l00176" name="l00176"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Linear.html#aa24e546b58f66fc945024eb35e5d20f2">  176</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Linear.html#aa24e546b58f66fc945024eb35e5d20f2">grad_bias_</a>;</div>
<div class="line"><a id="l00177" name="l00177"></a><span class="lineno">  177</span>};</div>
</div>
<div class="line"><a id="l00178" name="l00178"></a><span class="lineno">  178</span></div>
<div class="line"><a id="l00182" name="l00182"></a><span class="lineno">  182</span><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00183" data-start="{" data-end="};">
<div class="line"><a id="l00183" name="l00183"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1ReLU.html">  183</a></span><span class="keyword">class </span><a class="code hl_function" href="classtensor4d_1_1nn_1_1ReLU.html#aed0a602218dd422544cdf5ca46f6d056">ReLU</a> : <span class="keyword">public</span> <a class="code hl_class" href="classtensor4d_1_1nn_1_1Layer.html">Layer</a>&lt;T&gt; {</div>
<div class="line"><a id="l00184" name="l00184"></a><span class="lineno">  184</span><span class="keyword">public</span>:</div>
<div class="line"><a id="l00185" name="l00185"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1ReLU.html#aed0a602218dd422544cdf5ca46f6d056">  185</a></span>    <a class="code hl_function" href="classtensor4d_1_1nn_1_1ReLU.html#aed0a602218dd422544cdf5ca46f6d056">ReLU</a>() : <a class="code hl_variable" href="classtensor4d_1_1nn_1_1ReLU.html#a30f2eabf132b2de1b31ff67d0ad1a5c5">input_</a>({1, 1}, <span class="keyword">false</span>) {}</div>
<div class="line"><a id="l00186" name="l00186"></a><span class="lineno">  186</span>    </div>
<div class="foldopen" id="foldopen00187" data-start="{" data-end="}">
<div class="line"><a id="l00187" name="l00187"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1ReLU.html#a07b3b9bee90208e9510c4cc740639689">  187</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_function" href="classtensor4d_1_1nn_1_1ReLU.html#a07b3b9bee90208e9510c4cc740639689">forward</a>(<span class="keyword">const</span> <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>&amp; input)<span class="keyword"> override </span>{</div>
<div class="line"><a id="l00188" name="l00188"></a><span class="lineno">  188</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1ReLU.html#a30f2eabf132b2de1b31ff67d0ad1a5c5">input_</a> = input;</div>
<div class="line"><a id="l00189" name="l00189"></a><span class="lineno">  189</span>        <span class="keywordflow">return</span> input.<a class="code hl_function" href="classTensor.html#a74db7588a7150d94b620ad63de1f5980">relu</a>();</div>
<div class="line"><a id="l00190" name="l00190"></a><span class="lineno">  190</span>    }</div>
</div>
<div class="line"><a id="l00191" name="l00191"></a><span class="lineno">  191</span>    </div>
<div class="foldopen" id="foldopen00192" data-start="{" data-end="}">
<div class="line"><a id="l00192" name="l00192"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1ReLU.html#ac991c01d3b1607d533183075fb02f354">  192</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_function" href="classtensor4d_1_1nn_1_1ReLU.html#ac991c01d3b1607d533183075fb02f354">backward</a>(<span class="keyword">const</span> <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>&amp; grad_output)<span class="keyword"> override </span>{</div>
<div class="line"><a id="l00193" name="l00193"></a><span class="lineno">  193</span>        <span class="comment">// ReLU gradient: grad * (input &gt; 0)</span></div>
<div class="line"><a id="l00194" name="l00194"></a><span class="lineno">  194</span>        <span class="keyword">auto</span> shape = <a class="code hl_variable" href="classtensor4d_1_1nn_1_1ReLU.html#a30f2eabf132b2de1b31ff67d0ad1a5c5">input_</a>.shape();</div>
<div class="line"><a id="l00195" name="l00195"></a><span class="lineno">  195</span>        <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> grad_input(shape);</div>
<div class="line"><a id="l00196" name="l00196"></a><span class="lineno">  196</span>        </div>
<div class="line"><a id="l00197" name="l00197"></a><span class="lineno">  197</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; shape[0]; ++i) {</div>
<div class="line"><a id="l00198" name="l00198"></a><span class="lineno">  198</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; shape[1]; ++j) {</div>
<div class="line"><a id="l00199" name="l00199"></a><span class="lineno">  199</span>                grad_input[{i, j}] = <a class="code hl_variable" href="classtensor4d_1_1nn_1_1ReLU.html#a30f2eabf132b2de1b31ff67d0ad1a5c5">input_</a>[{i, j}] &gt; 0 ? grad_output[{i, j}] : 0;</div>
<div class="line"><a id="l00200" name="l00200"></a><span class="lineno">  200</span>            }</div>
<div class="line"><a id="l00201" name="l00201"></a><span class="lineno">  201</span>        }</div>
<div class="line"><a id="l00202" name="l00202"></a><span class="lineno">  202</span>        </div>
<div class="line"><a id="l00203" name="l00203"></a><span class="lineno">  203</span>        <span class="keywordflow">return</span> grad_input;</div>
<div class="line"><a id="l00204" name="l00204"></a><span class="lineno">  204</span>    }</div>
</div>
<div class="line"><a id="l00205" name="l00205"></a><span class="lineno">  205</span>    </div>
<div class="line"><a id="l00206" name="l00206"></a><span class="lineno">  206</span><span class="keyword">private</span>:</div>
<div class="line"><a id="l00207" name="l00207"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1ReLU.html#a30f2eabf132b2de1b31ff67d0ad1a5c5">  207</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1ReLU.html#a30f2eabf132b2de1b31ff67d0ad1a5c5">input_</a>;</div>
<div class="line"><a id="l00208" name="l00208"></a><span class="lineno">  208</span>};</div>
</div>
<div class="line"><a id="l00209" name="l00209"></a><span class="lineno">  209</span></div>
<div class="line"><a id="l00213" name="l00213"></a><span class="lineno">  213</span><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00214" data-start="{" data-end="};">
<div class="line"><a id="l00214" name="l00214"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Sigmoid.html">  214</a></span><span class="keyword">class </span><a class="code hl_function" href="classtensor4d_1_1nn_1_1Sigmoid.html#a7a699853be0806bf11af345641f690fd">Sigmoid</a> : <span class="keyword">public</span> <a class="code hl_class" href="classtensor4d_1_1nn_1_1Layer.html">Layer</a>&lt;T&gt; {</div>
<div class="line"><a id="l00215" name="l00215"></a><span class="lineno">  215</span><span class="keyword">public</span>:</div>
<div class="line"><a id="l00216" name="l00216"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Sigmoid.html#a7a699853be0806bf11af345641f690fd">  216</a></span>    <a class="code hl_function" href="classtensor4d_1_1nn_1_1Sigmoid.html#a7a699853be0806bf11af345641f690fd">Sigmoid</a>() : <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Sigmoid.html#aa8058b771d3d30a043d853026cfa06ea">output_</a>({1, 1}, <span class="keyword">false</span>) {}</div>
<div class="line"><a id="l00217" name="l00217"></a><span class="lineno">  217</span>    </div>
<div class="foldopen" id="foldopen00218" data-start="{" data-end="}">
<div class="line"><a id="l00218" name="l00218"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Sigmoid.html#a5bde4d78573f5ea7c6c5e4d624bda3fb">  218</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_function" href="classtensor4d_1_1nn_1_1Sigmoid.html#a5bde4d78573f5ea7c6c5e4d624bda3fb">forward</a>(<span class="keyword">const</span> <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>&amp; input)<span class="keyword"> override </span>{</div>
<div class="line"><a id="l00219" name="l00219"></a><span class="lineno">  219</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Sigmoid.html#aa8058b771d3d30a043d853026cfa06ea">output_</a> = input.<a class="code hl_function" href="classTensor.html#afff455663faa35d6cfa72aa03f689e94">sigmoid</a>();</div>
<div class="line"><a id="l00220" name="l00220"></a><span class="lineno">  220</span>        <span class="keywordflow">return</span> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Sigmoid.html#aa8058b771d3d30a043d853026cfa06ea">output_</a>;</div>
<div class="line"><a id="l00221" name="l00221"></a><span class="lineno">  221</span>    }</div>
</div>
<div class="line"><a id="l00222" name="l00222"></a><span class="lineno">  222</span>    </div>
<div class="foldopen" id="foldopen00223" data-start="{" data-end="}">
<div class="line"><a id="l00223" name="l00223"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Sigmoid.html#a41e695161d280883a0002fe199efdf98">  223</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_function" href="classtensor4d_1_1nn_1_1Sigmoid.html#a41e695161d280883a0002fe199efdf98">backward</a>(<span class="keyword">const</span> <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>&amp; grad_output)<span class="keyword"> override </span>{</div>
<div class="line"><a id="l00224" name="l00224"></a><span class="lineno">  224</span>        <span class="comment">// sigmoid&#39;(x) = sigmoid(x) * (1 - sigmoid(x))</span></div>
<div class="line"><a id="l00225" name="l00225"></a><span class="lineno">  225</span>        <span class="keyword">auto</span> shape = <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Sigmoid.html#aa8058b771d3d30a043d853026cfa06ea">output_</a>.shape();</div>
<div class="line"><a id="l00226" name="l00226"></a><span class="lineno">  226</span>        <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> grad_input(shape);</div>
<div class="line"><a id="l00227" name="l00227"></a><span class="lineno">  227</span>        </div>
<div class="line"><a id="l00228" name="l00228"></a><span class="lineno">  228</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; shape[0]; ++i) {</div>
<div class="line"><a id="l00229" name="l00229"></a><span class="lineno">  229</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; shape[1]; ++j) {</div>
<div class="line"><a id="l00230" name="l00230"></a><span class="lineno">  230</span>                T sig = <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Sigmoid.html#aa8058b771d3d30a043d853026cfa06ea">output_</a>[{i, j}];</div>
<div class="line"><a id="l00231" name="l00231"></a><span class="lineno">  231</span>                grad_input[{i, j}] = grad_output[{i, j}] * sig * (1 - sig);</div>
<div class="line"><a id="l00232" name="l00232"></a><span class="lineno">  232</span>            }</div>
<div class="line"><a id="l00233" name="l00233"></a><span class="lineno">  233</span>        }</div>
<div class="line"><a id="l00234" name="l00234"></a><span class="lineno">  234</span>        </div>
<div class="line"><a id="l00235" name="l00235"></a><span class="lineno">  235</span>        <span class="keywordflow">return</span> grad_input;</div>
<div class="line"><a id="l00236" name="l00236"></a><span class="lineno">  236</span>    }</div>
</div>
<div class="line"><a id="l00237" name="l00237"></a><span class="lineno">  237</span>    </div>
<div class="line"><a id="l00238" name="l00238"></a><span class="lineno">  238</span><span class="keyword">private</span>:</div>
<div class="line"><a id="l00239" name="l00239"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Sigmoid.html#aa8058b771d3d30a043d853026cfa06ea">  239</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Sigmoid.html#aa8058b771d3d30a043d853026cfa06ea">output_</a>;</div>
<div class="line"><a id="l00240" name="l00240"></a><span class="lineno">  240</span>};</div>
</div>
<div class="line"><a id="l00241" name="l00241"></a><span class="lineno">  241</span></div>
<div class="line"><a id="l00245" name="l00245"></a><span class="lineno">  245</span><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00246" data-start="{" data-end="};">
<div class="line"><a id="l00246" name="l00246"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Tanh.html">  246</a></span><span class="keyword">class </span><a class="code hl_function" href="classtensor4d_1_1nn_1_1Tanh.html#a0e1b8dd43bc9599b91da6a6beba02e22">Tanh</a> : <span class="keyword">public</span> <a class="code hl_class" href="classtensor4d_1_1nn_1_1Layer.html">Layer</a>&lt;T&gt; {</div>
<div class="line"><a id="l00247" name="l00247"></a><span class="lineno">  247</span><span class="keyword">public</span>:</div>
<div class="line"><a id="l00248" name="l00248"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Tanh.html#a0e1b8dd43bc9599b91da6a6beba02e22">  248</a></span>    <a class="code hl_function" href="classtensor4d_1_1nn_1_1Tanh.html#a0e1b8dd43bc9599b91da6a6beba02e22">Tanh</a>() : <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Tanh.html#a657c2dab547dc900fda0a86818ea1172">output_</a>({1, 1}, <span class="keyword">false</span>) {}</div>
<div class="line"><a id="l00249" name="l00249"></a><span class="lineno">  249</span>    </div>
<div class="foldopen" id="foldopen00250" data-start="{" data-end="}">
<div class="line"><a id="l00250" name="l00250"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Tanh.html#a5bf1911c8b5865f171c90efbefbbe437">  250</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_function" href="classtensor4d_1_1nn_1_1Tanh.html#a5bf1911c8b5865f171c90efbefbbe437">forward</a>(<span class="keyword">const</span> <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>&amp; input)<span class="keyword"> override </span>{</div>
<div class="line"><a id="l00251" name="l00251"></a><span class="lineno">  251</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Tanh.html#a657c2dab547dc900fda0a86818ea1172">output_</a> = input.<a class="code hl_function" href="classTensor.html#adcc5341aa2156f24c0f4069543c958e1">tanh</a>();</div>
<div class="line"><a id="l00252" name="l00252"></a><span class="lineno">  252</span>        <span class="keywordflow">return</span> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Tanh.html#a657c2dab547dc900fda0a86818ea1172">output_</a>;</div>
<div class="line"><a id="l00253" name="l00253"></a><span class="lineno">  253</span>    }</div>
</div>
<div class="line"><a id="l00254" name="l00254"></a><span class="lineno">  254</span>    </div>
<div class="foldopen" id="foldopen00255" data-start="{" data-end="}">
<div class="line"><a id="l00255" name="l00255"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Tanh.html#a8211c640d2b962ecad7a5c29203e663c">  255</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_function" href="classtensor4d_1_1nn_1_1Tanh.html#a8211c640d2b962ecad7a5c29203e663c">backward</a>(<span class="keyword">const</span> <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>&amp; grad_output)<span class="keyword"> override </span>{</div>
<div class="line"><a id="l00256" name="l00256"></a><span class="lineno">  256</span>        <span class="comment">// tanh&#39;(x) = 1 - tanh^2(x)</span></div>
<div class="line"><a id="l00257" name="l00257"></a><span class="lineno">  257</span>        <span class="keyword">auto</span> shape = <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Tanh.html#a657c2dab547dc900fda0a86818ea1172">output_</a>.shape();</div>
<div class="line"><a id="l00258" name="l00258"></a><span class="lineno">  258</span>        <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> grad_input(shape);</div>
<div class="line"><a id="l00259" name="l00259"></a><span class="lineno">  259</span>        </div>
<div class="line"><a id="l00260" name="l00260"></a><span class="lineno">  260</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; shape[0]; ++i) {</div>
<div class="line"><a id="l00261" name="l00261"></a><span class="lineno">  261</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; shape[1]; ++j) {</div>
<div class="line"><a id="l00262" name="l00262"></a><span class="lineno">  262</span>                T t = <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Tanh.html#a657c2dab547dc900fda0a86818ea1172">output_</a>[{i, j}];</div>
<div class="line"><a id="l00263" name="l00263"></a><span class="lineno">  263</span>                grad_input[{i, j}] = grad_output[{i, j}] * (1 - t * t);</div>
<div class="line"><a id="l00264" name="l00264"></a><span class="lineno">  264</span>            }</div>
<div class="line"><a id="l00265" name="l00265"></a><span class="lineno">  265</span>        }</div>
<div class="line"><a id="l00266" name="l00266"></a><span class="lineno">  266</span>        </div>
<div class="line"><a id="l00267" name="l00267"></a><span class="lineno">  267</span>        <span class="keywordflow">return</span> grad_input;</div>
<div class="line"><a id="l00268" name="l00268"></a><span class="lineno">  268</span>    }</div>
</div>
<div class="line"><a id="l00269" name="l00269"></a><span class="lineno">  269</span>    </div>
<div class="line"><a id="l00270" name="l00270"></a><span class="lineno">  270</span><span class="keyword">private</span>:</div>
<div class="line"><a id="l00271" name="l00271"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Tanh.html#a657c2dab547dc900fda0a86818ea1172">  271</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Tanh.html#a657c2dab547dc900fda0a86818ea1172">output_</a>;</div>
<div class="line"><a id="l00272" name="l00272"></a><span class="lineno">  272</span>};</div>
</div>
<div class="line"><a id="l00273" name="l00273"></a><span class="lineno">  273</span></div>
<div class="line"><a id="l00277" name="l00277"></a><span class="lineno">  277</span><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00278" data-start="{" data-end="};">
<div class="line"><a id="l00278" name="l00278"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Dropout.html">  278</a></span><span class="keyword">class </span><a class="code hl_function" href="classtensor4d_1_1nn_1_1Dropout.html#aea77c1d5fe4c7acaa55174fde51883c5">Dropout</a> : <span class="keyword">public</span> <a class="code hl_class" href="classtensor4d_1_1nn_1_1Layer.html">Layer</a>&lt;T&gt; {</div>
<div class="line"><a id="l00279" name="l00279"></a><span class="lineno">  279</span><span class="keyword">public</span>:</div>
<div class="foldopen" id="foldopen00284" data-start="{" data-end="}">
<div class="line"><a id="l00284" name="l00284"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Dropout.html#aea77c1d5fe4c7acaa55174fde51883c5">  284</a></span>    <span class="keyword">explicit</span> <a class="code hl_function" href="classtensor4d_1_1nn_1_1Dropout.html#aea77c1d5fe4c7acaa55174fde51883c5">Dropout</a>(T p = 0.5) : <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Dropout.html#add8163856fcd8550fc2d2bdbafdf7115">p_</a>(p), <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Dropout.html#a156bdcf7dd306241dfc47d6224c08b1c">mask_</a>({1, 1}, <span class="keyword">false</span>) {</div>
<div class="line"><a id="l00285" name="l00285"></a><span class="lineno">  285</span>        <span class="keywordflow">if</span> (p &lt; 0 || p &gt; 1) {</div>
<div class="line"><a id="l00286" name="l00286"></a><span class="lineno">  286</span>            <span class="keywordflow">throw</span> std::invalid_argument(<span class="stringliteral">&quot;Dropout probability must be between 0 and 1&quot;</span>);</div>
<div class="line"><a id="l00287" name="l00287"></a><span class="lineno">  287</span>        }</div>
<div class="line"><a id="l00288" name="l00288"></a><span class="lineno">  288</span>    }</div>
</div>
<div class="line"><a id="l00289" name="l00289"></a><span class="lineno">  289</span>    </div>
<div class="foldopen" id="foldopen00290" data-start="{" data-end="}">
<div class="line"><a id="l00290" name="l00290"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Dropout.html#aff0f87aa27d1aceca0bbcc6b0655ce24">  290</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_function" href="classtensor4d_1_1nn_1_1Dropout.html#aff0f87aa27d1aceca0bbcc6b0655ce24">forward</a>(<span class="keyword">const</span> <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>&amp; input)<span class="keyword"> override </span>{</div>
<div class="line"><a id="l00291" name="l00291"></a><span class="lineno">  291</span>        <span class="keywordflow">if</span> (!this-&gt;<a class="code hl_variable" href="classtensor4d_1_1nn_1_1Layer.html#a5046b1e468f41cc660af5f541be017d6">training_</a>) {</div>
<div class="line"><a id="l00292" name="l00292"></a><span class="lineno">  292</span>            <span class="keywordflow">return</span> input;  <span class="comment">// No dropout during inference</span></div>
<div class="line"><a id="l00293" name="l00293"></a><span class="lineno">  293</span>        }</div>
<div class="line"><a id="l00294" name="l00294"></a><span class="lineno">  294</span>        </div>
<div class="line"><a id="l00295" name="l00295"></a><span class="lineno">  295</span>        <span class="keyword">auto</span> shape = input.<a class="code hl_function" href="classTensor.html#a80b3ffaf92ed36f02d6f4d4230b5d2a0">shape</a>();</div>
<div class="line"><a id="l00296" name="l00296"></a><span class="lineno">  296</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Dropout.html#a156bdcf7dd306241dfc47d6224c08b1c">mask_</a> = <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>(shape);</div>
<div class="line"><a id="l00297" name="l00297"></a><span class="lineno">  297</span>        </div>
<div class="line"><a id="l00298" name="l00298"></a><span class="lineno">  298</span>        std::random_device rd;</div>
<div class="line"><a id="l00299" name="l00299"></a><span class="lineno">  299</span>        std::mt19937 gen(rd());</div>
<div class="line"><a id="l00300" name="l00300"></a><span class="lineno">  300</span>        std::bernoulli_distribution dist(1 - <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Dropout.html#add8163856fcd8550fc2d2bdbafdf7115">p_</a>);</div>
<div class="line"><a id="l00301" name="l00301"></a><span class="lineno">  301</span>        </div>
<div class="line"><a id="l00302" name="l00302"></a><span class="lineno">  302</span>        T scale = 1.0 / (1.0 - <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Dropout.html#add8163856fcd8550fc2d2bdbafdf7115">p_</a>);  <span class="comment">// Inverted dropout</span></div>
<div class="line"><a id="l00303" name="l00303"></a><span class="lineno">  303</span>        </div>
<div class="line"><a id="l00304" name="l00304"></a><span class="lineno">  304</span>        <span class="keyword">auto</span> output = input;</div>
<div class="line"><a id="l00305" name="l00305"></a><span class="lineno">  305</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; shape[0]; ++i) {</div>
<div class="line"><a id="l00306" name="l00306"></a><span class="lineno">  306</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; shape[1]; ++j) {</div>
<div class="line"><a id="l00307" name="l00307"></a><span class="lineno">  307</span>                <span class="keywordtype">bool</span> keep = dist(gen);</div>
<div class="line"><a id="l00308" name="l00308"></a><span class="lineno">  308</span>                <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Dropout.html#a156bdcf7dd306241dfc47d6224c08b1c">mask_</a>[{i, j}] = keep ? scale : 0;</div>
<div class="line"><a id="l00309" name="l00309"></a><span class="lineno">  309</span>                output[{i, j}] *= <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Dropout.html#a156bdcf7dd306241dfc47d6224c08b1c">mask_</a>[{i, j}];</div>
<div class="line"><a id="l00310" name="l00310"></a><span class="lineno">  310</span>            }</div>
<div class="line"><a id="l00311" name="l00311"></a><span class="lineno">  311</span>        }</div>
<div class="line"><a id="l00312" name="l00312"></a><span class="lineno">  312</span>        </div>
<div class="line"><a id="l00313" name="l00313"></a><span class="lineno">  313</span>        <span class="keywordflow">return</span> output;</div>
<div class="line"><a id="l00314" name="l00314"></a><span class="lineno">  314</span>    }</div>
</div>
<div class="line"><a id="l00315" name="l00315"></a><span class="lineno">  315</span>    </div>
<div class="foldopen" id="foldopen00316" data-start="{" data-end="}">
<div class="line"><a id="l00316" name="l00316"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Dropout.html#ad7713d85865e3238e14e920b47f44237">  316</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_function" href="classtensor4d_1_1nn_1_1Dropout.html#ad7713d85865e3238e14e920b47f44237">backward</a>(<span class="keyword">const</span> <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>&amp; grad_output)<span class="keyword"> override </span>{</div>
<div class="line"><a id="l00317" name="l00317"></a><span class="lineno">  317</span>        <span class="keywordflow">if</span> (!this-&gt;<a class="code hl_variable" href="classtensor4d_1_1nn_1_1Layer.html#a5046b1e468f41cc660af5f541be017d6">training_</a>) {</div>
<div class="line"><a id="l00318" name="l00318"></a><span class="lineno">  318</span>            <span class="keywordflow">return</span> grad_output;</div>
<div class="line"><a id="l00319" name="l00319"></a><span class="lineno">  319</span>        }</div>
<div class="line"><a id="l00320" name="l00320"></a><span class="lineno">  320</span>        </div>
<div class="line"><a id="l00321" name="l00321"></a><span class="lineno">  321</span>        <span class="keyword">auto</span> shape = grad_output.<a class="code hl_function" href="classTensor.html#a80b3ffaf92ed36f02d6f4d4230b5d2a0">shape</a>();</div>
<div class="line"><a id="l00322" name="l00322"></a><span class="lineno">  322</span>        <span class="keyword">auto</span> grad_input = grad_output;</div>
<div class="line"><a id="l00323" name="l00323"></a><span class="lineno">  323</span>        </div>
<div class="line"><a id="l00324" name="l00324"></a><span class="lineno">  324</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; shape[0]; ++i) {</div>
<div class="line"><a id="l00325" name="l00325"></a><span class="lineno">  325</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; shape[1]; ++j) {</div>
<div class="line"><a id="l00326" name="l00326"></a><span class="lineno">  326</span>                grad_input[{i, j}] *= <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Dropout.html#a156bdcf7dd306241dfc47d6224c08b1c">mask_</a>[{i, j}];</div>
<div class="line"><a id="l00327" name="l00327"></a><span class="lineno">  327</span>            }</div>
<div class="line"><a id="l00328" name="l00328"></a><span class="lineno">  328</span>        }</div>
<div class="line"><a id="l00329" name="l00329"></a><span class="lineno">  329</span>        </div>
<div class="line"><a id="l00330" name="l00330"></a><span class="lineno">  330</span>        <span class="keywordflow">return</span> grad_input;</div>
<div class="line"><a id="l00331" name="l00331"></a><span class="lineno">  331</span>    }</div>
</div>
<div class="line"><a id="l00332" name="l00332"></a><span class="lineno">  332</span>    </div>
<div class="line"><a id="l00333" name="l00333"></a><span class="lineno">  333</span><span class="keyword">private</span>:</div>
<div class="line"><a id="l00334" name="l00334"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Dropout.html#add8163856fcd8550fc2d2bdbafdf7115">  334</a></span>    T <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Dropout.html#add8163856fcd8550fc2d2bdbafdf7115">p_</a>;  <span class="comment">// Dropout probability</span></div>
<div class="line"><a id="l00335" name="l00335"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Dropout.html#a156bdcf7dd306241dfc47d6224c08b1c">  335</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Dropout.html#a156bdcf7dd306241dfc47d6224c08b1c">mask_</a>;</div>
<div class="line"><a id="l00336" name="l00336"></a><span class="lineno">  336</span>};</div>
</div>
<div class="line"><a id="l00337" name="l00337"></a><span class="lineno">  337</span></div>
<div class="line"><a id="l00341" name="l00341"></a><span class="lineno">  341</span><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00342" data-start="{" data-end="};">
<div class="line"><a id="l00342" name="l00342"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1BatchNorm1d.html">  342</a></span><span class="keyword">class </span><a class="code hl_function" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a2775a2774d8a6c4216b4cf2c5691335b">BatchNorm1d</a> : <span class="keyword">public</span> <a class="code hl_class" href="classtensor4d_1_1nn_1_1Layer.html">Layer</a>&lt;T&gt; {</div>
<div class="line"><a id="l00343" name="l00343"></a><span class="lineno">  343</span><span class="keyword">public</span>:</div>
<div class="foldopen" id="foldopen00350" data-start="{" data-end="}">
<div class="line"><a id="l00350" name="l00350"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a2775a2774d8a6c4216b4cf2c5691335b">  350</a></span>    <a class="code hl_function" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a2775a2774d8a6c4216b4cf2c5691335b">BatchNorm1d</a>(<span class="keywordtype">size_t</span> num_features, T eps = 1e-5, T momentum = 0.1)</div>
<div class="line"><a id="l00351" name="l00351"></a><span class="lineno">  351</span>        : <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a2c9cea8478dc951c47bc95c219e87db1">num_features_</a>(num_features), <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a66a9964817b54848afc8b46d7367207d">eps_</a>(eps), <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a5615d826982a2f132397419ca7881609">momentum_</a>(momentum),</div>
<div class="line"><a id="l00352" name="l00352"></a><span class="lineno">  352</span>          <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a311f849757fe8d8f70cfd55ce896b5da">gamma_</a>({1, num_features}, <span class="keyword">false</span>), <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a06aa43a886c3349131e4cec95a847a5e">beta_</a>({1, num_features}, <span class="keyword">false</span>),</div>
<div class="line"><a id="l00353" name="l00353"></a><span class="lineno">  353</span>          <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a5804439c12b21f719bdab6b8bac01fdc">running_mean_</a>({1, num_features}, <span class="keyword">false</span>), <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#afeec797fa0b23c42329aecb063a826b4">running_var_</a>({1, num_features}, <span class="keyword">false</span>),</div>
<div class="line"><a id="l00354" name="l00354"></a><span class="lineno">  354</span>          <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#ae56fd1f24787c14016e2fb0f14719b65">batch_mean_</a>({1, num_features}, <span class="keyword">false</span>), <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#af4cb5a26201a5cb84493fd4ade774989">batch_var_</a>({1, num_features}, <span class="keyword">false</span>),</div>
<div class="line"><a id="l00355" name="l00355"></a><span class="lineno">  355</span>          <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a20ef166dce9b80f2697e645af2bb451e">input_</a>({1, num_features}, <span class="keyword">false</span>), <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#ac9f443c1167f9978a0ab6a0dc97f02b2">input_normalized_</a>({1, num_features}, <span class="keyword">false</span>),</div>
<div class="line"><a id="l00356" name="l00356"></a><span class="lineno">  356</span>          <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a3ba4cd0f7addeb22751af6893a23491f">grad_gamma_</a>({1, num_features}, <span class="keyword">false</span>), <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a8295c6940c580ef2aed68f78099c7698">grad_beta_</a>({1, num_features}, <span class="keyword">false</span>) {</div>
<div class="line"><a id="l00357" name="l00357"></a><span class="lineno">  357</span>        </div>
<div class="line"><a id="l00358" name="l00358"></a><span class="lineno">  358</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a311f849757fe8d8f70cfd55ce896b5da">gamma_</a> = Tensor&lt;T, 2&gt;({1, num_features});</div>
<div class="line"><a id="l00359" name="l00359"></a><span class="lineno">  359</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a06aa43a886c3349131e4cec95a847a5e">beta_</a> = Tensor&lt;T, 2&gt;({1, num_features});</div>
<div class="line"><a id="l00360" name="l00360"></a><span class="lineno">  360</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a311f849757fe8d8f70cfd55ce896b5da">gamma_</a>.fill(1);</div>
<div class="line"><a id="l00361" name="l00361"></a><span class="lineno">  361</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a06aa43a886c3349131e4cec95a847a5e">beta_</a>.fill(0);</div>
<div class="line"><a id="l00362" name="l00362"></a><span class="lineno">  362</span>        </div>
<div class="line"><a id="l00363" name="l00363"></a><span class="lineno">  363</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a5804439c12b21f719bdab6b8bac01fdc">running_mean_</a> = Tensor&lt;T, 2&gt;({1, num_features});</div>
<div class="line"><a id="l00364" name="l00364"></a><span class="lineno">  364</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#afeec797fa0b23c42329aecb063a826b4">running_var_</a> = Tensor&lt;T, 2&gt;({1, num_features});</div>
<div class="line"><a id="l00365" name="l00365"></a><span class="lineno">  365</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a5804439c12b21f719bdab6b8bac01fdc">running_mean_</a>.fill(0);</div>
<div class="line"><a id="l00366" name="l00366"></a><span class="lineno">  366</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#afeec797fa0b23c42329aecb063a826b4">running_var_</a>.fill(1);</div>
<div class="line"><a id="l00367" name="l00367"></a><span class="lineno">  367</span>    }</div>
</div>
<div class="line"><a id="l00368" name="l00368"></a><span class="lineno">  368</span>    </div>
<div class="foldopen" id="foldopen00369" data-start="{" data-end="}">
<div class="line"><a id="l00369" name="l00369"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a8e589b2051e3a2c38b1a0feccc33bdb2">  369</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_function" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a8e589b2051e3a2c38b1a0feccc33bdb2">forward</a>(<span class="keyword">const</span> <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>&amp; input)<span class="keyword"> override </span>{</div>
<div class="line"><a id="l00370" name="l00370"></a><span class="lineno">  370</span>        <span class="keyword">auto</span> shape = input.<a class="code hl_function" href="classTensor.html#a80b3ffaf92ed36f02d6f4d4230b5d2a0">shape</a>();</div>
<div class="line"><a id="l00371" name="l00371"></a><span class="lineno">  371</span>        <span class="keywordtype">size_t</span> batch_size = shape[0];</div>
<div class="line"><a id="l00372" name="l00372"></a><span class="lineno">  372</span>        </div>
<div class="line"><a id="l00373" name="l00373"></a><span class="lineno">  373</span>        <span class="keywordflow">if</span> (this-&gt;<a class="code hl_variable" href="classtensor4d_1_1nn_1_1Layer.html#a5046b1e468f41cc660af5f541be017d6">training_</a>) {</div>
<div class="line"><a id="l00374" name="l00374"></a><span class="lineno">  374</span>            <span class="comment">// Compute batch statistics</span></div>
<div class="line"><a id="l00375" name="l00375"></a><span class="lineno">  375</span>            <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#ae56fd1f24787c14016e2fb0f14719b65">batch_mean_</a> = <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>({1, <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a2c9cea8478dc951c47bc95c219e87db1">num_features_</a>});</div>
<div class="line"><a id="l00376" name="l00376"></a><span class="lineno">  376</span>            <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#ae56fd1f24787c14016e2fb0f14719b65">batch_mean_</a>.fill(0);</div>
<div class="line"><a id="l00377" name="l00377"></a><span class="lineno">  377</span>            </div>
<div class="line"><a id="l00378" name="l00378"></a><span class="lineno">  378</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; batch_size; ++i) {</div>
<div class="line"><a id="l00379" name="l00379"></a><span class="lineno">  379</span>                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a2c9cea8478dc951c47bc95c219e87db1">num_features_</a>; ++j) {</div>
<div class="line"><a id="l00380" name="l00380"></a><span class="lineno">  380</span>                    <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#ae56fd1f24787c14016e2fb0f14719b65">batch_mean_</a>[{0, j}] += input[{i, j}];</div>
<div class="line"><a id="l00381" name="l00381"></a><span class="lineno">  381</span>                }</div>
<div class="line"><a id="l00382" name="l00382"></a><span class="lineno">  382</span>            }</div>
<div class="line"><a id="l00383" name="l00383"></a><span class="lineno">  383</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a2c9cea8478dc951c47bc95c219e87db1">num_features_</a>; ++j) {</div>
<div class="line"><a id="l00384" name="l00384"></a><span class="lineno">  384</span>                <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#ae56fd1f24787c14016e2fb0f14719b65">batch_mean_</a>[{0, j}] /= batch_size;</div>
<div class="line"><a id="l00385" name="l00385"></a><span class="lineno">  385</span>            }</div>
<div class="line"><a id="l00386" name="l00386"></a><span class="lineno">  386</span>            </div>
<div class="line"><a id="l00387" name="l00387"></a><span class="lineno">  387</span>            <span class="comment">// Compute variance</span></div>
<div class="line"><a id="l00388" name="l00388"></a><span class="lineno">  388</span>            <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#af4cb5a26201a5cb84493fd4ade774989">batch_var_</a> = <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>({1, <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a2c9cea8478dc951c47bc95c219e87db1">num_features_</a>});</div>
<div class="line"><a id="l00389" name="l00389"></a><span class="lineno">  389</span>            <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#af4cb5a26201a5cb84493fd4ade774989">batch_var_</a>.fill(0);</div>
<div class="line"><a id="l00390" name="l00390"></a><span class="lineno">  390</span>            </div>
<div class="line"><a id="l00391" name="l00391"></a><span class="lineno">  391</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; batch_size; ++i) {</div>
<div class="line"><a id="l00392" name="l00392"></a><span class="lineno">  392</span>                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a2c9cea8478dc951c47bc95c219e87db1">num_features_</a>; ++j) {</div>
<div class="line"><a id="l00393" name="l00393"></a><span class="lineno">  393</span>                    T diff = input[{i, j}] - <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#ae56fd1f24787c14016e2fb0f14719b65">batch_mean_</a>[{0, j}];</div>
<div class="line"><a id="l00394" name="l00394"></a><span class="lineno">  394</span>                    <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#af4cb5a26201a5cb84493fd4ade774989">batch_var_</a>[{0, j}] += diff * diff;</div>
<div class="line"><a id="l00395" name="l00395"></a><span class="lineno">  395</span>                }</div>
<div class="line"><a id="l00396" name="l00396"></a><span class="lineno">  396</span>            }</div>
<div class="line"><a id="l00397" name="l00397"></a><span class="lineno">  397</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a2c9cea8478dc951c47bc95c219e87db1">num_features_</a>; ++j) {</div>
<div class="line"><a id="l00398" name="l00398"></a><span class="lineno">  398</span>                <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#af4cb5a26201a5cb84493fd4ade774989">batch_var_</a>[{0, j}] /= batch_size;</div>
<div class="line"><a id="l00399" name="l00399"></a><span class="lineno">  399</span>            }</div>
<div class="line"><a id="l00400" name="l00400"></a><span class="lineno">  400</span>            </div>
<div class="line"><a id="l00401" name="l00401"></a><span class="lineno">  401</span>            <span class="comment">// Update running statistics</span></div>
<div class="line"><a id="l00402" name="l00402"></a><span class="lineno">  402</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a2c9cea8478dc951c47bc95c219e87db1">num_features_</a>; ++j) {</div>
<div class="line"><a id="l00403" name="l00403"></a><span class="lineno">  403</span>                <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a5804439c12b21f719bdab6b8bac01fdc">running_mean_</a>[{0, j}] = (1 - <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a5615d826982a2f132397419ca7881609">momentum_</a>) * <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a5804439c12b21f719bdab6b8bac01fdc">running_mean_</a>[{0, j}] + </div>
<div class="line"><a id="l00404" name="l00404"></a><span class="lineno">  404</span>                                        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a5615d826982a2f132397419ca7881609">momentum_</a> * <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#ae56fd1f24787c14016e2fb0f14719b65">batch_mean_</a>[{0, j}];</div>
<div class="line"><a id="l00405" name="l00405"></a><span class="lineno">  405</span>                <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#afeec797fa0b23c42329aecb063a826b4">running_var_</a>[{0, j}] = (1 - <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a5615d826982a2f132397419ca7881609">momentum_</a>) * <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#afeec797fa0b23c42329aecb063a826b4">running_var_</a>[{0, j}] + </div>
<div class="line"><a id="l00406" name="l00406"></a><span class="lineno">  406</span>                                       <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a5615d826982a2f132397419ca7881609">momentum_</a> * <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#af4cb5a26201a5cb84493fd4ade774989">batch_var_</a>[{0, j}];</div>
<div class="line"><a id="l00407" name="l00407"></a><span class="lineno">  407</span>            }</div>
<div class="line"><a id="l00408" name="l00408"></a><span class="lineno">  408</span>        }</div>
<div class="line"><a id="l00409" name="l00409"></a><span class="lineno">  409</span>        </div>
<div class="line"><a id="l00410" name="l00410"></a><span class="lineno">  410</span>        <span class="comment">// Normalize</span></div>
<div class="line"><a id="l00411" name="l00411"></a><span class="lineno">  411</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#ac9f443c1167f9978a0ab6a0dc97f02b2">input_normalized_</a> = <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>(shape);</div>
<div class="line"><a id="l00412" name="l00412"></a><span class="lineno">  412</span>        <span class="keyword">auto</span> output = <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>(shape);</div>
<div class="line"><a id="l00413" name="l00413"></a><span class="lineno">  413</span>        </div>
<div class="line"><a id="l00414" name="l00414"></a><span class="lineno">  414</span>        <span class="keyword">const</span> <span class="keyword">auto</span>&amp; mean = this-&gt;<a class="code hl_variable" href="classtensor4d_1_1nn_1_1Layer.html#a5046b1e468f41cc660af5f541be017d6">training_</a> ? <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#ae56fd1f24787c14016e2fb0f14719b65">batch_mean_</a> : <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a5804439c12b21f719bdab6b8bac01fdc">running_mean_</a>;</div>
<div class="line"><a id="l00415" name="l00415"></a><span class="lineno">  415</span>        <span class="keyword">const</span> <span class="keyword">auto</span>&amp; var = this-&gt;<a class="code hl_variable" href="classtensor4d_1_1nn_1_1Layer.html#a5046b1e468f41cc660af5f541be017d6">training_</a> ? <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#af4cb5a26201a5cb84493fd4ade774989">batch_var_</a> : <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#afeec797fa0b23c42329aecb063a826b4">running_var_</a>;</div>
<div class="line"><a id="l00416" name="l00416"></a><span class="lineno">  416</span>        </div>
<div class="line"><a id="l00417" name="l00417"></a><span class="lineno">  417</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; batch_size; ++i) {</div>
<div class="line"><a id="l00418" name="l00418"></a><span class="lineno">  418</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a2c9cea8478dc951c47bc95c219e87db1">num_features_</a>; ++j) {</div>
<div class="line"><a id="l00419" name="l00419"></a><span class="lineno">  419</span>                <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#ac9f443c1167f9978a0ab6a0dc97f02b2">input_normalized_</a>[{i, j}] = (input[{i, j}] - mean[{0, j}]) / </div>
<div class="line"><a id="l00420" name="l00420"></a><span class="lineno">  420</span>                                            std::sqrt(var[{0, j}] + <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a66a9964817b54848afc8b46d7367207d">eps_</a>);</div>
<div class="line"><a id="l00421" name="l00421"></a><span class="lineno">  421</span>                output[{i, j}] = <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a311f849757fe8d8f70cfd55ce896b5da">gamma_</a>[{0, j}] * <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#ac9f443c1167f9978a0ab6a0dc97f02b2">input_normalized_</a>[{i, j}] + <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a06aa43a886c3349131e4cec95a847a5e">beta_</a>[{0, j}];</div>
<div class="line"><a id="l00422" name="l00422"></a><span class="lineno">  422</span>            }</div>
<div class="line"><a id="l00423" name="l00423"></a><span class="lineno">  423</span>        }</div>
<div class="line"><a id="l00424" name="l00424"></a><span class="lineno">  424</span>        </div>
<div class="line"><a id="l00425" name="l00425"></a><span class="lineno">  425</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a20ef166dce9b80f2697e645af2bb451e">input_</a> = input;</div>
<div class="line"><a id="l00426" name="l00426"></a><span class="lineno">  426</span>        <span class="keywordflow">return</span> output;</div>
<div class="line"><a id="l00427" name="l00427"></a><span class="lineno">  427</span>    }</div>
</div>
<div class="line"><a id="l00428" name="l00428"></a><span class="lineno">  428</span>    </div>
<div class="foldopen" id="foldopen00429" data-start="{" data-end="}">
<div class="line"><a id="l00429" name="l00429"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a48ea5fa069810067b9756e3d24b48b73">  429</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_function" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a48ea5fa069810067b9756e3d24b48b73">backward</a>(<span class="keyword">const</span> <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>&amp; grad_output)<span class="keyword"> override </span>{</div>
<div class="line"><a id="l00430" name="l00430"></a><span class="lineno">  430</span>        <span class="keyword">auto</span> shape = grad_output.<a class="code hl_function" href="classTensor.html#a80b3ffaf92ed36f02d6f4d4230b5d2a0">shape</a>();</div>
<div class="line"><a id="l00431" name="l00431"></a><span class="lineno">  431</span>        <span class="keywordtype">size_t</span> batch_size = shape[0];</div>
<div class="line"><a id="l00432" name="l00432"></a><span class="lineno">  432</span>        </div>
<div class="line"><a id="l00433" name="l00433"></a><span class="lineno">  433</span>        <span class="comment">// Gradients w.r.t. gamma and beta</span></div>
<div class="line"><a id="l00434" name="l00434"></a><span class="lineno">  434</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a3ba4cd0f7addeb22751af6893a23491f">grad_gamma_</a> = <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>({1, <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a2c9cea8478dc951c47bc95c219e87db1">num_features_</a>});</div>
<div class="line"><a id="l00435" name="l00435"></a><span class="lineno">  435</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a8295c6940c580ef2aed68f78099c7698">grad_beta_</a> = <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>({1, <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a2c9cea8478dc951c47bc95c219e87db1">num_features_</a>});</div>
<div class="line"><a id="l00436" name="l00436"></a><span class="lineno">  436</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a3ba4cd0f7addeb22751af6893a23491f">grad_gamma_</a>.fill(0);</div>
<div class="line"><a id="l00437" name="l00437"></a><span class="lineno">  437</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a8295c6940c580ef2aed68f78099c7698">grad_beta_</a>.fill(0);</div>
<div class="line"><a id="l00438" name="l00438"></a><span class="lineno">  438</span>        </div>
<div class="line"><a id="l00439" name="l00439"></a><span class="lineno">  439</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; batch_size; ++i) {</div>
<div class="line"><a id="l00440" name="l00440"></a><span class="lineno">  440</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a2c9cea8478dc951c47bc95c219e87db1">num_features_</a>; ++j) {</div>
<div class="line"><a id="l00441" name="l00441"></a><span class="lineno">  441</span>                <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a3ba4cd0f7addeb22751af6893a23491f">grad_gamma_</a>[{0, j}] += grad_output[{i, j}] * <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#ac9f443c1167f9978a0ab6a0dc97f02b2">input_normalized_</a>[{i, j}];</div>
<div class="line"><a id="l00442" name="l00442"></a><span class="lineno">  442</span>                <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a8295c6940c580ef2aed68f78099c7698">grad_beta_</a>[{0, j}] += grad_output[{i, j}];</div>
<div class="line"><a id="l00443" name="l00443"></a><span class="lineno">  443</span>            }</div>
<div class="line"><a id="l00444" name="l00444"></a><span class="lineno">  444</span>        }</div>
<div class="line"><a id="l00445" name="l00445"></a><span class="lineno">  445</span>        </div>
<div class="line"><a id="l00446" name="l00446"></a><span class="lineno">  446</span>        <span class="comment">// Gradient w.r.t. input (simplified)</span></div>
<div class="line"><a id="l00447" name="l00447"></a><span class="lineno">  447</span>        <span class="keyword">auto</span> grad_input = <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>(shape);</div>
<div class="line"><a id="l00448" name="l00448"></a><span class="lineno">  448</span>        T inv_std = 1.0 / std::sqrt(<a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#af4cb5a26201a5cb84493fd4ade774989">batch_var_</a>[{0, 0}] + <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a66a9964817b54848afc8b46d7367207d">eps_</a>);</div>
<div class="line"><a id="l00449" name="l00449"></a><span class="lineno">  449</span>        </div>
<div class="line"><a id="l00450" name="l00450"></a><span class="lineno">  450</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; batch_size; ++i) {</div>
<div class="line"><a id="l00451" name="l00451"></a><span class="lineno">  451</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a2c9cea8478dc951c47bc95c219e87db1">num_features_</a>; ++j) {</div>
<div class="line"><a id="l00452" name="l00452"></a><span class="lineno">  452</span>                grad_input[{i, j}] = grad_output[{i, j}] * <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a311f849757fe8d8f70cfd55ce896b5da">gamma_</a>[{0, j}] * inv_std;</div>
<div class="line"><a id="l00453" name="l00453"></a><span class="lineno">  453</span>            }</div>
<div class="line"><a id="l00454" name="l00454"></a><span class="lineno">  454</span>        }</div>
<div class="line"><a id="l00455" name="l00455"></a><span class="lineno">  455</span>        </div>
<div class="line"><a id="l00456" name="l00456"></a><span class="lineno">  456</span>        <span class="keywordflow">return</span> grad_input;</div>
<div class="line"><a id="l00457" name="l00457"></a><span class="lineno">  457</span>    }</div>
</div>
<div class="line"><a id="l00458" name="l00458"></a><span class="lineno">  458</span>    </div>
<div class="foldopen" id="foldopen00459" data-start="{" data-end="}">
<div class="line"><a id="l00459" name="l00459"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a00a6dc7b408c9edaf7072301c75b4ccf">  459</a></span>    std::vector&lt;Tensor&lt;T, 2&gt;*&gt; <a class="code hl_function" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a00a6dc7b408c9edaf7072301c75b4ccf">parameters</a>()<span class="keyword"> override </span>{</div>
<div class="line"><a id="l00460" name="l00460"></a><span class="lineno">  460</span>        <span class="keywordflow">return</span> {&amp;<a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a311f849757fe8d8f70cfd55ce896b5da">gamma_</a>, &amp;<a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a06aa43a886c3349131e4cec95a847a5e">beta_</a>};</div>
<div class="line"><a id="l00461" name="l00461"></a><span class="lineno">  461</span>    }</div>
</div>
<div class="line"><a id="l00462" name="l00462"></a><span class="lineno">  462</span>    </div>
<div class="line"><a id="l00463" name="l00463"></a><span class="lineno">  463</span><span class="keyword">private</span>:</div>
<div class="line"><a id="l00464" name="l00464"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a2c9cea8478dc951c47bc95c219e87db1">  464</a></span>    <span class="keywordtype">size_t</span> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a2c9cea8478dc951c47bc95c219e87db1">num_features_</a>;</div>
<div class="line"><a id="l00465" name="l00465"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a66a9964817b54848afc8b46d7367207d">  465</a></span>    T <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a66a9964817b54848afc8b46d7367207d">eps_</a>;</div>
<div class="line"><a id="l00466" name="l00466"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a5615d826982a2f132397419ca7881609">  466</a></span>    T <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a5615d826982a2f132397419ca7881609">momentum_</a>;</div>
<div class="line"><a id="l00467" name="l00467"></a><span class="lineno">  467</span>    </div>
<div class="line"><a id="l00468" name="l00468"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a311f849757fe8d8f70cfd55ce896b5da">  468</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a311f849757fe8d8f70cfd55ce896b5da">gamma_</a>;  <span class="comment">// Scale parameter</span></div>
<div class="line"><a id="l00469" name="l00469"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a06aa43a886c3349131e4cec95a847a5e">  469</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a06aa43a886c3349131e4cec95a847a5e">beta_</a>;   <span class="comment">// Shift parameter</span></div>
<div class="line"><a id="l00470" name="l00470"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a5804439c12b21f719bdab6b8bac01fdc">  470</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a5804439c12b21f719bdab6b8bac01fdc">running_mean_</a>;</div>
<div class="line"><a id="l00471" name="l00471"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#afeec797fa0b23c42329aecb063a826b4">  471</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#afeec797fa0b23c42329aecb063a826b4">running_var_</a>;</div>
<div class="line"><a id="l00472" name="l00472"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#ae56fd1f24787c14016e2fb0f14719b65">  472</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#ae56fd1f24787c14016e2fb0f14719b65">batch_mean_</a>;</div>
<div class="line"><a id="l00473" name="l00473"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#af4cb5a26201a5cb84493fd4ade774989">  473</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#af4cb5a26201a5cb84493fd4ade774989">batch_var_</a>;</div>
<div class="line"><a id="l00474" name="l00474"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a20ef166dce9b80f2697e645af2bb451e">  474</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a20ef166dce9b80f2697e645af2bb451e">input_</a>;</div>
<div class="line"><a id="l00475" name="l00475"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#ac9f443c1167f9978a0ab6a0dc97f02b2">  475</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#ac9f443c1167f9978a0ab6a0dc97f02b2">input_normalized_</a>;</div>
<div class="line"><a id="l00476" name="l00476"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a3ba4cd0f7addeb22751af6893a23491f">  476</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a3ba4cd0f7addeb22751af6893a23491f">grad_gamma_</a>;</div>
<div class="line"><a id="l00477" name="l00477"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a8295c6940c580ef2aed68f78099c7698">  477</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a8295c6940c580ef2aed68f78099c7698">grad_beta_</a>;</div>
<div class="line"><a id="l00478" name="l00478"></a><span class="lineno">  478</span>};</div>
</div>
<div class="line"><a id="l00479" name="l00479"></a><span class="lineno">  479</span></div>
<div class="line"><a id="l00483" name="l00483"></a><span class="lineno">  483</span><span class="keyword">template</span>&lt;<span class="keyword">typename</span> T&gt;</div>
<div class="foldopen" id="foldopen00484" data-start="{" data-end="};">
<div class="line"><a id="l00484" name="l00484"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Softmax.html">  484</a></span><span class="keyword">class </span><a class="code hl_function" href="classtensor4d_1_1nn_1_1Softmax.html#aa600157567a716269b66a30f701921d5">Softmax</a> : <span class="keyword">public</span> <a class="code hl_class" href="classtensor4d_1_1nn_1_1Layer.html">Layer</a>&lt;T&gt; {</div>
<div class="line"><a id="l00485" name="l00485"></a><span class="lineno">  485</span><span class="keyword">public</span>:</div>
<div class="line"><a id="l00486" name="l00486"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Softmax.html#aa600157567a716269b66a30f701921d5">  486</a></span>    <a class="code hl_function" href="classtensor4d_1_1nn_1_1Softmax.html#aa600157567a716269b66a30f701921d5">Softmax</a>() : <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Softmax.html#ac1e254f8cb7a007b6ea0491024ceeead">output_</a>({1, 1}, <span class="keyword">false</span>) {}</div>
<div class="line"><a id="l00487" name="l00487"></a><span class="lineno">  487</span>    </div>
<div class="foldopen" id="foldopen00488" data-start="{" data-end="}">
<div class="line"><a id="l00488" name="l00488"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Softmax.html#a62cc4acc056fbd4f8a365637e1159a9e">  488</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_function" href="classtensor4d_1_1nn_1_1Softmax.html#a62cc4acc056fbd4f8a365637e1159a9e">forward</a>(<span class="keyword">const</span> <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>&amp; input)<span class="keyword"> override </span>{</div>
<div class="line"><a id="l00489" name="l00489"></a><span class="lineno">  489</span>        <span class="keyword">auto</span> shape = input.<a class="code hl_function" href="classTensor.html#a80b3ffaf92ed36f02d6f4d4230b5d2a0">shape</a>();</div>
<div class="line"><a id="l00490" name="l00490"></a><span class="lineno">  490</span>        <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Softmax.html#ac1e254f8cb7a007b6ea0491024ceeead">output_</a> = <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>(shape);</div>
<div class="line"><a id="l00491" name="l00491"></a><span class="lineno">  491</span>        </div>
<div class="line"><a id="l00492" name="l00492"></a><span class="lineno">  492</span>        <span class="comment">// Compute softmax for each sample in batch</span></div>
<div class="line"><a id="l00493" name="l00493"></a><span class="lineno">  493</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; shape[0]; ++i) {</div>
<div class="line"><a id="l00494" name="l00494"></a><span class="lineno">  494</span>            <span class="comment">// Find max for numerical stability</span></div>
<div class="line"><a id="l00495" name="l00495"></a><span class="lineno">  495</span>            T max_val = input[{i, 0}];</div>
<div class="line"><a id="l00496" name="l00496"></a><span class="lineno">  496</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 1; j &lt; shape[1]; ++j) {</div>
<div class="line"><a id="l00497" name="l00497"></a><span class="lineno">  497</span>                <span class="keywordflow">if</span> (input[{i, j}] &gt; max_val) {</div>
<div class="line"><a id="l00498" name="l00498"></a><span class="lineno">  498</span>                    max_val = input[{i, j}];</div>
<div class="line"><a id="l00499" name="l00499"></a><span class="lineno">  499</span>                }</div>
<div class="line"><a id="l00500" name="l00500"></a><span class="lineno">  500</span>            }</div>
<div class="line"><a id="l00501" name="l00501"></a><span class="lineno">  501</span>            </div>
<div class="line"><a id="l00502" name="l00502"></a><span class="lineno">  502</span>            <span class="comment">// Compute exp and sum</span></div>
<div class="line"><a id="l00503" name="l00503"></a><span class="lineno">  503</span>            T sum = 0;</div>
<div class="line"><a id="l00504" name="l00504"></a><span class="lineno">  504</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; shape[1]; ++j) {</div>
<div class="line"><a id="l00505" name="l00505"></a><span class="lineno">  505</span>                <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Softmax.html#ac1e254f8cb7a007b6ea0491024ceeead">output_</a>[{i, j}] = std::exp(input[{i, j}] - max_val);</div>
<div class="line"><a id="l00506" name="l00506"></a><span class="lineno">  506</span>                sum += <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Softmax.html#ac1e254f8cb7a007b6ea0491024ceeead">output_</a>[{i, j}];</div>
<div class="line"><a id="l00507" name="l00507"></a><span class="lineno">  507</span>            }</div>
<div class="line"><a id="l00508" name="l00508"></a><span class="lineno">  508</span>            </div>
<div class="line"><a id="l00509" name="l00509"></a><span class="lineno">  509</span>            <span class="comment">// Normalize</span></div>
<div class="line"><a id="l00510" name="l00510"></a><span class="lineno">  510</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; shape[1]; ++j) {</div>
<div class="line"><a id="l00511" name="l00511"></a><span class="lineno">  511</span>                <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Softmax.html#ac1e254f8cb7a007b6ea0491024ceeead">output_</a>[{i, j}] /= sum;</div>
<div class="line"><a id="l00512" name="l00512"></a><span class="lineno">  512</span>            }</div>
<div class="line"><a id="l00513" name="l00513"></a><span class="lineno">  513</span>        }</div>
<div class="line"><a id="l00514" name="l00514"></a><span class="lineno">  514</span>        </div>
<div class="line"><a id="l00515" name="l00515"></a><span class="lineno">  515</span>        <span class="keywordflow">return</span> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Softmax.html#ac1e254f8cb7a007b6ea0491024ceeead">output_</a>;</div>
<div class="line"><a id="l00516" name="l00516"></a><span class="lineno">  516</span>    }</div>
</div>
<div class="line"><a id="l00517" name="l00517"></a><span class="lineno">  517</span>    </div>
<div class="foldopen" id="foldopen00518" data-start="{" data-end="}">
<div class="line"><a id="l00518" name="l00518"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Softmax.html#abda8fce936f0e7f02d1779a120db27de">  518</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_function" href="classtensor4d_1_1nn_1_1Softmax.html#abda8fce936f0e7f02d1779a120db27de">backward</a>(<span class="keyword">const</span> <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>&amp; grad_output)<span class="keyword"> override </span>{</div>
<div class="line"><a id="l00519" name="l00519"></a><span class="lineno">  519</span>        <span class="keyword">auto</span> shape = <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Softmax.html#ac1e254f8cb7a007b6ea0491024ceeead">output_</a>.shape();</div>
<div class="line"><a id="l00520" name="l00520"></a><span class="lineno">  520</span>        <span class="keyword">auto</span> grad_input = <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a>(shape);</div>
<div class="line"><a id="l00521" name="l00521"></a><span class="lineno">  521</span>        </div>
<div class="line"><a id="l00522" name="l00522"></a><span class="lineno">  522</span>        <span class="comment">// Jacobian of softmax is: S_i * (_ij - S_j)</span></div>
<div class="line"><a id="l00523" name="l00523"></a><span class="lineno">  523</span>        <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> i = 0; i &lt; shape[0]; ++i) {</div>
<div class="line"><a id="l00524" name="l00524"></a><span class="lineno">  524</span>            <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> j = 0; j &lt; shape[1]; ++j) {</div>
<div class="line"><a id="l00525" name="l00525"></a><span class="lineno">  525</span>                T sum = 0;</div>
<div class="line"><a id="l00526" name="l00526"></a><span class="lineno">  526</span>                <span class="keywordflow">for</span> (<span class="keywordtype">size_t</span> k = 0; k &lt; shape[1]; ++k) {</div>
<div class="line"><a id="l00527" name="l00527"></a><span class="lineno">  527</span>                    T delta = (j == k) ? 1.0 : 0.0;</div>
<div class="line"><a id="l00528" name="l00528"></a><span class="lineno">  528</span>                    sum += grad_output[{i, k}] * <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Softmax.html#ac1e254f8cb7a007b6ea0491024ceeead">output_</a>[{i, j}] * (delta - <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Softmax.html#ac1e254f8cb7a007b6ea0491024ceeead">output_</a>[{i, k}]);</div>
<div class="line"><a id="l00529" name="l00529"></a><span class="lineno">  529</span>                }</div>
<div class="line"><a id="l00530" name="l00530"></a><span class="lineno">  530</span>                grad_input[{i, j}] = sum;</div>
<div class="line"><a id="l00531" name="l00531"></a><span class="lineno">  531</span>            }</div>
<div class="line"><a id="l00532" name="l00532"></a><span class="lineno">  532</span>        }</div>
<div class="line"><a id="l00533" name="l00533"></a><span class="lineno">  533</span>        </div>
<div class="line"><a id="l00534" name="l00534"></a><span class="lineno">  534</span>        <span class="keywordflow">return</span> grad_input;</div>
<div class="line"><a id="l00535" name="l00535"></a><span class="lineno">  535</span>    }</div>
</div>
<div class="line"><a id="l00536" name="l00536"></a><span class="lineno">  536</span>    </div>
<div class="line"><a id="l00537" name="l00537"></a><span class="lineno">  537</span><span class="keyword">private</span>:</div>
<div class="line"><a id="l00538" name="l00538"></a><span class="lineno"><a class="line" href="classtensor4d_1_1nn_1_1Softmax.html#ac1e254f8cb7a007b6ea0491024ceeead">  538</a></span>    <a class="code hl_class" href="classTensor.html">Tensor&lt;T, 2&gt;</a> <a class="code hl_variable" href="classtensor4d_1_1nn_1_1Softmax.html#ac1e254f8cb7a007b6ea0491024ceeead">output_</a>;</div>
<div class="line"><a id="l00539" name="l00539"></a><span class="lineno">  539</span>};</div>
</div>
<div class="line"><a id="l00540" name="l00540"></a><span class="lineno">  540</span> </div>
<div class="line"><a id="l00541" name="l00541"></a><span class="lineno">  541</span><span class="comment">// Type aliases for convenience</span></div>
<div class="line"><a id="l00542" name="l00542"></a><span class="lineno"><a class="line" href="namespacetensor4d_1_1nn.html#aaf2467899756d1b58455dff42f976904">  542</a></span><span class="keyword">using </span><a class="code hl_typedef" href="namespacetensor4d_1_1nn.html#aaf2467899756d1b58455dff42f976904">Linearf</a> = <a class="code hl_class" href="classtensor4d_1_1nn_1_1Linear.html">Linear&lt;float&gt;</a>;</div>
<div class="line"><a id="l00543" name="l00543"></a><span class="lineno"><a class="line" href="namespacetensor4d_1_1nn.html#a762e1706124db702d93be5bb8b18e629">  543</a></span><span class="keyword">using </span><a class="code hl_typedef" href="namespacetensor4d_1_1nn.html#a762e1706124db702d93be5bb8b18e629">Lineard</a> = <a class="code hl_class" href="classtensor4d_1_1nn_1_1Linear.html">Linear&lt;double&gt;</a>;</div>
<div class="line"><a id="l00544" name="l00544"></a><span class="lineno"><a class="line" href="namespacetensor4d_1_1nn.html#ac63545216aad7e4be2c45c0b70509653">  544</a></span><span class="keyword">using </span><a class="code hl_typedef" href="namespacetensor4d_1_1nn.html#ac63545216aad7e4be2c45c0b70509653">ReLUf</a> = <a class="code hl_class" href="classtensor4d_1_1nn_1_1ReLU.html">ReLU&lt;float&gt;</a>;</div>
<div class="line"><a id="l00545" name="l00545"></a><span class="lineno"><a class="line" href="namespacetensor4d_1_1nn.html#ad4dcbd0157fcb32c118ed38f1f40c58f">  545</a></span><span class="keyword">using </span><a class="code hl_typedef" href="namespacetensor4d_1_1nn.html#ad4dcbd0157fcb32c118ed38f1f40c58f">ReLUd</a> = <a class="code hl_class" href="classtensor4d_1_1nn_1_1ReLU.html">ReLU&lt;double&gt;</a>;</div>
<div class="line"><a id="l00546" name="l00546"></a><span class="lineno"><a class="line" href="namespacetensor4d_1_1nn.html#a83ad7bb2795465463d3684533657dc45">  546</a></span><span class="keyword">using </span><a class="code hl_typedef" href="namespacetensor4d_1_1nn.html#a83ad7bb2795465463d3684533657dc45">Sigmoidf</a> = <a class="code hl_class" href="classtensor4d_1_1nn_1_1Sigmoid.html">Sigmoid&lt;float&gt;</a>;</div>
<div class="line"><a id="l00547" name="l00547"></a><span class="lineno"><a class="line" href="namespacetensor4d_1_1nn.html#a4d5c82c731007a58002b1973150bb7e5">  547</a></span><span class="keyword">using </span><a class="code hl_typedef" href="namespacetensor4d_1_1nn.html#a4d5c82c731007a58002b1973150bb7e5">Sigmoidd</a> = <a class="code hl_class" href="classtensor4d_1_1nn_1_1Sigmoid.html">Sigmoid&lt;double&gt;</a>;</div>
<div class="line"><a id="l00548" name="l00548"></a><span class="lineno"><a class="line" href="namespacetensor4d_1_1nn.html#a322020c52ad6d285a72c09a50ea4b467">  548</a></span><span class="keyword">using </span><a class="code hl_typedef" href="namespacetensor4d_1_1nn.html#a322020c52ad6d285a72c09a50ea4b467">Tanhf</a> = <a class="code hl_class" href="classtensor4d_1_1nn_1_1Tanh.html">Tanh&lt;float&gt;</a>;</div>
<div class="line"><a id="l00549" name="l00549"></a><span class="lineno"><a class="line" href="namespacetensor4d_1_1nn.html#a684fa7cf2cac6ab7b8d62edc2b1da9d6">  549</a></span><span class="keyword">using </span><a class="code hl_typedef" href="namespacetensor4d_1_1nn.html#a684fa7cf2cac6ab7b8d62edc2b1da9d6">Tanhd</a> = <a class="code hl_class" href="classtensor4d_1_1nn_1_1Tanh.html">Tanh&lt;double&gt;</a>;</div>
<div class="line"><a id="l00550" name="l00550"></a><span class="lineno"><a class="line" href="namespacetensor4d_1_1nn.html#a3315ab248317bf7d71c75b77ccc5f985">  550</a></span><span class="keyword">using </span><a class="code hl_typedef" href="namespacetensor4d_1_1nn.html#a3315ab248317bf7d71c75b77ccc5f985">Dropoutf</a> = <a class="code hl_class" href="classtensor4d_1_1nn_1_1Dropout.html">Dropout&lt;float&gt;</a>;</div>
<div class="line"><a id="l00551" name="l00551"></a><span class="lineno"><a class="line" href="namespacetensor4d_1_1nn.html#ac2f3327e85a4c471ec2f30634bde0928">  551</a></span><span class="keyword">using </span><a class="code hl_typedef" href="namespacetensor4d_1_1nn.html#ac2f3327e85a4c471ec2f30634bde0928">Dropoutd</a> = <a class="code hl_class" href="classtensor4d_1_1nn_1_1Dropout.html">Dropout&lt;double&gt;</a>;</div>
<div class="line"><a id="l00552" name="l00552"></a><span class="lineno"><a class="line" href="namespacetensor4d_1_1nn.html#add8e6f802c9d7c435a6c981f545a37f2">  552</a></span><span class="keyword">using </span><a class="code hl_typedef" href="namespacetensor4d_1_1nn.html#add8e6f802c9d7c435a6c981f545a37f2">BatchNorm1df</a> = <a class="code hl_class" href="classtensor4d_1_1nn_1_1BatchNorm1d.html">BatchNorm1d&lt;float&gt;</a>;</div>
<div class="line"><a id="l00553" name="l00553"></a><span class="lineno"><a class="line" href="namespacetensor4d_1_1nn.html#a676f9d19eb47312f01a5c2ef0262e300">  553</a></span><span class="keyword">using </span><a class="code hl_typedef" href="namespacetensor4d_1_1nn.html#a676f9d19eb47312f01a5c2ef0262e300">BatchNorm1dd</a> = <a class="code hl_class" href="classtensor4d_1_1nn_1_1BatchNorm1d.html">BatchNorm1d&lt;double&gt;</a>;</div>
<div class="line"><a id="l00554" name="l00554"></a><span class="lineno"><a class="line" href="namespacetensor4d_1_1nn.html#a227492f3cd887244ddf283565d4f5327">  554</a></span><span class="keyword">using </span><a class="code hl_typedef" href="namespacetensor4d_1_1nn.html#a227492f3cd887244ddf283565d4f5327">Softmaxf</a> = <a class="code hl_class" href="classtensor4d_1_1nn_1_1Softmax.html">Softmax&lt;float&gt;</a>;</div>
<div class="line"><a id="l00555" name="l00555"></a><span class="lineno"><a class="line" href="namespacetensor4d_1_1nn.html#a35558d36da40b43a93f6743d3aaf91eb">  555</a></span><span class="keyword">using </span><a class="code hl_typedef" href="namespacetensor4d_1_1nn.html#a35558d36da40b43a93f6743d3aaf91eb">Softmaxd</a> = <a class="code hl_class" href="classtensor4d_1_1nn_1_1Softmax.html">Softmax&lt;double&gt;</a>;</div>
<div class="line"><a id="l00556" name="l00556"></a><span class="lineno">  556</span> </div>
<div class="line"><a id="l00557" name="l00557"></a><span class="lineno">  557</span>} <span class="comment">// namespace nn</span></div>
</div>
<div class="line"><a id="l00558" name="l00558"></a><span class="lineno">  558</span>} <span class="comment">// namespace tensor4d</span></div>
</div>
<div class="line"><a id="l00559" name="l00559"></a><span class="lineno">  559</span> </div>
<div class="line"><a id="l00560" name="l00560"></a><span class="lineno">  560</span><span class="preprocessor">#endif </span><span class="comment">// NN_LAYERS_H</span></div>
<div class="ttc" id="aclassTensor_html"><div class="ttname"><a href="classTensor.html">Tensor</a></div><div class="ttdoc">Forward declaration for autograd.</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00444">tensor.h:444</a></div></div>
<div class="ttc" id="aclassTensor_html_a74db7588a7150d94b620ad63de1f5980"><div class="ttname"><a href="classTensor.html#a74db7588a7150d94b620ad63de1f5980">Tensor::relu</a></div><div class="ttdeci">Tensor&lt; T, N &gt; relu() const</div><div class="ttdoc">Apply ReLU (Rectified Linear Unit) to all elements (creates new tensor).</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l01857">tensor.h:1857</a></div></div>
<div class="ttc" id="aclassTensor_html_a80b3ffaf92ed36f02d6f4d4230b5d2a0"><div class="ttname"><a href="classTensor.html#a80b3ffaf92ed36f02d6f4d4230b5d2a0">Tensor::shape</a></div><div class="ttdeci">TensorIndices&lt; N &gt; shape() const</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l00650">tensor.h:650</a></div></div>
<div class="ttc" id="aclassTensor_html_a88d5a081d321cbd88ca46ed42ca1112c"><div class="ttname"><a href="classTensor.html#a88d5a081d321cbd88ca46ed42ca1112c">Tensor::matmul</a></div><div class="ttdeci">std::enable_if&lt; M==2, TensorResult&lt; Tensor&lt; T, 2 &gt; &gt; &gt;::type matmul(const Tensor&lt; T, 2 &gt; &amp;other) const</div><div class="ttdoc">Matrix multiplication with autograd support (matmul).</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l03406">tensor.h:3406</a></div></div>
<div class="ttc" id="aclassTensor_html_adcc5341aa2156f24c0f4069543c958e1"><div class="ttname"><a href="classTensor.html#adcc5341aa2156f24c0f4069543c958e1">Tensor::tanh</a></div><div class="ttdeci">Tensor&lt; T, N &gt; tanh() const</div><div class="ttdoc">Apply hyperbolic tangent (tanh) to all elements (creates new tensor).</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l01734">tensor.h:1734</a></div></div>
<div class="ttc" id="aclassTensor_html_aed9419fabd015e2c1c35ff6723c1600a"><div class="ttname"><a href="classTensor.html#aed9419fabd015e2c1c35ff6723c1600a">Tensor::transpose</a></div><div class="ttdeci">Tensor&lt; T, N &gt; transpose() const</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l04004">tensor.h:4004</a></div></div>
<div class="ttc" id="aclassTensor_html_afff455663faa35d6cfa72aa03f689e94"><div class="ttname"><a href="classTensor.html#afff455663faa35d6cfa72aa03f689e94">Tensor::sigmoid</a></div><div class="ttdeci">Tensor&lt; T, N &gt; sigmoid() const</div><div class="ttdoc">Apply sigmoid function to all elements (creates new tensor).</div><div class="ttdef"><b>Definition</b> <a href="tensor_8h_source.html#l01778">tensor.h:1778</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1BatchNorm1d_html"><div class="ttname"><a href="classtensor4d_1_1nn_1_1BatchNorm1d.html">tensor4d::nn::BatchNorm1d</a></div><div class="ttdoc">Batch Normalization layer.</div><div class="ttdef"><b>Definition</b> <a href="#l00342">nn_layers.h:342</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1BatchNorm1d_html_a00a6dc7b408c9edaf7072301c75b4ccf"><div class="ttname"><a href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a00a6dc7b408c9edaf7072301c75b4ccf">tensor4d::nn::BatchNorm1d::parameters</a></div><div class="ttdeci">std::vector&lt; Tensor&lt; T, 2 &gt; * &gt; parameters() override</div><div class="ttdoc">Get trainable parameters.</div><div class="ttdef"><b>Definition</b> <a href="#l00459">nn_layers.h:459</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1BatchNorm1d_html_a06aa43a886c3349131e4cec95a847a5e"><div class="ttname"><a href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a06aa43a886c3349131e4cec95a847a5e">tensor4d::nn::BatchNorm1d::beta_</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; beta_</div><div class="ttdef"><b>Definition</b> <a href="#l00469">nn_layers.h:469</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1BatchNorm1d_html_a20ef166dce9b80f2697e645af2bb451e"><div class="ttname"><a href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a20ef166dce9b80f2697e645af2bb451e">tensor4d::nn::BatchNorm1d::input_</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; input_</div><div class="ttdef"><b>Definition</b> <a href="#l00474">nn_layers.h:474</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1BatchNorm1d_html_a2775a2774d8a6c4216b4cf2c5691335b"><div class="ttname"><a href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a2775a2774d8a6c4216b4cf2c5691335b">tensor4d::nn::BatchNorm1d::BatchNorm1d</a></div><div class="ttdeci">BatchNorm1d(size_t num_features, T eps=1e-5, T momentum=0.1)</div><div class="ttdoc">Construct batch normalization layer.</div><div class="ttdef"><b>Definition</b> <a href="#l00350">nn_layers.h:350</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1BatchNorm1d_html_a2c9cea8478dc951c47bc95c219e87db1"><div class="ttname"><a href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a2c9cea8478dc951c47bc95c219e87db1">tensor4d::nn::BatchNorm1d&lt; float &gt;::num_features_</a></div><div class="ttdeci">size_t num_features_</div><div class="ttdef"><b>Definition</b> <a href="#l00464">nn_layers.h:464</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1BatchNorm1d_html_a311f849757fe8d8f70cfd55ce896b5da"><div class="ttname"><a href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a311f849757fe8d8f70cfd55ce896b5da">tensor4d::nn::BatchNorm1d&lt; float &gt;::gamma_</a></div><div class="ttdeci">Tensor&lt; float, 2 &gt; gamma_</div><div class="ttdef"><b>Definition</b> <a href="#l00468">nn_layers.h:468</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1BatchNorm1d_html_a3ba4cd0f7addeb22751af6893a23491f"><div class="ttname"><a href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a3ba4cd0f7addeb22751af6893a23491f">tensor4d::nn::BatchNorm1d::grad_gamma_</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; grad_gamma_</div><div class="ttdef"><b>Definition</b> <a href="#l00476">nn_layers.h:476</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1BatchNorm1d_html_a48ea5fa069810067b9756e3d24b48b73"><div class="ttname"><a href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a48ea5fa069810067b9756e3d24b48b73">tensor4d::nn::BatchNorm1d::backward</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; backward(const Tensor&lt; T, 2 &gt; &amp;grad_output) override</div><div class="ttdoc">Backward pass (gradient computation).</div><div class="ttdef"><b>Definition</b> <a href="#l00429">nn_layers.h:429</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1BatchNorm1d_html_a5615d826982a2f132397419ca7881609"><div class="ttname"><a href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a5615d826982a2f132397419ca7881609">tensor4d::nn::BatchNorm1d&lt; float &gt;::momentum_</a></div><div class="ttdeci">float momentum_</div><div class="ttdef"><b>Definition</b> <a href="#l00466">nn_layers.h:466</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1BatchNorm1d_html_a5804439c12b21f719bdab6b8bac01fdc"><div class="ttname"><a href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a5804439c12b21f719bdab6b8bac01fdc">tensor4d::nn::BatchNorm1d::running_mean_</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; running_mean_</div><div class="ttdef"><b>Definition</b> <a href="#l00470">nn_layers.h:470</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1BatchNorm1d_html_a66a9964817b54848afc8b46d7367207d"><div class="ttname"><a href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a66a9964817b54848afc8b46d7367207d">tensor4d::nn::BatchNorm1d&lt; float &gt;::eps_</a></div><div class="ttdeci">float eps_</div><div class="ttdef"><b>Definition</b> <a href="#l00465">nn_layers.h:465</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1BatchNorm1d_html_a8295c6940c580ef2aed68f78099c7698"><div class="ttname"><a href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a8295c6940c580ef2aed68f78099c7698">tensor4d::nn::BatchNorm1d::grad_beta_</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; grad_beta_</div><div class="ttdef"><b>Definition</b> <a href="#l00477">nn_layers.h:477</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1BatchNorm1d_html_a8e589b2051e3a2c38b1a0feccc33bdb2"><div class="ttname"><a href="classtensor4d_1_1nn_1_1BatchNorm1d.html#a8e589b2051e3a2c38b1a0feccc33bdb2">tensor4d::nn::BatchNorm1d::forward</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; forward(const Tensor&lt; T, 2 &gt; &amp;input) override</div><div class="ttdoc">Forward pass through the layer.</div><div class="ttdef"><b>Definition</b> <a href="#l00369">nn_layers.h:369</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1BatchNorm1d_html_ac9f443c1167f9978a0ab6a0dc97f02b2"><div class="ttname"><a href="classtensor4d_1_1nn_1_1BatchNorm1d.html#ac9f443c1167f9978a0ab6a0dc97f02b2">tensor4d::nn::BatchNorm1d::input_normalized_</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; input_normalized_</div><div class="ttdef"><b>Definition</b> <a href="#l00475">nn_layers.h:475</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1BatchNorm1d_html_ae56fd1f24787c14016e2fb0f14719b65"><div class="ttname"><a href="classtensor4d_1_1nn_1_1BatchNorm1d.html#ae56fd1f24787c14016e2fb0f14719b65">tensor4d::nn::BatchNorm1d::batch_mean_</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; batch_mean_</div><div class="ttdef"><b>Definition</b> <a href="#l00472">nn_layers.h:472</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1BatchNorm1d_html_af4cb5a26201a5cb84493fd4ade774989"><div class="ttname"><a href="classtensor4d_1_1nn_1_1BatchNorm1d.html#af4cb5a26201a5cb84493fd4ade774989">tensor4d::nn::BatchNorm1d::batch_var_</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; batch_var_</div><div class="ttdef"><b>Definition</b> <a href="#l00473">nn_layers.h:473</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1BatchNorm1d_html_afeec797fa0b23c42329aecb063a826b4"><div class="ttname"><a href="classtensor4d_1_1nn_1_1BatchNorm1d.html#afeec797fa0b23c42329aecb063a826b4">tensor4d::nn::BatchNorm1d::running_var_</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; running_var_</div><div class="ttdef"><b>Definition</b> <a href="#l00471">nn_layers.h:471</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Dropout_html"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Dropout.html">tensor4d::nn::Dropout</a></div><div class="ttdoc">Dropout layer for regularization.</div><div class="ttdef"><b>Definition</b> <a href="#l00278">nn_layers.h:278</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Dropout_html_a156bdcf7dd306241dfc47d6224c08b1c"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Dropout.html#a156bdcf7dd306241dfc47d6224c08b1c">tensor4d::nn::Dropout&lt; float &gt;::mask_</a></div><div class="ttdeci">Tensor&lt; float, 2 &gt; mask_</div><div class="ttdef"><b>Definition</b> <a href="#l00335">nn_layers.h:335</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Dropout_html_ad7713d85865e3238e14e920b47f44237"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Dropout.html#ad7713d85865e3238e14e920b47f44237">tensor4d::nn::Dropout::backward</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; backward(const Tensor&lt; T, 2 &gt; &amp;grad_output) override</div><div class="ttdoc">Backward pass (gradient computation).</div><div class="ttdef"><b>Definition</b> <a href="#l00316">nn_layers.h:316</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Dropout_html_add8163856fcd8550fc2d2bdbafdf7115"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Dropout.html#add8163856fcd8550fc2d2bdbafdf7115">tensor4d::nn::Dropout&lt; float &gt;::p_</a></div><div class="ttdeci">float p_</div><div class="ttdef"><b>Definition</b> <a href="#l00334">nn_layers.h:334</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Dropout_html_aea77c1d5fe4c7acaa55174fde51883c5"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Dropout.html#aea77c1d5fe4c7acaa55174fde51883c5">tensor4d::nn::Dropout::Dropout</a></div><div class="ttdeci">Dropout(T p=0.5)</div><div class="ttdoc">Construct dropout layer.</div><div class="ttdef"><b>Definition</b> <a href="#l00284">nn_layers.h:284</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Dropout_html_aff0f87aa27d1aceca0bbcc6b0655ce24"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Dropout.html#aff0f87aa27d1aceca0bbcc6b0655ce24">tensor4d::nn::Dropout::forward</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; forward(const Tensor&lt; T, 2 &gt; &amp;input) override</div><div class="ttdoc">Forward pass through the layer.</div><div class="ttdef"><b>Definition</b> <a href="#l00290">nn_layers.h:290</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Layer_html"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Layer.html">tensor4d::nn::Layer</a></div><div class="ttdoc">Base class for all neural network layers.</div><div class="ttdef"><b>Definition</b> <a href="#l00029">nn_layers.h:29</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Layer_html_a2d171fcf4e726e2bd0f6c9399288436b"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Layer.html#a2d171fcf4e726e2bd0f6c9399288436b">tensor4d::nn::Layer::forward</a></div><div class="ttdeci">virtual Tensor&lt; T, 2 &gt; forward(const Tensor&lt; T, 2 &gt; &amp;input)=0</div><div class="ttdoc">Forward pass through the layer.</div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Layer_html_a3d9932a950faa4534cc8c468c9152f22"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Layer.html#a3d9932a950faa4534cc8c468c9152f22">tensor4d::nn::Layer::backward</a></div><div class="ttdeci">virtual Tensor&lt; T, 2 &gt; backward(const Tensor&lt; T, 2 &gt; &amp;grad_output)=0</div><div class="ttdoc">Backward pass (gradient computation).</div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Layer_html_a5046b1e468f41cc660af5f541be017d6"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Layer.html#a5046b1e468f41cc660af5f541be017d6">tensor4d::nn::Layer::training_</a></div><div class="ttdeci">bool training_</div><div class="ttdef"><b>Definition</b> <a href="#l00065">nn_layers.h:65</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Layer_html_a5a29143edf7136c7a3d944846f23d05d"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Layer.html#a5a29143edf7136c7a3d944846f23d05d">tensor4d::nn::Layer::parameters</a></div><div class="ttdeci">virtual std::vector&lt; Tensor&lt; T, 2 &gt; * &gt; parameters()</div><div class="ttdoc">Get trainable parameters.</div><div class="ttdef"><b>Definition</b> <a href="#l00051">nn_layers.h:51</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Layer_html_a9f069156fc18ad5035bcfa99ddfdda83"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Layer.html#a9f069156fc18ad5035bcfa99ddfdda83">tensor4d::nn::Layer::train</a></div><div class="ttdeci">virtual void train(bool mode=true)</div><div class="ttdoc">Set training mode.</div><div class="ttdef"><b>Definition</b> <a href="#l00057">nn_layers.h:57</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Layer_html_aabd4feffefbe1a92d584484413289a05"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Layer.html#aabd4feffefbe1a92d584484413289a05">tensor4d::nn::Layer::~Layer</a></div><div class="ttdeci">virtual ~Layer()=default</div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Layer_html_ae5d280d927fb2b5757ae8de43af64a79"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Layer.html#ae5d280d927fb2b5757ae8de43af64a79">tensor4d::nn::Layer::is_training</a></div><div class="ttdeci">bool is_training() const</div><div class="ttdoc">Check if layer is in training mode.</div><div class="ttdef"><b>Definition</b> <a href="#l00062">nn_layers.h:62</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Linear_html"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Linear.html">tensor4d::nn::Linear</a></div><div class="ttdoc">Linear (Dense/Fully Connected) layer.</div><div class="ttdef"><b>Definition</b> <a href="#l00074">nn_layers.h:74</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Linear_html_a08cc48c658f333a45ca0ea084f69ec54"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Linear.html#a08cc48c658f333a45ca0ea084f69ec54">tensor4d::nn::Linear::weights</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; &amp; weights()</div><div class="ttdef"><b>Definition</b> <a href="#l00162">nn_layers.h:162</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Linear_html_a0af1f08655e4b88cc7adc4e7d8a323e3"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Linear.html#a0af1f08655e4b88cc7adc4e7d8a323e3">tensor4d::nn::Linear::forward</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; forward(const Tensor&lt; T, 2 &gt; &amp;input) override</div><div class="ttdoc">Forward pass through the layer.</div><div class="ttdef"><b>Definition</b> <a href="#l00108">nn_layers.h:108</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Linear_html_a0fab0d83bb52b8ed52b9d4679f5a4ead"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Linear.html#a0fab0d83bb52b8ed52b9d4679f5a4ead">tensor4d::nn::Linear::grad_weights</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; &amp; grad_weights()</div><div class="ttdef"><b>Definition</b> <a href="#l00164">nn_layers.h:164</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Linear_html_a24f7dbc86ee05b08278886cf1e8bf357"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Linear.html#a24f7dbc86ee05b08278886cf1e8bf357">tensor4d::nn::Linear::grad_bias</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; &amp; grad_bias()</div><div class="ttdef"><b>Definition</b> <a href="#l00165">nn_layers.h:165</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Linear_html_a3f45dfd88be3f8cb6348b6dc317ebc4a"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Linear.html#a3f45dfd88be3f8cb6348b6dc317ebc4a">tensor4d::nn::Linear&lt; float &gt;::use_bias_</a></div><div class="ttdeci">bool use_bias_</div><div class="ttdef"><b>Definition</b> <a href="#l00170">nn_layers.h:170</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Linear_html_a5364162aed6bb8c7758d88142ac74c1b"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Linear.html#a5364162aed6bb8c7758d88142ac74c1b">tensor4d::nn::Linear::backward</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; backward(const Tensor&lt; T, 2 &gt; &amp;grad_output) override</div><div class="ttdoc">Backward pass (gradient computation).</div><div class="ttdef"><b>Definition</b> <a href="#l00129">nn_layers.h:129</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Linear_html_a6e7fab012ef8b37597f46e3c82694df4"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Linear.html#a6e7fab012ef8b37597f46e3c82694df4">tensor4d::nn::Linear::grad_weights_</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; grad_weights_</div><div class="ttdef"><b>Definition</b> <a href="#l00175">nn_layers.h:175</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Linear_html_a794be1290e09a38a6daad16f19aa7126"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Linear.html#a794be1290e09a38a6daad16f19aa7126">tensor4d::nn::Linear&lt; float &gt;::weights_</a></div><div class="ttdeci">Tensor&lt; float, 2 &gt; weights_</div><div class="ttdef"><b>Definition</b> <a href="#l00172">nn_layers.h:172</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Linear_html_a7e262da58b4b499b6eeab66bdd6f84c5"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Linear.html#a7e262da58b4b499b6eeab66bdd6f84c5">tensor4d::nn::Linear&lt; float &gt;::in_features_</a></div><div class="ttdeci">size_t in_features_</div><div class="ttdef"><b>Definition</b> <a href="#l00168">nn_layers.h:168</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Linear_html_a873ae71e9bf64f75ab818dc40c32442e"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Linear.html#a873ae71e9bf64f75ab818dc40c32442e">tensor4d::nn::Linear&lt; float &gt;::out_features_</a></div><div class="ttdeci">size_t out_features_</div><div class="ttdef"><b>Definition</b> <a href="#l00169">nn_layers.h:169</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Linear_html_a9af9fd6d9d5322f77ce1297c3edb82c7"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Linear.html#a9af9fd6d9d5322f77ce1297c3edb82c7">tensor4d::nn::Linear::input_</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; input_</div><div class="ttdef"><b>Definition</b> <a href="#l00174">nn_layers.h:174</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Linear_html_aa0fab014d4634b17ea27cda3e120d238"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Linear.html#aa0fab014d4634b17ea27cda3e120d238">tensor4d::nn::Linear::parameters</a></div><div class="ttdeci">std::vector&lt; Tensor&lt; T, 2 &gt; * &gt; parameters() override</div><div class="ttdoc">Get trainable parameters.</div><div class="ttdef"><b>Definition</b> <a href="#l00153">nn_layers.h:153</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Linear_html_aa24e546b58f66fc945024eb35e5d20f2"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Linear.html#aa24e546b58f66fc945024eb35e5d20f2">tensor4d::nn::Linear::grad_bias_</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; grad_bias_</div><div class="ttdef"><b>Definition</b> <a href="#l00176">nn_layers.h:176</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Linear_html_aea284ce51288593c283f10f739ae1696"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Linear.html#aea284ce51288593c283f10f739ae1696">tensor4d::nn::Linear::bias_</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; bias_</div><div class="ttdef"><b>Definition</b> <a href="#l00173">nn_layers.h:173</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Linear_html_af3a3fecbb2390303fc899b9b2285ea24"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Linear.html#af3a3fecbb2390303fc899b9b2285ea24">tensor4d::nn::Linear::Linear</a></div><div class="ttdeci">Linear(size_t in_features, size_t out_features, bool use_bias=true)</div><div class="ttdoc">Construct a linear layer.</div><div class="ttdef"><b>Definition</b> <a href="#l00082">nn_layers.h:82</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Linear_html_afefc9f73184487c8cb0abb37641a6932"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Linear.html#afefc9f73184487c8cb0abb37641a6932">tensor4d::nn::Linear::bias</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; &amp; bias()</div><div class="ttdef"><b>Definition</b> <a href="#l00163">nn_layers.h:163</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1ReLU_html"><div class="ttname"><a href="classtensor4d_1_1nn_1_1ReLU.html">tensor4d::nn::ReLU</a></div><div class="ttdoc">ReLU activation layer.</div><div class="ttdef"><b>Definition</b> <a href="#l00183">nn_layers.h:183</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1ReLU_html_a07b3b9bee90208e9510c4cc740639689"><div class="ttname"><a href="classtensor4d_1_1nn_1_1ReLU.html#a07b3b9bee90208e9510c4cc740639689">tensor4d::nn::ReLU::forward</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; forward(const Tensor&lt; T, 2 &gt; &amp;input) override</div><div class="ttdoc">Forward pass through the layer.</div><div class="ttdef"><b>Definition</b> <a href="#l00187">nn_layers.h:187</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1ReLU_html_a30f2eabf132b2de1b31ff67d0ad1a5c5"><div class="ttname"><a href="classtensor4d_1_1nn_1_1ReLU.html#a30f2eabf132b2de1b31ff67d0ad1a5c5">tensor4d::nn::ReLU&lt; float &gt;::input_</a></div><div class="ttdeci">Tensor&lt; float, 2 &gt; input_</div><div class="ttdef"><b>Definition</b> <a href="#l00207">nn_layers.h:207</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1ReLU_html_ac991c01d3b1607d533183075fb02f354"><div class="ttname"><a href="classtensor4d_1_1nn_1_1ReLU.html#ac991c01d3b1607d533183075fb02f354">tensor4d::nn::ReLU::backward</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; backward(const Tensor&lt; T, 2 &gt; &amp;grad_output) override</div><div class="ttdoc">Backward pass (gradient computation).</div><div class="ttdef"><b>Definition</b> <a href="#l00192">nn_layers.h:192</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1ReLU_html_aed0a602218dd422544cdf5ca46f6d056"><div class="ttname"><a href="classtensor4d_1_1nn_1_1ReLU.html#aed0a602218dd422544cdf5ca46f6d056">tensor4d::nn::ReLU::ReLU</a></div><div class="ttdeci">ReLU()</div><div class="ttdef"><b>Definition</b> <a href="#l00185">nn_layers.h:185</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Sigmoid_html"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Sigmoid.html">tensor4d::nn::Sigmoid</a></div><div class="ttdoc">Sigmoid activation layer.</div><div class="ttdef"><b>Definition</b> <a href="#l00214">nn_layers.h:214</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Sigmoid_html_a41e695161d280883a0002fe199efdf98"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Sigmoid.html#a41e695161d280883a0002fe199efdf98">tensor4d::nn::Sigmoid::backward</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; backward(const Tensor&lt; T, 2 &gt; &amp;grad_output) override</div><div class="ttdoc">Backward pass (gradient computation).</div><div class="ttdef"><b>Definition</b> <a href="#l00223">nn_layers.h:223</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Sigmoid_html_a5bde4d78573f5ea7c6c5e4d624bda3fb"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Sigmoid.html#a5bde4d78573f5ea7c6c5e4d624bda3fb">tensor4d::nn::Sigmoid::forward</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; forward(const Tensor&lt; T, 2 &gt; &amp;input) override</div><div class="ttdoc">Forward pass through the layer.</div><div class="ttdef"><b>Definition</b> <a href="#l00218">nn_layers.h:218</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Sigmoid_html_a7a699853be0806bf11af345641f690fd"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Sigmoid.html#a7a699853be0806bf11af345641f690fd">tensor4d::nn::Sigmoid::Sigmoid</a></div><div class="ttdeci">Sigmoid()</div><div class="ttdef"><b>Definition</b> <a href="#l00216">nn_layers.h:216</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Sigmoid_html_aa8058b771d3d30a043d853026cfa06ea"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Sigmoid.html#aa8058b771d3d30a043d853026cfa06ea">tensor4d::nn::Sigmoid&lt; float &gt;::output_</a></div><div class="ttdeci">Tensor&lt; float, 2 &gt; output_</div><div class="ttdef"><b>Definition</b> <a href="#l00239">nn_layers.h:239</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Softmax_html"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Softmax.html">tensor4d::nn::Softmax</a></div><div class="ttdoc">Softmax activation layer.</div><div class="ttdef"><b>Definition</b> <a href="#l00484">nn_layers.h:484</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Softmax_html_a62cc4acc056fbd4f8a365637e1159a9e"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Softmax.html#a62cc4acc056fbd4f8a365637e1159a9e">tensor4d::nn::Softmax::forward</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; forward(const Tensor&lt; T, 2 &gt; &amp;input) override</div><div class="ttdoc">Forward pass through the layer.</div><div class="ttdef"><b>Definition</b> <a href="#l00488">nn_layers.h:488</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Softmax_html_aa600157567a716269b66a30f701921d5"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Softmax.html#aa600157567a716269b66a30f701921d5">tensor4d::nn::Softmax::Softmax</a></div><div class="ttdeci">Softmax()</div><div class="ttdef"><b>Definition</b> <a href="#l00486">nn_layers.h:486</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Softmax_html_abda8fce936f0e7f02d1779a120db27de"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Softmax.html#abda8fce936f0e7f02d1779a120db27de">tensor4d::nn::Softmax::backward</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; backward(const Tensor&lt; T, 2 &gt; &amp;grad_output) override</div><div class="ttdoc">Backward pass (gradient computation).</div><div class="ttdef"><b>Definition</b> <a href="#l00518">nn_layers.h:518</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Softmax_html_ac1e254f8cb7a007b6ea0491024ceeead"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Softmax.html#ac1e254f8cb7a007b6ea0491024ceeead">tensor4d::nn::Softmax&lt; float &gt;::output_</a></div><div class="ttdeci">Tensor&lt; float, 2 &gt; output_</div><div class="ttdef"><b>Definition</b> <a href="#l00538">nn_layers.h:538</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Tanh_html"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Tanh.html">tensor4d::nn::Tanh</a></div><div class="ttdoc">Tanh activation layer.</div><div class="ttdef"><b>Definition</b> <a href="#l00246">nn_layers.h:246</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Tanh_html_a0e1b8dd43bc9599b91da6a6beba02e22"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Tanh.html#a0e1b8dd43bc9599b91da6a6beba02e22">tensor4d::nn::Tanh::Tanh</a></div><div class="ttdeci">Tanh()</div><div class="ttdef"><b>Definition</b> <a href="#l00248">nn_layers.h:248</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Tanh_html_a5bf1911c8b5865f171c90efbefbbe437"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Tanh.html#a5bf1911c8b5865f171c90efbefbbe437">tensor4d::nn::Tanh::forward</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; forward(const Tensor&lt; T, 2 &gt; &amp;input) override</div><div class="ttdoc">Forward pass through the layer.</div><div class="ttdef"><b>Definition</b> <a href="#l00250">nn_layers.h:250</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Tanh_html_a657c2dab547dc900fda0a86818ea1172"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Tanh.html#a657c2dab547dc900fda0a86818ea1172">tensor4d::nn::Tanh&lt; float &gt;::output_</a></div><div class="ttdeci">Tensor&lt; float, 2 &gt; output_</div><div class="ttdef"><b>Definition</b> <a href="#l00271">nn_layers.h:271</a></div></div>
<div class="ttc" id="aclasstensor4d_1_1nn_1_1Tanh_html_a8211c640d2b962ecad7a5c29203e663c"><div class="ttname"><a href="classtensor4d_1_1nn_1_1Tanh.html#a8211c640d2b962ecad7a5c29203e663c">tensor4d::nn::Tanh::backward</a></div><div class="ttdeci">Tensor&lt; T, 2 &gt; backward(const Tensor&lt; T, 2 &gt; &amp;grad_output) override</div><div class="ttdoc">Backward pass (gradient computation).</div><div class="ttdef"><b>Definition</b> <a href="#l00255">nn_layers.h:255</a></div></div>
<div class="ttc" id="anamespacetensor4d_1_1nn_html"><div class="ttname"><a href="namespacetensor4d_1_1nn.html">tensor4d::nn</a></div><div class="ttdef"><b>Definition</b> <a href="#l00019">nn_layers.h:19</a></div></div>
<div class="ttc" id="anamespacetensor4d_1_1nn_html_a227492f3cd887244ddf283565d4f5327"><div class="ttname"><a href="namespacetensor4d_1_1nn.html#a227492f3cd887244ddf283565d4f5327">tensor4d::nn::Softmaxf</a></div><div class="ttdeci">Softmax&lt; float &gt; Softmaxf</div><div class="ttdef"><b>Definition</b> <a href="#l00554">nn_layers.h:554</a></div></div>
<div class="ttc" id="anamespacetensor4d_1_1nn_html_a322020c52ad6d285a72c09a50ea4b467"><div class="ttname"><a href="namespacetensor4d_1_1nn.html#a322020c52ad6d285a72c09a50ea4b467">tensor4d::nn::Tanhf</a></div><div class="ttdeci">Tanh&lt; float &gt; Tanhf</div><div class="ttdef"><b>Definition</b> <a href="#l00548">nn_layers.h:548</a></div></div>
<div class="ttc" id="anamespacetensor4d_1_1nn_html_a3315ab248317bf7d71c75b77ccc5f985"><div class="ttname"><a href="namespacetensor4d_1_1nn.html#a3315ab248317bf7d71c75b77ccc5f985">tensor4d::nn::Dropoutf</a></div><div class="ttdeci">Dropout&lt; float &gt; Dropoutf</div><div class="ttdef"><b>Definition</b> <a href="#l00550">nn_layers.h:550</a></div></div>
<div class="ttc" id="anamespacetensor4d_1_1nn_html_a35558d36da40b43a93f6743d3aaf91eb"><div class="ttname"><a href="namespacetensor4d_1_1nn.html#a35558d36da40b43a93f6743d3aaf91eb">tensor4d::nn::Softmaxd</a></div><div class="ttdeci">Softmax&lt; double &gt; Softmaxd</div><div class="ttdef"><b>Definition</b> <a href="#l00555">nn_layers.h:555</a></div></div>
<div class="ttc" id="anamespacetensor4d_1_1nn_html_a4d5c82c731007a58002b1973150bb7e5"><div class="ttname"><a href="namespacetensor4d_1_1nn.html#a4d5c82c731007a58002b1973150bb7e5">tensor4d::nn::Sigmoidd</a></div><div class="ttdeci">Sigmoid&lt; double &gt; Sigmoidd</div><div class="ttdef"><b>Definition</b> <a href="#l00547">nn_layers.h:547</a></div></div>
<div class="ttc" id="anamespacetensor4d_1_1nn_html_a676f9d19eb47312f01a5c2ef0262e300"><div class="ttname"><a href="namespacetensor4d_1_1nn.html#a676f9d19eb47312f01a5c2ef0262e300">tensor4d::nn::BatchNorm1dd</a></div><div class="ttdeci">BatchNorm1d&lt; double &gt; BatchNorm1dd</div><div class="ttdef"><b>Definition</b> <a href="#l00553">nn_layers.h:553</a></div></div>
<div class="ttc" id="anamespacetensor4d_1_1nn_html_a684fa7cf2cac6ab7b8d62edc2b1da9d6"><div class="ttname"><a href="namespacetensor4d_1_1nn.html#a684fa7cf2cac6ab7b8d62edc2b1da9d6">tensor4d::nn::Tanhd</a></div><div class="ttdeci">Tanh&lt; double &gt; Tanhd</div><div class="ttdef"><b>Definition</b> <a href="#l00549">nn_layers.h:549</a></div></div>
<div class="ttc" id="anamespacetensor4d_1_1nn_html_a762e1706124db702d93be5bb8b18e629"><div class="ttname"><a href="namespacetensor4d_1_1nn.html#a762e1706124db702d93be5bb8b18e629">tensor4d::nn::Lineard</a></div><div class="ttdeci">Linear&lt; double &gt; Lineard</div><div class="ttdef"><b>Definition</b> <a href="#l00543">nn_layers.h:543</a></div></div>
<div class="ttc" id="anamespacetensor4d_1_1nn_html_a83ad7bb2795465463d3684533657dc45"><div class="ttname"><a href="namespacetensor4d_1_1nn.html#a83ad7bb2795465463d3684533657dc45">tensor4d::nn::Sigmoidf</a></div><div class="ttdeci">Sigmoid&lt; float &gt; Sigmoidf</div><div class="ttdef"><b>Definition</b> <a href="#l00546">nn_layers.h:546</a></div></div>
<div class="ttc" id="anamespacetensor4d_1_1nn_html_aaf2467899756d1b58455dff42f976904"><div class="ttname"><a href="namespacetensor4d_1_1nn.html#aaf2467899756d1b58455dff42f976904">tensor4d::nn::Linearf</a></div><div class="ttdeci">Linear&lt; float &gt; Linearf</div><div class="ttdef"><b>Definition</b> <a href="#l00542">nn_layers.h:542</a></div></div>
<div class="ttc" id="anamespacetensor4d_1_1nn_html_ac2f3327e85a4c471ec2f30634bde0928"><div class="ttname"><a href="namespacetensor4d_1_1nn.html#ac2f3327e85a4c471ec2f30634bde0928">tensor4d::nn::Dropoutd</a></div><div class="ttdeci">Dropout&lt; double &gt; Dropoutd</div><div class="ttdef"><b>Definition</b> <a href="#l00551">nn_layers.h:551</a></div></div>
<div class="ttc" id="anamespacetensor4d_1_1nn_html_ac63545216aad7e4be2c45c0b70509653"><div class="ttname"><a href="namespacetensor4d_1_1nn.html#ac63545216aad7e4be2c45c0b70509653">tensor4d::nn::ReLUf</a></div><div class="ttdeci">ReLU&lt; float &gt; ReLUf</div><div class="ttdef"><b>Definition</b> <a href="#l00544">nn_layers.h:544</a></div></div>
<div class="ttc" id="anamespacetensor4d_1_1nn_html_ad4dcbd0157fcb32c118ed38f1f40c58f"><div class="ttname"><a href="namespacetensor4d_1_1nn.html#ad4dcbd0157fcb32c118ed38f1f40c58f">tensor4d::nn::ReLUd</a></div><div class="ttdeci">ReLU&lt; double &gt; ReLUd</div><div class="ttdef"><b>Definition</b> <a href="#l00545">nn_layers.h:545</a></div></div>
<div class="ttc" id="anamespacetensor4d_1_1nn_html_add8e6f802c9d7c435a6c981f545a37f2"><div class="ttname"><a href="namespacetensor4d_1_1nn.html#add8e6f802c9d7c435a6c981f545a37f2">tensor4d::nn::BatchNorm1df</a></div><div class="ttdeci">BatchNorm1d&lt; float &gt; BatchNorm1df</div><div class="ttdef"><b>Definition</b> <a href="#l00552">nn_layers.h:552</a></div></div>
<div class="ttc" id="anamespacetensor4d_html"><div class="ttname"><a href="namespacetensor4d.html">tensor4d</a></div><div class="ttdef"><b>Definition</b> <a href="#l00018">nn_layers.h:18</a></div></div>
<div class="ttc" id="atensor_8h_html"><div class="ttname"><a href="tensor_8h.html">tensor.h</a></div><div class="ttdoc">High-performance multi-dimensional tensor library with GPU, BLAS, and autograd support.</div></div>
<div class="ttc" id="atensor__types_8h_html"><div class="ttname"><a href="tensor__types_8h.html">tensor_types.h</a></div><div class="ttdoc">Type aliases for common Tensor specializations.</div></div>
</div><!-- fragment --></div><!-- contents -->
</div><!-- doc-content -->
</div><!-- container -->
<!-- start footer part -->
<div id="nav-path" class="navpath"><!-- id is needed for treeview function! -->
  <ul>
    <li class="navelem"><a href="dir_d44c64559bbebec7f509842c48db8b23.html">include</a></li><li class="navelem"><a href="nn__layers_8h.html">nn_layers.h</a></li>
    <li class="footer">Generated by <a href="https://www.doxygen.org/index.html"><img class="footer" src="doxygen.svg" width="104" height="31" alt="doxygen"/></a> 1.15.0 </li>
  </ul>
</div>
</body>
</html>
